
======== componentstatuses manifests ========

apiVersion: v1
items:
- apiVersion: v1
  conditions:
  - message: '{"health": "true"}'
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: etcd-0
    selfLink: /api/v1/componentstatuses/etcd-0
- apiVersion: v1
  conditions:
  - message: ok
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: controller-manager
    selfLink: /api/v1/componentstatuses/controller-manager
- apiVersion: v1
  conditions:
  - message: ok
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: scheduler
    selfLink: /api/v1/componentstatuses/scheduler
- apiVersion: v1
  conditions:
  - message: '{"health": "true"}'
    status: "True"
    type: Healthy
  kind: ComponentStatus
  metadata:
    creationTimestamp: null
    name: etcd-1
    selfLink: /api/v1/componentstatuses/etcd-1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== configmaps manifests ========

apiVersion: v1
items:
- apiVersion: v1
  data:
    client-ca-file: |
      -----BEGIN CERTIFICATE-----
      MIIDDDCCAfSgAwIBAgIRALNasrnbISF1ztjNbBwrN9wwDQYJKoZIhvcNAQELBQAw
      LzEtMCsGA1UEAxMkMzU0ZTA2NDAtNGNmNi00NTNkLWE1MTEtYjliN2IyMjFkM2Zj
      MB4XDTIwMDMxNTA5MDIzMloXDTI1MDMxNDEwMDIzMlowLzEtMCsGA1UEAxMkMzU0
      ZTA2NDAtNGNmNi00NTNkLWE1MTEtYjliN2IyMjFkM2ZjMIIBIjANBgkqhkiG9w0B
      AQEFAAOCAQ8AMIIBCgKCAQEA11Hdmr+ybBgXC+MTQzp89CLPJKc8Cq4aKb2LIkan
      BKVULvCCJnktyloJddaKlvckhFslGKsIrkBgyZrVfjhVjLaOQw3AUto3Kfc55nie
      PD+fSCIvNn/8XiUVoBfaaxNs976WcUPWBKHsaVTjRXKyQSqoCyHS/Jhovog4Hrlg
      Prhu6bgZnlq7aF5TEyMlVCxqbxAhGPnqiRIoP6DgCJ7FptXYG4V6mEbjodtCezH5
      DoHjmeOPV31Vy3MCcFlKcyHkFFHLYsJpagPpMrfPB6t67m9v9I9IxKfnKy0M6+g4
      hDP0PmhQ87ANYqag+xqJQlSmvh8sOKRx0YHBFXQIVXMiwwIDAQABoyMwITAOBgNV
      HQ8BAf8EBAMCAgQwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEA
      G+gy0dVeW3APGn2Q4LmbBw46uGkmB1uPbCU9e6u1Vu5hb14NN4Thbb9Hp5xkFne/
      3vh1CanpfbbzS/lK1uhxVzWE9/o9N6fWQpuQPLaF6m7wAboDGgjt/afvmKQqLwqk
      qPRduTPisNgRlv7jGawQprZC9eMYgYM0dU7WNFJ2u5jstz9qQ/fFOMvaIVcQ0zG5
      KjUksFAPJ3Bg9tPKcEhXgVdbC4lKsEGFr9oJTziznRlZAMPagthjE2mra0HlxN7n
      fodwj8MlTgKhzwhzVaHJOv35KiDpe2Qafy+0AXZHb7kpQhvJ6NlqSvN6w+6vRcBj
      1Ou5Gip5181FssC+sSs/xw==
      -----END CERTIFICATE-----
    requestheader-allowed-names: '["aggregator"]'
    requestheader-client-ca-file: |
      -----BEGIN CERTIFICATE-----
      MIIDDDCCAfSgAwIBAgIRAMacGDwpMbxkuDBuZjbeVukwDQYJKoZIhvcNAQELBQAw
      LzEtMCsGA1UEAxMkYjU1OTlhYjAtZTM4ZC00ZDdjLTk3NTMtNTE0ZDkxYjYwNTQz
      MB4XDTIwMDMxNTA5MDMwMloXDTI1MDMxNDEwMDMwMlowLzEtMCsGA1UEAxMkYjU1
      OTlhYjAtZTM4ZC00ZDdjLTk3NTMtNTE0ZDkxYjYwNTQzMIIBIjANBgkqhkiG9w0B
      AQEFAAOCAQ8AMIIBCgKCAQEAiQN/oBnA6gS1TvNbrGGPHYx7vUNOS3XX4Y9Yvfzh
      oMDDFdQ2vX0sa54BlI33+Cv+LMhtjpiO1WuVhcFoomOuP/DrCcISmeWnKpBpYhXH
      Uuc9y8Kq2pFGFQNzxbLX0Uk4CnTDpRjLjsFObGEuPAfjyYU9+57RsSW9c/Ou0qN6
      1po/xPDKsraywx6KpzWOvkf4g4N2Y/dm3+T+UyMxh4bSgCYUyKqeig9CtkYYJxqB
      vHRVzIfAI1LGQrHph1OAvGcx3ATfZg2UAOK7G9zN1zQZYx3cyVktcjCqjWg1b9XG
      r9D5Zc4kvOww+1n+eyGvb4NTbZ8Xja4pHjDn6UH94q6vTwIDAQABoyMwITAOBgNV
      HQ8BAf8EBAMCAgQwDwYDVR0TAQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEA
      e3mhX4ClYvz+5AqjESXl2Zg/FtmJY59rYmVZ/AyBbJgVSNsHlef3mPPO1n4oaaLq
      y4cOILIR02vzgpvY2BxuBJetZy4bywnuRKJILcub1JV6Y+siVMHtxQ/h/tBtAhuE
      /Om7H22EwLWEk2zuyj6MDXyPM/JL6gDpPmsqKwDGHwaV4npTYlqI20imSHBkF/vd
      StCpj4Pb67QX+6/+ph0fXJKE6OuPqy1KgTKptyTylsZMc+QNArnb6avtVM+FtieV
      whDnjec1lsquDdj8nWx/3tmQgiNrHMlKn/Xkz4qoa7z+DKo876ZEXjRPHQqrmnf8
      QXglEO2Ronh6Fz0ex2dRcw==
      -----END CERTIFICATE-----
    requestheader-extra-headers-prefix: '["X-Remote-Extra-"]'
    requestheader-group-headers: '["X-Remote-Group"]'
    requestheader-username-headers: '["X-Remote-User"]'
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:04:48Z"
    name: extension-apiserver-authentication
    namespace: kube-system
    resourceVersion: "35"
    selfLink: /api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication
    uid: 673ac811-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  data:
    containers.input.conf: "# This configuration file for Fluentd is used\n# to watch
      changes to Docker log files that live in the\n# directory /var/lib/docker/containers/
      and are symbolically\n# linked to from the /var/log/containers directory using
      names that capture the\n# pod name and container name. These logs are then submitted
      to\n# Google Cloud Logging which assumes the installation of the cloud-logging
      plug-in.\n#\n# Example\n# =======\n# A line in the Docker log file might look
      like this JSON:\n#\n# {\"log\":\"2014/09/25 21:15:03 Got request with path wombat\\\\n\",\n#
      \ \"stream\":\"stderr\",\n#   \"time\":\"2014-09-25T21:15:03.499185026Z\"}\n#\n#
      The original tag is derived from the log file's location.\n# For example a Docker
      container's logs might be in the directory:\n#  /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\n#
      and in the file:\n#  997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n#
      where 997599971ee6... is the Docker ID of the running container.\n# The Kubernetes
      kubelet makes a symbolic link to this file on the host\n# machine in the /var/log/containers
      directory which includes the pod name,\n# the namespace name and the Kubernetes
      container name:\n#    synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n#
      \   ->\n#    /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n#
      The /var/log directory on the host is mapped to the /var/log directory in the
      container\n# running this instance of Fluentd and we end up collecting the file:\n#
      \  /var/log/containers/synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n#
      This results in the tag:\n#  var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n#
      where 'synthetic-logger-0.25lps-pod' is the pod name, 'default' is the\n# namespace
      name, 'synth-lgr' is the container name and '997599971ee6..' is\n# the container
      ID.\n# The record reformer is used to extract pod_name, namespace_name and\n#
      container_name from the tag and set them in a local_resource_id in the\n# format
      of:\n# 'k8s_container.<NAMESPACE_NAME>.<POD_NAME>.<CONTAINER_NAME>'.\n# The
      reformer also changes the tags to 'stderr' or 'stdout' based on the\n# value
      of 'stream'.\n# local_resource_id is later used by google_cloud plugin to determine
      the\n# monitored resource to ingest logs against.\n\n# Json Log Example:\n#
      {\"log\":\"[info:2016-02-16T16:04:05.930-08:00] Some log text here\\n\",\"stream\":\"stdout\",\"time\":\"2016-02-17T00:04:05.931087621Z\"}\n#
      CRI Log Example:\n# 2016-02-17T00:04:05.931087621Z stdout F [info:2016-02-16T16:04:05.930-08:00]
      Some log text here\n<source>\n  @type tail\n  \n  path /var/log/containers/*.log\n
      \ \n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-containers.pos\n  \n
      \ # Tags at this point are in the format of:\n  # reform.var.log.containers.<POD_NAME>_<NAMESPACE_NAME>_<CONTAINER_NAME>-<CONTAINER_ID>.log\n
      \ tag reform.*\n  read_from_head true\n  <parse>\n    @type multi_format\n    <pattern>\n
      \     format json\n      time_key time\n      time_format %Y-%m-%dT%H:%M:%S.%NZ\n
      \   </pattern>\n    <pattern>\n      format /^(?<time>.+) (?<stream>stdout|stderr)
      [^ ]* (?<log>.*)$/\n      time_format %Y-%m-%dT%H:%M:%S.%N%:z\n    </pattern>\n
      \ </parse>\n</source>\n\n<filter reform.**>\n  @type parser\n  format /^(?<severity>\\w)(?<time>\\d{4}
      [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<log>.*)/\n  reserve_data
      true\n  suppress_parse_error_log true\n  emit_invalid_record_to_error false\n
      \ key_name log\n</filter>\n\n\n<filter reform.**>\n  # This plugin uses environment
      variables KUBERNETES_SERVICE_HOST and\n  # KUBERNETES_SERVICE_PORT to talk to
      the API server. These environment\n  # variables are added by kubelet automatically.\n
      \ @type kubernetes_metadata\n  # Interval in seconds to dump cache stats locally
      in the Fluentd log.\n  stats_interval 300\n  # TTL in seconds of each cached
      element.\n  cache_ttl 30\n  \n  # Skip fetching unused metadata.\n  skip_container_metadata
      true\n  skip_master_url true\n  skip_namespace_metadata true\n  \n</filter>\n\n<filter
      reform.**>\n  # We have to use record_modifier because only this plugin supports
      complex\n  # logic to modify record the way we need.\n  @type record_modifier\n
      \ enable_ruby true\n  <record>\n    # Extract \"kubernetes\"->\"labels\" and
      set them as\n    # \"logging.googleapis.com/labels\". Prefix these labels with\n
      \   # \"k8s-pod\" to distinguish with other labels and avoid\n    # label name
      collision with other types of labels.\n    _dummy_ ${if record.is_a?(Hash) &&
      record.has_key?('kubernetes') && record['kubernetes'].has_key?('labels') &&
      record['kubernetes']['labels'].is_a?(Hash); then; record[\"logging.googleapis.com/labels\"]
      = record['kubernetes']['labels'].map{ |k, v| [\"k8s-pod/#{k}\", v]}.to_h; end;
      nil}\n  </record>\n  # Delete this dummy field and the rest of \"kubernetes\"
      and \"docker\".\n  remove_keys _dummy_,kubernetes,docker\n</filter>\n\n\n<match
      reform.**>\n  @type record_reformer\n  enable_ruby true\n  <record>\n    # Extract
      local_resource_id from tag for 'k8s_container' monitored\n    # resource. The
      format is:\n    # 'k8s_container.<namespace_name>.<pod_name>.<container_name>'.\n
      \   \"logging.googleapis.com/local_resource_id\" ${\"k8s_container.#{tag_suffix[4].rpartition('.')[0].split('_')[1]}.#{tag_suffix[4].rpartition('.')[0].split('_')[0]}.#{tag_suffix[4].rpartition('.')[0].split('_')[2].rpartition('-')[0]}\"}\n
      \   # Rename the field 'log' to a more generic field 'message'. This way the\n
      \   # fluent-plugin-google-cloud knows to flatten the field as textPayload\n
      \   # instead of jsonPayload after extracting 'time', 'severity' and\n    #
      'stream' from the record.\n    message ${record['log']}\n    # If 'severity'
      is not set, assume stderr is ERROR and stdout is INFO.\n    severity ${record['severity']
      || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end}\n  </record>\n
      \ tag ${if record['stream'] == 'stderr' then 'raw.stderr' else 'raw.stdout'
      end}\n  remove_keys stream,log\n</match>\n\n# Detect exceptions in the log output
      and forward them as one log entry.\n<match {raw.stderr,raw.stdout}>\n  @type
      detect_exceptions\n\n  remove_tag_prefix raw\n  message message\n  stream \"logging.googleapis.com/local_resource_id\"\n
      \ multiline_flush_interval 5\n  max_bytes 500000\n  max_lines 1000\n</match>"
    monitoring.conf: |-
      # This source is used to acquire approximate process start timestamp,
      # which purpose is explained before the corresponding output plugin.
      <source>
        @type exec
        command /bin/sh -c 'date +%s'
        tag process_start
        time_format %Y-%m-%d %H:%M:%S
        keys process_start_timestamp
      </source>

      # This filter is used to convert process start timestamp to integer
      # value for correct ingestion in the prometheus output plugin.
      <filter process_start>
        @type record_transformer
        enable_ruby true
        auto_typecast true
        <record>
          process_start_timestamp ${record["process_start_timestamp"].to_i}
        </record>
      </filter>
    output.conf: "# This match is placed before the all-matching output to provide
      metric\n# exporter with a process start timestamp for correct exporting of\n#
      cumulative metrics to Stackdriver.\n<match process_start>\n  @type prometheus\n\n
      \ <metric>\n    type gauge\n    name process_start_time_seconds\n    desc Timestamp
      of the process start in seconds\n    key process_start_timestamp\n  </metric>\n</match>\n\n#
      This filter allows to count the number of log entries read by fluentd\n# before
      they are processed by the output plugin. This in turn allows to\n# monitor the
      number of log entries that were read but never sent, e.g.\n# because of liveness
      probe removing buffer.\n<filter **>\n  @type prometheus\n  <metric>\n    type
      counter\n    name logging_entry_count\n    desc Total number of log entries
      generated by either application containers or system components\n  </metric>\n</filter>\n\n#
      This section is exclusive for k8s_container logs. Those come with\n# 'stderr'/'stdout'
      tags.\n# TODO(instrumentation): Reconsider this workaround later.\n# Trim the
      entries which exceed slightly less than 100KB, to avoid\n# dropping them. It
      is a necessity, because Stackdriver only supports\n# entries that are up to
      100KB in size.\n<filter {stderr,stdout}>\n  @type record_transformer\n  enable_ruby
      true\n  <record>\n    message ${record['message'].length > 100000 ? \"[Trimmed]#{record['message'][0..100000]}...\"
      : record['message']}\n  </record>\n</filter>\n\n# Do not collect fluentd's own
      logs to avoid infinite loops.\n<match fluent.**>\n  @type null\n</match>\n\n#
      Add a unique insertId to each log entry that doesn't already have it.\n# This
      helps guarantee the order and prevent log duplication.\n<filter **>\n  @type
      add_insert_ids\n</filter>\n\n# This filter parses the 'source' field created
      for glog lines into a single\n# top-level field, for proper processing by the
      output plugin.\n# For example, if a record includes:\n#     {\"source\":\"handlers.go:131\"},\n#
      then the following entry will be added to the record:\n#     {\"logging.googleapis.com/sourceLocation\":\n#
      \         {\"file\":\"handlers.go\", \"line\":\"131\"}\n#     }\n<filter **>\n
      \ @type record_transformer\n  enable_ruby true\n  <record>\n    \"logging.googleapis.com/sourceLocation\"
      ${if record.is_a?(Hash) && record.has_key?('source'); source_parts = record['source'].split(':',
      2); {'file' => source_parts[0], 'line' => source_parts[1]} if source_parts.length
      == 2; else; nil; end}\n  </record>\n</filter>\n\n\n# This section is exclusive
      for k8s_container logs. These logs come with\n# 'stderr'/'stdout' tags.\n# We
      use a separate output stanza for 'k8s_node' logs with a smaller buffer\n# because
      node logs are less important than user's container logs.\n<match {stderr,stdout}>\n
      \ @type google_cloud\n\n  # Try to detect JSON formatted log entries.\n  detect_json
      true\n  # Collect metrics in Prometheus registry about plugin activity.\n  enable_monitoring
      true\n  monitoring_type prometheus\n  # Allow log entries from multiple containers
      to be sent in the same request.\n  split_logs_by_tag false\n  # Set the buffer
      type to file to improve the reliability and reduce the memory consumption\n
      \ buffer_type file\n  \n  buffer_path /var/run/google-fluentd/buffers/kubernetes.containers.buffer\n
      \ \n  # Set queue_full action to block because we want to pause gracefully\n
      \ # in case of the off-the-limits load instead of throwing an exception\n  buffer_queue_full_action
      block\n  # Set the chunk limit conservatively to avoid exceeding the recommended\n
      \ # chunk size of 5MB per write request.\n  buffer_chunk_limit 512k\n  # Cap
      the combined memory usage of this buffer and the one below to\n  # 512KiB/chunk
      * (6 + 2) chunks = 4 MiB\n  buffer_queue_limit 6\n  # Never wait more than 5
      seconds before flushing logs in the non-error case.\n  flush_interval 5s\n  #
      Never wait longer than 30 seconds between retries.\n  max_retry_wait 30\n  #
      Disable the limit on the number of retries (retry forever).\n  disable_retry_limit\n
      \ # Use multiple threads for processing.\n  num_threads 2\n  use_grpc true\n
      \ # Skip timestamp adjustment as this is in a controlled environment with\n
      \ # known timestamp format. This helps with CPU usage.\n  adjust_invalid_timestamps
      false\n</match>\n\n# Attach local_resource_id for 'k8s_node' monitored resource.\n<filter
      **>\n  @type record_transformer\n  enable_ruby true\n  <record>\n    \"logging.googleapis.com/local_resource_id\"
      ${\"k8s_node.#{ENV['NODE_NAME']}\"}\n  </record>\n</filter>\n\n# This section
      is exclusive for 'k8s_node' logs. These logs come with tags\n# that are neither
      'stderr' or 'stdout'.\n# We use a separate output stanza for 'k8s_container'
      logs with a larger\n# buffer because user's container logs are more important
      than node logs.\n<match **>\n  @type google_cloud\n\n  detect_json true\n  enable_monitoring
      true\n  monitoring_type prometheus\n  # Allow entries from multiple system logs
      to be sent in the same request.\n  split_logs_by_tag false\n  detect_subservice
      false\n  buffer_type file\n  \n  buffer_path /var/run/google-fluentd/buffers/kubernetes.system.buffer\n
      \ \n  buffer_queue_full_action block\n  buffer_chunk_limit 512k\n  buffer_queue_limit
      2\n  flush_interval 5s\n  max_retry_wait 30\n  disable_retry_limit\n  num_threads
      2\n  use_grpc true\n  # Skip timestamp adjustment as this is in a controlled
      environment with\n  # known timestamp format. This helps with CPU usage.\n  adjust_invalid_timestamps
      false\n</match>"
    system.input.conf: "# Example:\n# Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj
      startupscript: Finished running startup script /var/run/google.startup.script\n<source>\n
      \ @type tail\n  format syslog\n  path /var/log/startupscript.log\n  \n  pos_file
      /var/run/google-fluentd/pos-files/gcp-startupscript.pos\n  \n  tag startupscript\n</source>\n\n#
      Examples:\n# time=\"2016-02-04T06:51:03.053580605Z\" level=info msg=\"GET /containers/json\"\n#
      time=\"2016-02-04T07:53:57.505612354Z\" level=error msg=\"HTTP Error\" err=\"No
      such image: -f\" statusCode=404\n# TODO(random-liu): Remove this after cri container
      runtime rolls out.\n<source>\n  @type tail\n  format /^time=\"(?<time>[^)]*)\"
      level=(?<severity>[^ ]*) msg=\"(?<message>[^\"]*)\"( err=\"(?<error>[^\"]*)\")?(
      statusCode=($<status_code>\\d+))?/\n  path /var/log/docker.log\n  \n  pos_file
      /var/run/google-fluentd/pos-files/gcp-docker.pos\n  \n  tag docker\n</source>\n\n#
      Example:\n# 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal\n<source>\n
      \ @type tail\n  # Not parsing this, because it doesn't have anything particularly
      useful to\n  # parse out of it (like severities).\n  format none\n  path /var/log/etcd.log\n
      \ \n  pos_file /var/run/google-fluentd/pos-files/gcp-etcd.pos\n  \n  tag etcd\n</source>\n\n#
      Multi-line parsing is required for all the kube logs because very large log\n#
      statements, such as those that include entire object bodies, get split into\n#
      multiple lines by glog.\n\n# Example:\n# I0204 07:32:30.020537    3368 server.go:1048]
      POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]\n<source>\n
      \ @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline
      /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^
      \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kubelet.log\n
      \ \n  pos_file /var/run/google-fluentd/pos-files/gcp-kubelet.pos\n  \n  tag
      kubelet\n</source>\n\n# Example:\n# I1118 21:26:53.975789       6 proxier.go:1096]
      Port \"nodePort for kube-system/default-http-backend:http\" (:31429/tcp) was
      open before and is still needed\n<source>\n  @type tail\n  format multiline\n
      \ multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4}
      [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format
      %m%d %H:%M:%S.%N\n  path /var/log/kube-proxy.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-proxy.pos\n
      \ \n  tag kube-proxy\n</source>\n\n# Example:\n# I0204 07:00:19.604280       5
      handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3
      (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]\n<source>\n  @type tail\n
      \ format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n
      \ format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^
      \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-apiserver.log\n
      \ \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-apiserver.pos\n  \n
      \ tag kube-apiserver\n</source>\n\n# Example:\n# I0204 06:55:31.872680       5
      servicecontroller.go:277] LB already exists and doesn't need update for service
      kube-system/kube-ui\n<source>\n  @type tail\n  format multiline\n  multiline_flush_interval
      5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4}
      [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format
      %m%d %H:%M:%S.%N\n  path /var/log/kube-controller-manager.log\n  \n  pos_file
      /var/run/google-fluentd/pos-files/gcp-kube-controller-manager.pos\n  \n  tag
      kube-controller-manager\n</source>\n\n# Example:\n# W0204 06:49:18.239674       7
      reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service
      ended with: 401: The event in requested index is outdated and cleared (the requested
      history has been cleared [2578313/2577886]) [2579312]\n<source>\n  @type tail\n
      \ format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n
      \ format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^
      \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-scheduler.log\n
      \ \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-scheduler.pos\n  \n
      \ tag kube-scheduler\n</source>\n\n# Example:\n# I1104 10:36:20.242766       5
      rescheduler.go:73] Running Rescheduler\n<source>\n  @type tail\n  format multiline\n
      \ multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4}
      [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format
      %m%d %H:%M:%S.%N\n  path /var/log/rescheduler.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-rescheduler.pos\n
      \ \n  tag rescheduler\n</source>\n\n# Example:\n# I0603 15:31:05.793605       6
      cluster_manager.go:230] Reading config from path /etc/gce.conf\n<source>\n  @type
      tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline
      /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^
      \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/glbc.log\n
      \ \n  pos_file /var/run/google-fluentd/pos-files/gcp-glbc.pos\n  \n  tag glbc\n</source>\n\n#
      Example:\n# I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config
      from path /etc/gce.conf\n<source>\n  @type tail\n  format multiline\n  multiline_flush_interval
      5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4}
      [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format
      %m%d %H:%M:%S.%N\n  path /var/log/cluster-autoscaler.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-cluster-autoscaler.pos\n
      \ \n  tag cluster-autoscaler\n</source>\n\n# Logs from systemd-journal for interesting
      services.\n# TODO(random-liu): Keep this for compatibility, remove this after\n#
      cri container runtime rolls out.\n<source>\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\":
      \"docker.service\" }]\n  \n  <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-docker.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag docker\n</source>\n\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"docker.service\" }]\n  \n
      \ <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-container-runtime.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag container-runtime\n</source>\n\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kubelet.service\" }]\n  \n
      \ <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kubelet.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag kubelet\n</source>\n\n\n# kube-node-installation,
      kube-node-configuration, and kube-logrotate are\n# oneshots, but it's extremely
      valuable to have their logs on Stackdriver\n# as they can diagnose critical
      issues with node startup.\n# See http://cs/cloud-gke-kubernetes/cluster/gce/gci/node.yaml.\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-node-installation.service\"
      }]\n  \n  <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-node-installation.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag kube-node-installation\n</source>\n\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-node-configuration.service\"
      }]\n  \n  <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-node-configuration.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag kube-node-configuration\n</source>\n\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-logrotate.service\"
      }]\n  \n  <storage>\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-logrotate.pos\n
      \ </storage>\n  \n  read_from_head true\n  tag kube-logrotate\n</source>\n\n\n<source>\n
      \ @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"node-problem-detector.service\"
      }]\n  pos_file /var/log/gcp-journald-node-problem-detector.pos\n  read_from_head
      true\n  tag node-problem-detector\n</source>\n\n\n<source>\n  @type systemd\n
      \ filters [{ \"_SYSTEMD_UNIT\": \"kube-container-runtime-monitor.service\" }]\n
      \ pos_file /var/log/gcp-journald-kube-container-runtime-monitor.pos\n  read_from_head
      true\n  tag kube-container-runtime-monitor\n</source>\n\n<source>\n  @type systemd\n
      \ filters [{ \"_SYSTEMD_UNIT\": \"kubelet-monitor.service\" }]\n  pos_file /var/log/gcp-journald-kubelet-monitor.pos\n
      \ read_from_head true\n  tag kubelet-monitor\n</source>"
  kind: ConfigMap
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","data":{"containers.input.conf":"# This configuration file for Fluentd is used\n# to watch changes to Docker log files that live in the\n# directory /var/lib/docker/containers/ and are symbolically\n# linked to from the /var/log/containers directory using names that capture the\n# pod name and container name. These logs are then submitted to\n# Google Cloud Logging which assumes the installation of the cloud-logging plug-in.\n#\n# Example\n# =======\n# A line in the Docker log file might look like this JSON:\n#\n# {\"log\":\"2014/09/25 21:15:03 Got request with path wombat\\\\n\",\n#  \"stream\":\"stderr\",\n#   \"time\":\"2014-09-25T21:15:03.499185026Z\"}\n#\n# The original tag is derived from the log file's location.\n# For example a Docker container's logs might be in the directory:\n#  /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\n# and in the file:\n#  997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n# where 997599971ee6... is the Docker ID of the running container.\n# The Kubernetes kubelet makes a symbolic link to this file on the host\n# machine in the /var/log/containers directory which includes the pod name,\n# the namespace name and the Kubernetes container name:\n#    synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n#    -\u003e\n#    /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n# The /var/log directory on the host is mapped to the /var/log directory in the container\n# running this instance of Fluentd and we end up collecting the file:\n#   /var/log/containers/synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n# This results in the tag:\n#  var.log.containers.synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n# where 'synthetic-logger-0.25lps-pod' is the pod name, 'default' is the\n# namespace name, 'synth-lgr' is the container name and '997599971ee6..' is\n# the container ID.\n# The record reformer is used to extract pod_name, namespace_name and\n# container_name from the tag and set them in a local_resource_id in the\n# format of:\n# 'k8s_container.\u003cNAMESPACE_NAME\u003e.\u003cPOD_NAME\u003e.\u003cCONTAINER_NAME\u003e'.\n# The reformer also changes the tags to 'stderr' or 'stdout' based on the\n# value of 'stream'.\n# local_resource_id is later used by google_cloud plugin to determine the\n# monitored resource to ingest logs against.\n\n# Json Log Example:\n# {\"log\":\"[info:2016-02-16T16:04:05.930-08:00] Some log text here\\n\",\"stream\":\"stdout\",\"time\":\"2016-02-17T00:04:05.931087621Z\"}\n# CRI Log Example:\n# 2016-02-17T00:04:05.931087621Z stdout F [info:2016-02-16T16:04:05.930-08:00] Some log text here\n\u003csource\u003e\n  @type tail\n  \n  path /var/log/containers/*.log\n  \n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-containers.pos\n  \n  # Tags at this point are in the format of:\n  # reform.var.log.containers.\u003cPOD_NAME\u003e_\u003cNAMESPACE_NAME\u003e_\u003cCONTAINER_NAME\u003e-\u003cCONTAINER_ID\u003e.log\n  tag reform.*\n  read_from_head true\n  \u003cparse\u003e\n    @type multi_format\n    \u003cpattern\u003e\n      format json\n      time_key time\n      time_format %Y-%m-%dT%H:%M:%S.%NZ\n    \u003c/pattern\u003e\n    \u003cpattern\u003e\n      format /^(?\u003ctime\u003e.+) (?\u003cstream\u003estdout|stderr) [^ ]* (?\u003clog\u003e.*)$/\n      time_format %Y-%m-%dT%H:%M:%S.%N%:z\n    \u003c/pattern\u003e\n  \u003c/parse\u003e\n\u003c/source\u003e\n\n\u003cfilter reform.**\u003e\n  @type parser\n  format /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003clog\u003e.*)/\n  reserve_data true\n  suppress_parse_error_log true\n  emit_invalid_record_to_error false\n  key_name log\n\u003c/filter\u003e\n\n\n\u003cfilter reform.**\u003e\n  # This plugin uses environment variables KUBERNETES_SERVICE_HOST and\n  # KUBERNETES_SERVICE_PORT to talk to the API server. These environment\n  # variables are added by kubelet automatically.\n  @type kubernetes_metadata\n  # Interval in seconds to dump cache stats locally in the Fluentd log.\n  stats_interval 300\n  # TTL in seconds of each cached element.\n  cache_ttl 30\n  \n  # Skip fetching unused metadata.\n  skip_container_metadata true\n  skip_master_url true\n  skip_namespace_metadata true\n  \n\u003c/filter\u003e\n\n\u003cfilter reform.**\u003e\n  # We have to use record_modifier because only this plugin supports complex\n  # logic to modify record the way we need.\n  @type record_modifier\n  enable_ruby true\n  \u003crecord\u003e\n    # Extract \"kubernetes\"-\u003e\"labels\" and set them as\n    # \"logging.googleapis.com/labels\". Prefix these labels with\n    # \"k8s-pod\" to distinguish with other labels and avoid\n    # label name collision with other types of labels.\n    _dummy_ ${if record.is_a?(Hash) \u0026\u0026 record.has_key?('kubernetes') \u0026\u0026 record['kubernetes'].has_key?('labels') \u0026\u0026 record['kubernetes']['labels'].is_a?(Hash); then; record[\"logging.googleapis.com/labels\"] = record['kubernetes']['labels'].map{ |k, v| [\"k8s-pod/#{k}\", v]}.to_h; end; nil}\n  \u003c/record\u003e\n  # Delete this dummy field and the rest of \"kubernetes\" and \"docker\".\n  remove_keys _dummy_,kubernetes,docker\n\u003c/filter\u003e\n\n\n\u003cmatch reform.**\u003e\n  @type record_reformer\n  enable_ruby true\n  \u003crecord\u003e\n    # Extract local_resource_id from tag for 'k8s_container' monitored\n    # resource. The format is:\n    # 'k8s_container.\u003cnamespace_name\u003e.\u003cpod_name\u003e.\u003ccontainer_name\u003e'.\n    \"logging.googleapis.com/local_resource_id\" ${\"k8s_container.#{tag_suffix[4].rpartition('.')[0].split('_')[1]}.#{tag_suffix[4].rpartition('.')[0].split('_')[0]}.#{tag_suffix[4].rpartition('.')[0].split('_')[2].rpartition('-')[0]}\"}\n    # Rename the field 'log' to a more generic field 'message'. This way the\n    # fluent-plugin-google-cloud knows to flatten the field as textPayload\n    # instead of jsonPayload after extracting 'time', 'severity' and\n    # 'stream' from the record.\n    message ${record['log']}\n    # If 'severity' is not set, assume stderr is ERROR and stdout is INFO.\n    severity ${record['severity'] || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end}\n  \u003c/record\u003e\n  tag ${if record['stream'] == 'stderr' then 'raw.stderr' else 'raw.stdout' end}\n  remove_keys stream,log\n\u003c/match\u003e\n\n# Detect exceptions in the log output and forward them as one log entry.\n\u003cmatch {raw.stderr,raw.stdout}\u003e\n  @type detect_exceptions\n\n  remove_tag_prefix raw\n  message message\n  stream \"logging.googleapis.com/local_resource_id\"\n  multiline_flush_interval 5\n  max_bytes 500000\n  max_lines 1000\n\u003c/match\u003e","monitoring.conf":"# This source is used to acquire approximate process start timestamp,\n# which purpose is explained before the corresponding output plugin.\n\u003csource\u003e\n  @type exec\n  command /bin/sh -c 'date +%s'\n  tag process_start\n  time_format %Y-%m-%d %H:%M:%S\n  keys process_start_timestamp\n\u003c/source\u003e\n\n# This filter is used to convert process start timestamp to integer\n# value for correct ingestion in the prometheus output plugin.\n\u003cfilter process_start\u003e\n  @type record_transformer\n  enable_ruby true\n  auto_typecast true\n  \u003crecord\u003e\n    process_start_timestamp ${record[\"process_start_timestamp\"].to_i}\n  \u003c/record\u003e\n\u003c/filter\u003e","output.conf":"# This match is placed before the all-matching output to provide metric\n# exporter with a process start timestamp for correct exporting of\n# cumulative metrics to Stackdriver.\n\u003cmatch process_start\u003e\n  @type prometheus\n\n  \u003cmetric\u003e\n    type gauge\n    name process_start_time_seconds\n    desc Timestamp of the process start in seconds\n    key process_start_timestamp\n  \u003c/metric\u003e\n\u003c/match\u003e\n\n# This filter allows to count the number of log entries read by fluentd\n# before they are processed by the output plugin. This in turn allows to\n# monitor the number of log entries that were read but never sent, e.g.\n# because of liveness probe removing buffer.\n\u003cfilter **\u003e\n  @type prometheus\n  \u003cmetric\u003e\n    type counter\n    name logging_entry_count\n    desc Total number of log entries generated by either application containers or system components\n  \u003c/metric\u003e\n\u003c/filter\u003e\n\n# This section is exclusive for k8s_container logs. Those come with\n# 'stderr'/'stdout' tags.\n# TODO(instrumentation): Reconsider this workaround later.\n# Trim the entries which exceed slightly less than 100KB, to avoid\n# dropping them. It is a necessity, because Stackdriver only supports\n# entries that are up to 100KB in size.\n\u003cfilter {stderr,stdout}\u003e\n  @type record_transformer\n  enable_ruby true\n  \u003crecord\u003e\n    message ${record['message'].length \u003e 100000 ? \"[Trimmed]#{record['message'][0..100000]}...\" : record['message']}\n  \u003c/record\u003e\n\u003c/filter\u003e\n\n# Do not collect fluentd's own logs to avoid infinite loops.\n\u003cmatch fluent.**\u003e\n  @type null\n\u003c/match\u003e\n\n# Add a unique insertId to each log entry that doesn't already have it.\n# This helps guarantee the order and prevent log duplication.\n\u003cfilter **\u003e\n  @type add_insert_ids\n\u003c/filter\u003e\n\n# This filter parses the 'source' field created for glog lines into a single\n# top-level field, for proper processing by the output plugin.\n# For example, if a record includes:\n#     {\"source\":\"handlers.go:131\"},\n# then the following entry will be added to the record:\n#     {\"logging.googleapis.com/sourceLocation\":\n#          {\"file\":\"handlers.go\", \"line\":\"131\"}\n#     }\n\u003cfilter **\u003e\n  @type record_transformer\n  enable_ruby true\n  \u003crecord\u003e\n    \"logging.googleapis.com/sourceLocation\" ${if record.is_a?(Hash) \u0026\u0026 record.has_key?('source'); source_parts = record['source'].split(':', 2); {'file' =\u003e source_parts[0], 'line' =\u003e source_parts[1]} if source_parts.length == 2; else; nil; end}\n  \u003c/record\u003e\n\u003c/filter\u003e\n\n\n# This section is exclusive for k8s_container logs. These logs come with\n# 'stderr'/'stdout' tags.\n# We use a separate output stanza for 'k8s_node' logs with a smaller buffer\n# because node logs are less important than user's container logs.\n\u003cmatch {stderr,stdout}\u003e\n  @type google_cloud\n\n  # Try to detect JSON formatted log entries.\n  detect_json true\n  # Collect metrics in Prometheus registry about plugin activity.\n  enable_monitoring true\n  monitoring_type prometheus\n  # Allow log entries from multiple containers to be sent in the same request.\n  split_logs_by_tag false\n  # Set the buffer type to file to improve the reliability and reduce the memory consumption\n  buffer_type file\n  \n  buffer_path /var/run/google-fluentd/buffers/kubernetes.containers.buffer\n  \n  # Set queue_full action to block because we want to pause gracefully\n  # in case of the off-the-limits load instead of throwing an exception\n  buffer_queue_full_action block\n  # Set the chunk limit conservatively to avoid exceeding the recommended\n  # chunk size of 5MB per write request.\n  buffer_chunk_limit 512k\n  # Cap the combined memory usage of this buffer and the one below to\n  # 512KiB/chunk * (6 + 2) chunks = 4 MiB\n  buffer_queue_limit 6\n  # Never wait more than 5 seconds before flushing logs in the non-error case.\n  flush_interval 5s\n  # Never wait longer than 30 seconds between retries.\n  max_retry_wait 30\n  # Disable the limit on the number of retries (retry forever).\n  disable_retry_limit\n  # Use multiple threads for processing.\n  num_threads 2\n  use_grpc true\n  # Skip timestamp adjustment as this is in a controlled environment with\n  # known timestamp format. This helps with CPU usage.\n  adjust_invalid_timestamps false\n\u003c/match\u003e\n\n# Attach local_resource_id for 'k8s_node' monitored resource.\n\u003cfilter **\u003e\n  @type record_transformer\n  enable_ruby true\n  \u003crecord\u003e\n    \"logging.googleapis.com/local_resource_id\" ${\"k8s_node.#{ENV['NODE_NAME']}\"}\n  \u003c/record\u003e\n\u003c/filter\u003e\n\n# This section is exclusive for 'k8s_node' logs. These logs come with tags\n# that are neither 'stderr' or 'stdout'.\n# We use a separate output stanza for 'k8s_container' logs with a larger\n# buffer because user's container logs are more important than node logs.\n\u003cmatch **\u003e\n  @type google_cloud\n\n  detect_json true\n  enable_monitoring true\n  monitoring_type prometheus\n  # Allow entries from multiple system logs to be sent in the same request.\n  split_logs_by_tag false\n  detect_subservice false\n  buffer_type file\n  \n  buffer_path /var/run/google-fluentd/buffers/kubernetes.system.buffer\n  \n  buffer_queue_full_action block\n  buffer_chunk_limit 512k\n  buffer_queue_limit 2\n  flush_interval 5s\n  max_retry_wait 30\n  disable_retry_limit\n  num_threads 2\n  use_grpc true\n  # Skip timestamp adjustment as this is in a controlled environment with\n  # known timestamp format. This helps with CPU usage.\n  adjust_invalid_timestamps false\n\u003c/match\u003e","system.input.conf":"# Example:\n# Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script /var/run/google.startup.script\n\u003csource\u003e\n  @type tail\n  format syslog\n  path /var/log/startupscript.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-startupscript.pos\n  \n  tag startupscript\n\u003c/source\u003e\n\n# Examples:\n# time=\"2016-02-04T06:51:03.053580605Z\" level=info msg=\"GET /containers/json\"\n# time=\"2016-02-04T07:53:57.505612354Z\" level=error msg=\"HTTP Error\" err=\"No such image: -f\" statusCode=404\n# TODO(random-liu): Remove this after cri container runtime rolls out.\n\u003csource\u003e\n  @type tail\n  format /^time=\"(?\u003ctime\u003e[^)]*)\" level=(?\u003cseverity\u003e[^ ]*) msg=\"(?\u003cmessage\u003e[^\"]*)\"( err=\"(?\u003cerror\u003e[^\"]*)\")?( statusCode=($\u003cstatus_code\u003e\\d+))?/\n  path /var/log/docker.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-docker.pos\n  \n  tag docker\n\u003c/source\u003e\n\n# Example:\n# 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal\n\u003csource\u003e\n  @type tail\n  # Not parsing this, because it doesn't have anything particularly useful to\n  # parse out of it (like severities).\n  format none\n  path /var/log/etcd.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-etcd.pos\n  \n  tag etcd\n\u003c/source\u003e\n\n# Multi-line parsing is required for all the kube logs because very large log\n# statements, such as those that include entire object bodies, get split into\n# multiple lines by glog.\n\n# Example:\n# I0204 07:32:30.020537    3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kubelet.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kubelet.pos\n  \n  tag kubelet\n\u003c/source\u003e\n\n# Example:\n# I1118 21:26:53.975789       6 proxier.go:1096] Port \"nodePort for kube-system/default-http-backend:http\" (:31429/tcp) was open before and is still needed\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-proxy.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-proxy.pos\n  \n  tag kube-proxy\n\u003c/source\u003e\n\n# Example:\n# I0204 07:00:19.604280       5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-apiserver.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-apiserver.pos\n  \n  tag kube-apiserver\n\u003c/source\u003e\n\n# Example:\n# I0204 06:55:31.872680       5 servicecontroller.go:277] LB already exists and doesn't need update for service kube-system/kube-ui\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-controller-manager.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-controller-manager.pos\n  \n  tag kube-controller-manager\n\u003c/source\u003e\n\n# Example:\n# W0204 06:49:18.239674       7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service ended with: 401: The event in requested index is outdated and cleared (the requested history has been cleared [2578313/2577886]) [2579312]\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-scheduler.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-kube-scheduler.pos\n  \n  tag kube-scheduler\n\u003c/source\u003e\n\n# Example:\n# I1104 10:36:20.242766       5 rescheduler.go:73] Running Rescheduler\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/rescheduler.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-rescheduler.pos\n  \n  tag rescheduler\n\u003c/source\u003e\n\n# Example:\n# I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from path /etc/gce.conf\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/glbc.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-glbc.pos\n  \n  tag glbc\n\u003c/source\u003e\n\n# Example:\n# I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from path /etc/gce.conf\n\u003csource\u003e\n  @type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?\u003cseverity\u003e\\w)(?\u003ctime\u003e\\d{4} [^\\s]*)\\s+(?\u003cpid\u003e\\d+)\\s+(?\u003csource\u003e[^ \\]]+)\\] (?\u003cmessage\u003e.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/cluster-autoscaler.log\n  \n  pos_file /var/run/google-fluentd/pos-files/gcp-cluster-autoscaler.pos\n  \n  tag cluster-autoscaler\n\u003c/source\u003e\n\n# Logs from systemd-journal for interesting services.\n# TODO(random-liu): Keep this for compatibility, remove this after\n# cri container runtime rolls out.\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"docker.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-docker.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag docker\n\u003c/source\u003e\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"docker.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-container-runtime.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag container-runtime\n\u003c/source\u003e\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kubelet.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kubelet.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag kubelet\n\u003c/source\u003e\n\n\n# kube-node-installation, kube-node-configuration, and kube-logrotate are\n# oneshots, but it's extremely valuable to have their logs on Stackdriver\n# as they can diagnose critical issues with node startup.\n# See http://cs/cloud-gke-kubernetes/cluster/gce/gci/node.yaml.\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-node-installation.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-node-installation.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag kube-node-installation\n\u003c/source\u003e\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-node-configuration.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-node-configuration.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag kube-node-configuration\n\u003c/source\u003e\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-logrotate.service\" }]\n  \n  \u003cstorage\u003e\n    @type local\n    path /var/run/google-fluentd/pos-files/gcp-journald-kube-logrotate.pos\n  \u003c/storage\u003e\n  \n  read_from_head true\n  tag kube-logrotate\n\u003c/source\u003e\n\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"node-problem-detector.service\" }]\n  pos_file /var/log/gcp-journald-node-problem-detector.pos\n  read_from_head true\n  tag node-problem-detector\n\u003c/source\u003e\n\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kube-container-runtime-monitor.service\" }]\n  pos_file /var/log/gcp-journald-kube-container-runtime-monitor.pos\n  read_from_head true\n  tag kube-container-runtime-monitor\n\u003c/source\u003e\n\n\u003csource\u003e\n  @type systemd\n  filters [{ \"_SYSTEMD_UNIT\": \"kubelet-monitor.service\" }]\n  pos_file /var/log/gcp-journald-kubelet-monitor.pos\n  read_from_head true\n  tag kubelet-monitor\n\u003c/source\u003e"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"fluentd-gcp-config-v1.2.6","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: fluentd-gcp-config-v1.2.6
    namespace: kube-system
    resourceVersion: "449"
    selfLink: /api/v1/namespaces/kube-system/configmaps/fluentd-gcp-config-v1.2.6
    uid: 7b789e07-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: ConfigMap
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm_799a1","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:47:01Z","renewTime":"2020-05-02T07:07:06Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: gke-common-webhook-lock
    namespace: kube-system
    resourceVersion: "13429719"
    selfLink: /api/v1/namespaces/kube-system/configmaps/gke-common-webhook-lock
    uid: 70c57740-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  data:
    NannyConfiguration: |-
      apiVersion: nannyconfig/v1alpha1
      kind: NannyConfiguration
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:05:12Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
      kubernetes.io/cluster-service: "true"
    name: heapster-config
    namespace: kube-system
    resourceVersion: "276"
    selfLink: /api/v1/namespaces/kube-system/configmaps/heapster-config
    uid: 75d74497-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: ConfigMap
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm_4f522","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:47:04Z","renewTime":"2020-05-02T07:07:06Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:05:27Z"
    name: ingress-gce-lock
    namespace: kube-system
    resourceVersion: "13429720"
    selfLink: /api/v1/namespaces/kube-system/configmaps/ingress-gce-lock
    uid: 7ecfa655-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  data:
    provider-uid: 43e918df9dbb1844
    uid: 43e918df9dbb1844
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:05:24Z"
    name: ingress-uid
    namespace: kube-system
    resourceVersion: "488"
    selfLink: /api/v1/namespaces/kube-system/configmaps/ingress-uid
    uid: 7cba833d-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:05:12Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
    name: kube-dns
    namespace: kube-system
    resourceVersion: "274"
    selfLink: /api/v1/namespaces/kube-system/configmaps/kube-dns
    uid: 759fa30c-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  data:
    linear: '{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}'
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:05:31Z"
    name: kube-dns-autoscaler
    namespace: kube-system
    resourceVersion: "613"
    selfLink: /api/v1/namespaces/kube-system/configmaps/kube-dns-autoscaler
    uid: 813437b7-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  data:
    NannyConfiguration: |-
      apiVersion: nannyconfig/v1alpha1
      kind: NannyConfiguration
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-04-01T22:47:47Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
      kubernetes.io/cluster-service: "true"
    name: metadata-agent-config
    namespace: kube-system
    resourceVersion: "4938072"
    selfLink: /api/v1/namespaces/kube-system/configmaps/metadata-agent-config
    uid: ceb7fba2-746a-11ea-b920-42010a8002b4
- apiVersion: v1
  data:
    NannyConfiguration: |-
      apiVersion: nannyconfig/v1alpha1
      kind: NannyConfiguration
  kind: ConfigMap
  metadata:
    creationTimestamp: "2020-03-15T10:05:12Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
      kubernetes.io/cluster-service: "true"
    name: metrics-server-config
    namespace: kube-system
    resourceVersion: "277"
    selfLink: /api/v1/namespaces/kube-system/configmaps/metrics-server-config
    uid: 75e34c02-66a4-11ea-b80b-42010a800288
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== endpoints manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      endpoints.kubernetes.io/last-change-trigger-time: "2020-05-02T06:58:31Z"
    creationTimestamp: "2020-03-17T16:59:54Z"
    labels:
      run: essbaseservice
    name: essbaseservice
    namespace: default
    resourceVersion: "13428052"
    selfLink: /api/v1/namespaces/default/endpoints/essbaseservice
    uid: b94c7b8d-6870-11ea-b004-42010a80008c
  subsets:
  - addresses:
    - ip: 10.4.0.31
      nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
      targetRef:
        kind: Pod
        name: essbaseservice-f5f56b5b-fbzlt
        namespace: default
        resourceVersion: "13428050"
        uid: 542f6629-8c42-11ea-b920-42010a8002b4
    ports:
    - port: 8080
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    creationTimestamp: "2020-03-15T10:04:50Z"
    name: kubernetes
    namespace: default
    resourceVersion: "147"
    selfLink: /api/v1/namespaces/default/endpoints/kubernetes
    uid: 689a5087-66a4-11ea-b80b-42010a800288
  subsets:
  - addresses:
    - ip: 104.197.210.17
    ports:
    - name: https
      port: 443
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      endpoints.kubernetes.io/last-change-trigger-time: "2020-04-21T13:09:53Z"
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: glbc
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: GLBCDefaultBackend
    name: default-http-backend
    namespace: kube-system
    resourceVersion: "10399114"
    selfLink: /api/v1/namespaces/kube-system/endpoints/default-http-backend
    uid: 77576eac-66a4-11ea-b80b-42010a800288
  subsets:
  - addresses:
    - ip: 10.4.0.10
      nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
      targetRef:
        kind: Pod
        name: l7-default-backend-8f479dd9-gkfqd
        namespace: kube-system
        resourceVersion: "10399113"
        uid: eb573b82-83d0-11ea-b920-42010a8002b4
    ports:
    - name: http
      port: 8080
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:47:01Z","renewTime":"2020-05-02T07:07:10Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:05:15Z"
    name: gcp-controller-manager
    namespace: kube-system
    resourceVersion: "13429735"
    selfLink: /api/v1/namespaces/kube-system/endpoints/gcp-controller-manager
    uid: 77d81c29-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      endpoints.kubernetes.io/last-change-trigger-time: "2020-04-21T13:10:29Z"
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Heapster
    name: heapster
    namespace: kube-system
    resourceVersion: "10399250"
    selfLink: /api/v1/namespaces/kube-system/endpoints/heapster
    uid: 78a81f26-66a4-11ea-b80b-42010a800288
  subsets:
  - addresses:
    - ip: 10.4.0.4
      nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
      targetRef:
        kind: Pod
        name: heapster-gke-7df9bb754d-bvbv6
        namespace: kube-system
        resourceVersion: "10399249"
        uid: eb1368d9-83d0-11ea-b920-42010a8002b4
    ports:
    - port: 8082
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm_a1486315-746a-11ea-9c0d-42010a8002b4","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:46:57Z","renewTime":"2020-05-02T07:07:10Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:04:50Z"
    name: kube-controller-manager
    namespace: kube-system
    resourceVersion: "13429732"
    selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
    uid: 68d7114d-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: Endpoints
  metadata:
    creationTimestamp: "2020-03-15T10:05:13Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: KubeDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "10572313"
    selfLink: /api/v1/namespaces/kube-system/endpoints/kube-dns
    uid: 769ffa77-66a4-11ea-b80b-42010a800288
  subsets:
  - addresses:
    - ip: 10.4.0.6
      nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
      targetRef:
        kind: Pod
        name: kube-dns-5877696fb4-mjdth
        namespace: kube-system
        resourceVersion: "10399306"
        uid: eb4adcd6-83d0-11ea-b920-42010a8002b4
    ports:
    - name: dns
      port: 53
      protocol: UDP
    - name: dns-tcp
      port: 53
      protocol: TCP
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm_a76be2a6-746a-11ea-a288-42010a8002b4","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:46:59Z","renewTime":"2020-05-02T07:07:10Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:04:50Z"
    name: kube-scheduler
    namespace: kube-system
    resourceVersion: "13429731"
    selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler
    uid: 68bce965-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"gke-3f25c209473ab1b55f0e-c0c1-a0ac-vm","leaseDurationSeconds":15,"acquireTime":"2020-04-01T22:47:15Z","renewTime":"2020-05-02T07:07:09Z","leaderTransitions":3}'
    creationTimestamp: "2020-03-15T10:05:20Z"
    name: managed-certificate-controller
    namespace: kube-system
    resourceVersion: "13429730"
    selfLink: /api/v1/namespaces/kube-system/endpoints/managed-certificate-controller
    uid: 7a6827f5-66a4-11ea-b80b-42010a800288
- apiVersion: v1
  kind: Endpoints
  metadata:
    annotations:
      endpoints.kubernetes.io/last-change-trigger-time: "2020-04-21T13:09:48Z"
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Metrics-server
    name: metrics-server
    namespace: kube-system
    resourceVersion: "10399091"
    selfLink: /api/v1/namespaces/kube-system/endpoints/metrics-server
    uid: 7a0bc458-66a4-11ea-b80b-42010a800288
  subsets:
  - addresses:
    - ip: 10.4.0.3
      nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
      targetRef:
        kind: Pod
        name: metrics-server-v0.3.1-5c6fbf777-hqvcs
        namespace: kube-system
        resourceVersion: "10399089"
        uid: eb7cf390-83d0-11ea-b920-42010a8002b4
    ports:
    - port: 443
      protocol: TCP
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== events manifests ========

apiVersion: v1
items:
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:58:29Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    resourceVersion: "13428038"
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:58:29Z"
  message: Successfully assigned default/essbaseservice-f5f56b5b-fbzlt to gke-indra20k8-default-pool-b615b32b-kb0v
  metadata:
    creationTimestamp: "2020-05-02T06:58:29Z"
    name: essbaseservice-f5f56b5b-fbzlt.160b23d9485d13fa
    namespace: default
    resourceVersion: "29254"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b-fbzlt.160b23d9485d13fa
    uid: 543ae1a8-8c42-11ea-b920-42010a8002b4
  reason: Scheduled
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: default-scheduler
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{essbaseservice}
    kind: Pod
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    resourceVersion: "13428042"
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:58:30Z"
  message: Container image "gcr.io/indrasolproj-2020/essbaseservice:v23.1" already
    present on machine
  metadata:
    creationTimestamp: "2020-05-02T06:58:30Z"
    name: essbaseservice-f5f56b5b-fbzlt.160b23d97a5b5a45
    namespace: default
    resourceVersion: "29255"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b-fbzlt.160b23d97a5b5a45
    uid: 54bad02a-8c42-11ea-b920-42010a8002b4
  reason: Pulled
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: gke-indra20k8-default-pool-b615b32b-kb0v
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{essbaseservice}
    kind: Pod
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    resourceVersion: "13428042"
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:58:30Z"
  message: Created container essbaseservice
  metadata:
    creationTimestamp: "2020-05-02T06:58:30Z"
    name: essbaseservice-f5f56b5b-fbzlt.160b23d97eb4372c
    namespace: default
    resourceVersion: "29256"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b-fbzlt.160b23d97eb4372c
    uid: 54c5e50e-8c42-11ea-b920-42010a8002b4
  reason: Created
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: gke-indra20k8-default-pool-b615b32b-kb0v
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{essbaseservice}
    kind: Pod
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    resourceVersion: "13428042"
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:58:30Z"
  message: Started container essbaseservice
  metadata:
    creationTimestamp: "2020-05-02T06:58:30Z"
    name: essbaseservice-f5f56b5b-fbzlt.160b23d98b83a085
    namespace: default
    resourceVersion: "29257"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b-fbzlt.160b23d98b83a085
    uid: 54e6b09a-8c42-11ea-b920-42010a8002b4
  reason: Started
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: gke-indra20k8-default-pool-b615b32b-kb0v
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:49:00Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{essbaseservice}
    kind: Pod
    name: essbaseservice-f5f56b5b-svw9m
    namespace: default
    resourceVersion: "12162047"
    uid: 48e6335b-88b1-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:49:00Z"
  message: Stopping container essbaseservice
  metadata:
    creationTimestamp: "2020-05-02T06:49:00Z"
    name: essbaseservice-f5f56b5b-svw9m.160b2354a75bf46e
    namespace: default
    resourceVersion: "29246"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b-svw9m.160b2354a75bf46e
    uid: 00b3a05a-8c41-11ea-b920-42010a8002b4
  reason: Killing
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: kubelet
    host: gke-indra20k8-default-pool-b615b32b-kb0v
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:49:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: essbaseservice-f5f56b5b
    namespace: default
    resourceVersion: "13426182"
    uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:49:00Z"
  message: 'Deleted pod: essbaseservice-f5f56b5b-svw9m'
  metadata:
    creationTimestamp: "2020-05-02T06:49:00Z"
    name: essbaseservice-f5f56b5b.160b2354a7f83dfb
    namespace: default
    resourceVersion: "29247"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b.160b2354a7f83dfb
    uid: 00b68340-8c41-11ea-b920-42010a8002b4
  reason: SuccessfulDelete
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:58:29Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: essbaseservice-f5f56b5b
    namespace: default
    resourceVersion: "13428034"
    uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
  kind: Event
  lastTimestamp: "2020-05-02T06:58:29Z"
  message: 'Created pod: essbaseservice-f5f56b5b-fbzlt'
  metadata:
    creationTimestamp: "2020-05-02T06:58:29Z"
    name: essbaseservice-f5f56b5b.160b23d944fda648
    namespace: default
    resourceVersion: "29253"
    selfLink: /api/v1/namespaces/default/events/essbaseservice-f5f56b5b.160b23d944fda648
    uid: 54333644-8c42-11ea-b920-42010a8002b4
  reason: SuccessfulCreate
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2020-04-27T18:02:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: essbaseservice
    namespace: default
    resourceVersion: "13428033"
    uid: 8dfc8260-6870-11ea-b004-42010a80008c
  kind: Event
  lastTimestamp: "2020-05-02T06:58:29Z"
  message: Scaled up replica set essbaseservice-f5f56b5b to 1
  metadata:
    creationTimestamp: "2020-05-02T06:58:29Z"
    name: essbaseservice.1609bf30da0eb497
    namespace: default
    resourceVersion: "29252"
    selfLink: /api/v1/namespaces/default/events/essbaseservice.1609bf30da0eb497
    uid: 542e22ab-8c42-11ea-b920-42010a8002b4
  reason: ScalingReplicaSet
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2020-05-02T06:49:00Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: essbaseservice
    namespace: default
    resourceVersion: "13426181"
    uid: 8dfc8260-6870-11ea-b004-42010a80008c
  kind: Event
  lastTimestamp: "2020-05-02T06:49:00Z"
  message: Scaled down replica set essbaseservice-f5f56b5b to 0
  metadata:
    creationTimestamp: "2020-05-02T06:49:00Z"
    name: essbaseservice.160b2354a62cb72e
    namespace: default
    resourceVersion: "29245"
    selfLink: /api/v1/namespaces/default/events/essbaseservice.160b2354a62cb72e
    uid: 00b07e10-8c41-11ea-b920-42010a8002b4
  reason: ScalingReplicaSet
  reportingComponent: ""
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== limitranges manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: LimitRange
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"LimitRange","metadata":{"annotations":{},"name":"limits","namespace":"default"},"spec":{"limits":[{"defaultRequest":{"cpu":"100m"},"type":"Container"}]}}
    creationTimestamp: "2020-03-15T10:05:10Z"
    name: limits
    namespace: default
    resourceVersion: "271"
    selfLink: /api/v1/namespaces/default/limitranges/limits
    uid: 74e134f0-66a4-11ea-b80b-42010a800288
  spec:
    limits:
    - defaultRequest:
        cpu: 100m
      type: Container
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== namespaces manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: "2020-03-15T10:04:50Z"
    name: default
    resourceVersion: "143"
    selfLink: /api/v1/namespaces/default
    uid: 689491b3-66a4-11ea-b80b-42010a800288
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    name: kube-node-lease
    resourceVersion: "34"
    selfLink: /api/v1/namespaces/kube-node-lease
    uid: 67066ac4-66a4-11ea-b80b-42010a800288
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
- apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    name: kube-public
    resourceVersion: "30"
    selfLink: /api/v1/namespaces/kube-public
    uid: 66ff2d0d-66a4-11ea-b80b-42010a800288
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
- apiVersion: v1
  kind: Namespace
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"name":"kube-system"}}
    creationTimestamp: "2020-03-15T10:04:47Z"
    name: kube-system
    resourceVersion: "167"
    selfLink: /api/v1/namespaces/kube-system
    uid: 66f7f024-66a4-11ea-b80b-42010a800288
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== nodes manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      container.googleapis.com/instance_id: "5140598096185740963"
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: "2020-03-17T16:27:54Z"
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/fluentd-ds-ready: "true"
      beta.kubernetes.io/instance-type: n1-standard-1
      beta.kubernetes.io/os: linux
      cloud.google.com/gke-nodepool: default-pool
      cloud.google.com/gke-os-distribution: cos
      failure-domain.beta.kubernetes.io/region: us-central1
      failure-domain.beta.kubernetes.io/zone: us-central1-c
      kubernetes.io/arch: amd64
      kubernetes.io/hostname: gke-indra20k8-default-pool-b615b32b-kb0v
      kubernetes.io/os: linux
    name: gke-indra20k8-default-pool-b615b32b-kb0v
    resourceVersion: "13429715"
    selfLink: /api/v1/nodes/gke-indra20k8-default-pool-b615b32b-kb0v
    uid: 4108a29a-686c-11ea-b004-42010a80008c
  spec:
    podCIDR: 10.4.0.0/24
    providerID: gce://indrasolproj-2020/us-central1-c/gke-indra20k8-default-pool-b615b32b-kb0v
  status:
    addresses:
    - address: 10.128.0.6
      type: InternalIP
    - address: 104.197.156.53
      type: ExternalIP
    - address: gke-indra20k8-default-pool-b615b32b-kb0v.us-central1-c.c.indrasolproj-2020.internal
      type: InternalDNS
    - address: gke-indra20k8-default-pool-b615b32b-kb0v.us-central1-c.c.indrasolproj-2020.internal
      type: Hostname
    allocatable:
      attachable-volumes-gce-pd: "127"
      cpu: 940m
      ephemeral-storage: "47093746742"
      hugepages-2Mi: "0"
      memory: 2701244Ki
      pods: "110"
    capacity:
      attachable-volumes-gce-pd: "127"
      cpu: "1"
      ephemeral-storage: 98868448Ki
      hugepages-2Mi: "0"
      memory: 3786684Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: docker is functioning properly
      reason: NoFrequentDockerRestart
      status: "False"
      type: FrequentDockerRestart
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: containerd is functioning properly
      reason: NoFrequentContainerdRestart
      status: "False"
      type: FrequentContainerdRestart
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kernel has no deadlock
      reason: KernelHasNoDeadlock
      status: "False"
      type: KernelDeadlock
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: Filesystem is not read-only
      reason: FilesystemIsNotReadOnly
      status: "False"
      type: ReadonlyFilesystem
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: docker overlay2 is functioning properly
      reason: NoCorruptDockerOverlay2
      status: "False"
      type: CorruptDockerOverlay2
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: node is functioning properly
      reason: NoFrequentUnregisterNetDevice
      status: "False"
      type: FrequentUnregisterNetDevice
    - lastHeartbeatTime: "2020-05-02T07:07:04Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet is functioning properly
      reason: NoFrequentKubeletRestart
      status: "False"
      type: FrequentKubeletRestart
    - lastHeartbeatTime: "2020-04-01T22:47:08Z"
      lastTransitionTime: "2020-04-01T22:47:08Z"
      message: NodeController create implicit route
      reason: RouteCreated
      status: "False"
      type: NetworkUnavailable
    - lastHeartbeatTime: "2020-05-02T07:06:57Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: "2020-05-02T07:06:57Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: "2020-05-02T07:06:57Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has sufficient PID available
      reason: KubeletHasSufficientPID
      status: "False"
      type: PIDPressure
    - lastHeartbeatTime: "2020-05-02T07:06:57Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet is posting ready status. AppArmor enabled
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:79ddc530f0e558da80c3857c2e02d8b6dcce64c4c875fb94e3a420f53c502492
      - gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      sizeBytes: 413364992
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:7a485bd251330431a6591f9c190979743f058340c37e4234e771b6c9df7ec093
      - gcr.io/indrasolproj-2020/essbaseservice:v20.3
      sizeBytes: 152863693
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:1fd7293607be9d2c7b59c38b242244064a1ba9f260600bc8d6126a5eeaa78ab8
      - gcr.io/indrasolproj-2020/essbaseservice:v20.2
      sizeBytes: 152862650
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:0d3db443f4d9ae0fd6cd45bd3b91c867800dcce4f3852d66b591d31c3e91e16e
      - gcr.io/indrasolproj-2020/essbaseservice:v20.1
      sizeBytes: 152862641
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:0b4ed73d67ddb35368caa6c45bf71b584f1b79c33341e9ec363539b6a638c15b
      - gcr.io/indrasolproj-2020/essbaseservice:v20
      sizeBytes: 152862592
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:38f3fbe38ea655a58a39c393170d0ac78fd313b4860456f48db54cfe93d87370
      - gcr.io/indrasolproj-2020/essbaseservice:v19.1
      - gcr.io/indrasolproj-2020/essbaseservice:v19.2
      sizeBytes: 152862592
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:b7380aff14593768b01365b2f270ce7b92468f34dac527fb1a5777cd436c0a4b
      - gcr.io/indrasolproj-2020/essbaseservice:v18
      sizeBytes: 152858888
    - names:
      - k8s.gcr.io/fluentd-elasticsearch@sha256:5a704c386f66bb3c24e3bcf2e94269c426f1473100fcd37b31579ca8b709c558
      - k8s.gcr.io/fluentd-elasticsearch:v2.4.0
      sizeBytes: 139904122
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:c45933c5fe3f153ede7170af94e7cf97a4547e7c0dadce1828736a84a0625b6d
      - gcr.io/indrasolproj-2020/essbaseservice:v23.1
      sizeBytes: 130194273
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:837f26308b8bf131be958c475273fe251ff8f1317b4b9566c3a03ced323fa98f
      - gcr.io/indrasolproj-2020/essbaseservice:v23
      sizeBytes: 130193454
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:9bd5d07f24d170219e008f0769ec695d45d4b0fac6831356585a2389584bae2d
      - gcr.io/indrasolproj-2020/essbaseservice:v22
      sizeBytes: 130191475
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:b1ff9783ed029adc857741360c2b4806b009e22c4d551cee75df622090cc4d37
      - gcr.io/indrasolproj-2020/essbaseservice:v20.4
      sizeBytes: 130186930
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:80ff5f72f920551e2addd361ffb3508e12eaa7ce4402f9a4646498068e60d6b2
      - gcr.io/indrasolproj-2020/essbaseservice:v21
      sizeBytes: 130186431
    - names:
      - k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747
      - k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
      sizeBytes: 121711221
    - names:
      - k8s.gcr.io/node-problem-detector@sha256:9d54df11804a862c54276648702a45a6a0027a9d930a86becd69c34cc84bf510
      - k8s.gcr.io/node-problem-detector:v0.6.3
      sizeBytes: 93550819
    - names:
      - k8s.gcr.io/fluentd-gcp-scaler@sha256:4f28f10fb89506768910b858f7a18ffb996824a16d70d5ac895e49687df9ff58
      - k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      sizeBytes: 90498960
    - names:
      - k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:a13c60e2a9d49f965095a1e003388926f3f2a6189ed4aecb1541f114c955f8ec
      - k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      sizeBytes: 86980681
    - names:
      - gke.gcr.io/heapster@sha256:26891d2f8c22407a772b911aed912993e1c530128ebb2d3561b49fc16a52d765
      - gke.gcr.io/heapster:v1.7.2
      sizeBytes: 84338494
    - names:
      - gke.gcr.io/kube-proxy:v1.14.10-gke.27
      - k8s.gcr.io/kube-proxy:v1.14.10-gke.27
      sizeBytes: 83627412
    - names:
      - k8s.gcr.io/kube-addon-manager@sha256:382c220b3531d9f95bf316a16b7282cc2ef929cd8a89a9dd3f5933edafc41a8e
      - k8s.gcr.io/kube-addon-manager:v9.0.1
      sizeBytes: 83076194
    - names:
      - gcr.io/stackdriver-agents/metadata-agent-go@sha256:ca13ec92f6e41befff6ca2a578ee7951edb1e49a566430f816f9a8acf631a62a
      - gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      sizeBytes: 82131866
    - names:
      - k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:e55cbd5361a86bf0a01bfeaca2e958e15571f1e741356eab83bb444a13020d4c
      - k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      sizeBytes: 79319492
    - names:
      - k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:0a70a8a9ae8cfe752021de84f13b3ecd109d9b5fbe3f1541c52fcd1d4c2c0b45
      - k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      sizeBytes: 77756591
    - names:
      - k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521
      - k8s.gcr.io/heapster-amd64:v1.6.0-beta.1
      sizeBytes: 76016169
    - names:
      - k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca
      - k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3
      sizeBytes: 71797285
    nodeInfo:
      architecture: amd64
      bootID: 6e01c85a-6604-41fa-8ab3-7d2654aa7225
      containerRuntimeVersion: docker://18.9.7
      kernelVersion: 4.14.138+
      kubeProxyVersion: v1.14.10-gke.27
      kubeletVersion: v1.14.10-gke.27
      machineID: f2e2dfda9375c4200e66b163e9949ca9
      operatingSystem: linux
      osImage: Container-Optimized OS from Google
      systemUUID: F2E2DFDA-9375-C420-0E66-B163E9949CA9
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== pods manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        essbaseservice'
    creationTimestamp: "2020-05-02T06:58:29Z"
    generateName: essbaseservice-f5f56b5b-
    labels:
      pod-template-hash: f5f56b5b
      run: essbaseservice
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: essbaseservice-f5f56b5b
      uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
    resourceVersion: "13428050"
    selfLink: /api/v1/namespaces/default/pods/essbaseservice-f5f56b5b-fbzlt
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  spec:
    containers:
    - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
      imagePullPolicy: IfNotPresent
      name: essbaseservice
      ports:
      - containerPort: 8080
        protocol: TCP
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-l6wj4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-l6wj4
      secret:
        defaultMode: 420
        secretName: default-token-l6wj4
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://558d928eb17333048815dc9ebfde2ff27bb6c4f8755374a78cb0f9d4baa2af39
      image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
      imageID: docker-pullable://gcr.io/indrasolproj-2020/essbaseservice@sha256:c45933c5fe3f153ede7170af94e7cf97a4547e7c0dadce1828736a84a0625b6d
      lastState: {}
      name: essbaseservice
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-05-02T06:58:30Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.31
    qosClass: Burstable
    startTime: "2020-05-02T06:58:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: event-exporter-v0.2.5-7df89f4b8f-
    labels:
      k8s-app: event-exporter
      pod-template-hash: 7df89f4b8f
      version: v0.2.5
    name: event-exporter-v0.2.5-7df89f4b8f-vgtt4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: event-exporter-v0.2.5-7df89f4b8f
      uid: 78c873a9-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399193"
    selfLink: /api/v1/namespaces/kube-system/pods/event-exporter-v0.2.5-7df89f4b8f-vgtt4
    uid: eaf8601d-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /event-exporter
      - -sink-opts=-stackdriver-resource-model=new
      image: k8s.gcr.io/event-exporter:v0.2.5
      imagePullPolicy: IfNotPresent
      name: event-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-x58h2
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-x58h2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: event-exporter-sa
    serviceAccountName: event-exporter-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: ssl-certs
    - name: event-exporter-sa-token-x58h2
      secret:
        defaultMode: 420
        secretName: event-exporter-sa-token-x58h2
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://bd39da0fc6ce9c762d1d815411a1d7b59fd371028a04b7d4f0582c3a565d6d82
      image: k8s.gcr.io/event-exporter:v0.2.5
      imageID: docker-pullable://k8s.gcr.io/event-exporter@sha256:06acf489ab092b4fb49273e426549a52c0fcd1dbcb67e03d5935b5ee1a899c3e
      lastState: {}
      name: event-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:14Z"
    - containerID: docker://605ef115da9546ea390bd5afaf03021e4c71ff3aba2ad1a43daf2993098be146
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:15Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.7
    qosClass: BestEffort
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: fluentd-gcp-scaler-54ccb89d5-
    labels:
      k8s-app: fluentd-gcp-scaler
      pod-template-hash: 54ccb89d5
    name: fluentd-gcp-scaler-54ccb89d5-9jv5d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: fluentd-gcp-scaler-54ccb89d5
      uid: 7b7d4c47-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399094"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-54ccb89d5-9jv5d
    uid: eafc3194-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /scaler.sh
      - --ds-name=fluentd-gcp-v3.1.1
      - --scaling-policy=fluentd-gcp-scaling-policy
      env:
      - name: CPU_REQUEST
        value: 100m
      - name: MEMORY_REQUEST
        value: 200Mi
      - name: CPU_LIMIT
        value: "1"
      - name: MEMORY_LIMIT
        value: 500Mi
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      imagePullPolicy: IfNotPresent
      name: fluentd-gcp-scaler
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-scaler-token-8gdvq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp-scaler
    serviceAccountName: fluentd-gcp-scaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: fluentd-gcp-scaler-token-8gdvq
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-scaler-token-8gdvq
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d10b531483cfd82bcc393cb0f7e88a28a2c5a5756dfbae91427cb7b1594506d7
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      imageID: docker-pullable://k8s.gcr.io/fluentd-gcp-scaler@sha256:4f28f10fb89506768910b858f7a18ffb996824a16d70d5ac895e49687df9ff58
      lastState: {}
      name: fluentd-gcp-scaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:47Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.9
    qosClass: BestEffort
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      EnableKnativeConfig: "false"
      EnableNodeJournal: "false"
      EnablePodSecurityPolicy: "false"
      PodLogEnabled: "false"
      SystemOnlyLogging: "false"
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-04-01T22:47:56Z"
    generateName: fluentd-gcp-v3.1.1-
    labels:
      controller-revision-hash: 57d5cdd48
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "3"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1-7wtmz
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.1.1
      uid: 779ca16d-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399163"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.1.1-7wtmz
    uid: d476410f-746a-11ea-b920-42010a8002b4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-indra20k8-default-pool-b615b32b-kb0v
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |2

            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
              rm -rf /var/run/google-fluentd/buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/google-fluentd
        name: varrun
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-85hzc
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-85hzc
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run/google-fluentd
        type: ""
      name: varrun
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-v1.2.6
      name: config-volume
    - name: fluentd-gcp-token-85hzc
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-85hzc
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-01T22:47:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-01T22:47:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9cbb789a838ed5a8c954c9a1710799d8cb45f2d065f979da2bc8f81dedda6e24
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:79ddc530f0e558da80c3857c2e02d8b6dcce64c4c875fb94e3a420f53c502492
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:04Z"
    - containerID: docker://95e4822e75901337bfd296657da7446d106a92441f870701ba0f0a9b7b1c074b
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:05Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-04-01T22:47:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: heapster-gke-7df9bb754d-
    labels:
      k8s-app: heapster
      pod-template-hash: 7df9bb754d
      version: v1.7.2
    name: heapster-gke-7df9bb754d-bvbv6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: heapster-gke-7df9bb754d
      uid: cf396f60-746a-11ea-b920-42010a8002b4
    resourceVersion: "10399249"
    selfLink: /api/v1/namespaces/kube-system/pods/heapster-gke-7df9bb754d-bvbv6
    uid: eb1368d9-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /heapster
      - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
      - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
      image: gke.gcr.io/heapster:v1.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8082
          scheme: HTTP
        initialDelaySeconds: 180
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: heapster
      resources:
        limits:
          cpu: 13m
          memory: 120Mi
        requests:
          cpu: 13m
          memory: 120Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    - command:
      - /monitor
      - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prom-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=10m
      - --extra-cpu=0.5m
      - --memory=100Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=heapster-gke
      - --container=heapster
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.3
      imagePullPolicy: IfNotPresent
      name: heapster-nanny
      resources:
        limits:
          cpu: 50m
          memory: 92560Ki
        requests:
          cpu: 50m
          memory: 92560Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: heapster-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      supplementalGroups:
      - 65534
    serviceAccount: heapster
    serviceAccountName: heapster
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: heapster-config
      name: heapster-config-volume
    - name: heapster-token-x8jx5
      secret:
        defaultMode: 420
        secretName: heapster-token-x8jx5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://92050393ea4f667283a83e12320ae4a7999765d5d66d6ec275673de73fc1f888
      image: gke.gcr.io/heapster:v1.7.2
      imageID: docker-pullable://gke.gcr.io/heapster@sha256:26891d2f8c22407a772b911aed912993e1c530128ebb2d3561b49fc16a52d765
      lastState: {}
      name: heapster
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:10Z"
    - containerID: docker://7f9d5bdb7565ca69ab2e44314c2b79385454f8cc3b343b95f076b456b99a245a
      image: k8s.gcr.io/addon-resizer:1.8.3
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:07353f7b26327f0d933515a22b1de587b040d3d85c464ea299c1b9f242529326
      lastState: {}
      name: heapster-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:29Z"
    - containerID: docker://c9dd8d9300e193b31fc91ac59f830e082e13fe7d40bd9037970356f17cf644b7
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prom-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:12Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.4
    qosClass: Burstable
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: kube-dns-5877696fb4-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5877696fb4
    name: kube-dns-5877696fb4-mjdth
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-5877696fb4
      uid: 76c1c78a-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399306"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-5877696fb4-mjdth
    uid: eb4adcd6-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - args:
      - --domain=cluster.local.
      - --dns-port=10053
      - --config-dir=/kube-dns-config
      - --v=2
      env:
      - name: PROMETHEUS_PORT
        value: "10055"
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/kubedns
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kubedns
      ports:
      - containerPort: 10053
        name: dns-local
        protocol: UDP
      - containerPort: 10053
        name: dns-tcp-local
        protocol: TCP
      - containerPort: 10055
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /kube-dns-config
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - args:
      - -v=2
      - -logtostderr
      - -configDir=/etc/k8s/dns/dnsmasq-nanny
      - -restartDnsmasq=true
      - --
      - -k
      - --cache-size=1000
      - --no-negcache
      - --log-facility=-
      - --server=/cluster.local/127.0.0.1#10053
      - --server=/in-addr.arpa/127.0.0.1#10053
      - --server=/ip6.arpa/127.0.0.1#10053
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/dnsmasq
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dnsmasq
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      resources:
        requests:
          cpu: 150m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/k8s/dns/dnsmasq-nanny
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - args:
      - --v=2
      - --logtostderr
      - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
      - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /metrics
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: sidecar
      ports:
      - containerPort: 10054
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - command:
      - /monitor
      - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      - --v=2
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-dns
    serviceAccountName: kube-dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-dns
        optional: true
      name: kube-dns-config
    - name: kube-dns-token-2j6rq
      secret:
        defaultMode: 420
        secretName: kube-dns-token-2j6rq
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://3b1616a4ae31d4aa25f5d6a7204e1f11b6b5a89a11cfc13d94c60d1b282fa690
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:0a70a8a9ae8cfe752021de84f13b3ecd109d9b5fbe3f1541c52fcd1d4c2c0b45
      lastState: {}
      name: dnsmasq
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:26Z"
    - containerID: docker://97675a961edbfed4bee6ff276a0e0516905880ee525fe73dbd8b650a61442f7e
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:a13c60e2a9d49f965095a1e003388926f3f2a6189ed4aecb1541f114c955f8ec
      lastState: {}
      name: kubedns
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:12Z"
    - containerID: docker://328b783ecd54e34b14bc93c745face1c3bff94cebeba9cdb578815034bc24485
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:aca8ef83a7fae83f1f8583e978dd4d1ff655b9f2ca0a76bda5edce6d8965bdf2
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:34Z"
    - containerID: docker://ec50a57b02f86fa43abffa1c2fadfc989288f5ee6bbfd43d66c8909a79205e70
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:e55cbd5361a86bf0a01bfeaca2e958e15571f1e741356eab83bb444a13020d4c
      lastState: {}
      name: sidecar
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:31Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.6
    qosClass: Burstable
    startTime: "2020-04-21T13:09:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: kube-dns-autoscaler-8687c64fc-
    labels:
      k8s-app: kube-dns-autoscaler
      pod-template-hash: 8687c64fc
    name: kube-dns-autoscaler-8687c64fc-rbqnd
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-autoscaler-8687c64fc
      uid: 7777872f-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399081"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-8687c64fc-rbqnd
    uid: eb59002c-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /cluster-proportional-autoscaler
      - --namespace=kube-system
      - --configmap=kube-dns-autoscaler
      - --target=Deployment/kube-dns
      - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
      - --logtostderr=true
      - --v=2
      image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
      imagePullPolicy: IfNotPresent
      name: autoscaler
      resources:
        requests:
          cpu: 20m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-autoscaler-token-mfpqp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      supplementalGroups:
      - 65534
    serviceAccount: kube-dns-autoscaler
    serviceAccountName: kube-dns-autoscaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-dns-autoscaler-token-mfpqp
      secret:
        defaultMode: 420
        secretName: kube-dns-autoscaler-token-mfpqp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:47Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:47Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6aec47b65d9388c5b7819c8246f19251b7d64a78b4d5ff73cfbf206d95b38acb
      image: asia.gcr.io/gke-release-staging/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
      imageID: docker-pullable://asia.gcr.io/gke-release-staging/cluster-proportional-autoscaler-amd64@sha256:e3f48b3d1e49cfa3e7f002020769c9cd01cd0e77bbc99dc133c7ab0f8097e989
      lastState: {}
      name: autoscaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:45Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.5
    qosClass: Burstable
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: d216a501cc256e4968139420d5d29855
      kubernetes.io/config.mirror: d216a501cc256e4968139420d5d29855
      kubernetes.io/config.seen: "2020-04-21T13:09:35.838830462Z"
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-04-21T13:09:41Z"
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-indra20k8-default-pool-b615b32b-kb0v
    namespace: kube-system
    resourceVersion: "10399072"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-indra20k8-default-pool-b615b32b-kb0v
    uid: 5cace7ba-83d1-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://104.197.210.17 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.4.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,TaintBasedEvictions=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: gke.gcr.io/kube-proxy:v1.14.10-gke.27
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://aa929b8303f213bc26384a2ac46911af7be66dd6aa899b0ec3134d779d591a47
      image: gke.gcr.io/kube-proxy:v1.14.10-gke.27
      imageID: docker://sha256:4c5288b3ecb59693e446354cd4ef1ed45cce9885ce3f6fdba66736aff391698a
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:38Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-03-17T16:27:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: l7-default-backend-8f479dd9-
    labels:
      k8s-app: glbc
      name: glbc
      pod-template-hash: 8f479dd9
    name: l7-default-backend-8f479dd9-gkfqd
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: l7-default-backend-8f479dd9
      uid: 77042a48-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399113"
    selfLink: /api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-gkfqd
    uid: eb573b82-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - image: k8s.gcr.io/defaultbackend-amd64:1.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: default-http-backend
      ports:
      - containerPort: 8080
        protocol: TCP
      resources:
        limits:
          cpu: 10m
          memory: 20Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-22rgh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-22rgh
      secret:
        defaultMode: 420
        secretName: default-token-22rgh
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://39ff419cc3d8f57127d33f6b73d5580b91a6f72be2df935f1f7bb718e18bb6f7
      image: k8s.gcr.io/defaultbackend-amd64:1.5
      imageID: docker-pullable://k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7
      lastState: {}
      name: default-http-backend
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:52Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.10
    qosClass: Guaranteed
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: metrics-server-v0.3.1-5c6fbf777-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5c6fbf777
      version: v0.3.1
    name: metrics-server-v0.3.1-5c6fbf777-hqvcs
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-v0.3.1-5c6fbf777
      uid: 83c10be5-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399089"
    selfLink: /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-5c6fbf777-hqvcs
    uid: eb7cf390-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /metrics-server
      - --metric-resolution=30s
      - --kubelet-port=10255
      - --deprecated-kubelet-completely-insecure=true
      - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imagePullPolicy: IfNotPresent
      name: metrics-server
      ports:
      - containerPort: 443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 43m
          memory: 55Mi
        requests:
          cpu: 43m
          memory: 55Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-x6d9m
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=40m
      - --extra-cpu=0.5m
      - --memory=35Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=metrics-server-v0.3.1
      - --container=metrics-server
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: gke.gcr.io/addon-resizer:1.8.4-gke.0
      imagePullPolicy: IfNotPresent
      name: metrics-server-nanny
      resources:
        limits:
          cpu: 100m
          memory: 300Mi
        requests:
          cpu: 5m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: metrics-server-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-x6d9m
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: metrics-server-config
      name: metrics-server-config-volume
    - name: metrics-server-token-x6d9m
      secret:
        defaultMode: 420
        secretName: metrics-server-token-x6d9m
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ec5dac4ebdf4b2003216a73807e8521c38d0d326dd344a06d0931e6b4cc34925
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imageID: docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:43Z"
    - containerID: docker://86b90f7f689f4851bcccdd8794f29ec8e65aada562a501fe069bd88b3af091d7
      image: asia.gcr.io/gke-release-staging/addon-resizer:1.8.4-gke.0
      imageID: docker-pullable://asia.gcr.io/gke-release-staging/addon-resizer@sha256:94e7e68175dfd18a9e3c31bc1f4a6ab19444efef47192f13b0e5af3b03dc04c6
      lastState: {}
      name: metrics-server-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:46Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.3
    qosClass: Burstable
    startTime: "2020-04-21T13:09:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-03-17T16:27:54Z"
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 6cbdc4dbd7
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-t84vf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 792a47e1-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399097"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-t84vf
    uid: 41174538-686c-11ea-b004-42010a80008c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-indra20k8-default-pool-b615b32b-kb0v
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
      - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      - --export-interval=120s
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-h7rkk
        readOnly: true
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=kubernetes.io/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
      - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
      - --stackdriver-prefix=kubernetes.io/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      - --monitored-resource-type-prefix=k8s_
      - --monitored-resource-labels=location=us-central1-c
      - --export-interval=120s
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-new-model
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-h7rkk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-h7rkk
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-h7rkk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://283f595d13e726142ccced8948db5d4af92770a54a46ae8974719c53a08819af
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:3216dd0e94d6911f6dc04f4258c0bf5cb1fff088ee2d3ce742ada490cbd5ca5c
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:44Z"
    - containerID: docker://d5aa585d6659ab602854e0122db19128eff1c55994cccee595322e59f7d7e26d
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:3216dd0e94d6911f6dc04f4258c0bf5cb1fff088ee2d3ce742ada490cbd5ca5c
      lastState: {}
      name: prometheus-to-sd-new-model
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:45Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-03-17T16:27:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: stackdriver-metadata-agent-cluster-level-865b464794-
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 865b464794
    name: stackdriver-metadata-agent-cluster-level-865b464794-n898v
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: stackdriver-metadata-agent-cluster-level-865b464794
      uid: d28677b2-746a-11ea-b920-42010a8002b4
    resourceVersion: "10399231"
    selfLink: /api/v1/namespaces/kube-system/pods/stackdriver-metadata-agent-cluster-level-865b464794-n898v
    uid: eb86efd1-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - args:
      - -logtostderr
      - -v=1
      env:
      - name: CLUSTER_NAME
        value: indra20k8
      - name: CLUSTER_LOCATION
        value: us-central1-c
      image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      imagePullPolicy: IfNotPresent
      name: metadata-agent
      resources:
        limits:
          cpu: 43m
          memory: 25Mi
        requests:
          cpu: 43m
          memory: 25Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ssl-certs
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metadata-agent-token-9jjpn
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=40m
      - --extra-cpu=0.5m
      - --memory=20Mi
      - --extra-memory=1Mi
      - --threshold=5
      - --deployment=stackdriver-metadata-agent-cluster-level
      - --container=metadata-agent
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.7
      imagePullPolicy: IfNotPresent
      name: metadata-agent-nanny
      resources:
        limits:
          cpu: 50m
          memory: 92560Ki
        requests:
          cpu: 50m
          memory: 92560Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: metadata-agent-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metadata-agent-token-9jjpn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metadata-agent
    serviceAccountName: metadata-agent
    terminationGracePeriodSeconds: 5
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: Directory
      name: ssl-certs
    - configMap:
        defaultMode: 420
        name: metadata-agent-config
      name: metadata-agent-config-volume
    - name: metadata-agent-token-9jjpn
      secret:
        defaultMode: 420
        secretName: metadata-agent-token-9jjpn
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://997c2aa1ec092a9d21b0d10674225f7a0fd25afb46af5a7bc627197fc05775df
      image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      imageID: docker-pullable://gcr.io/stackdriver-agents/metadata-agent-go@sha256:ca13ec92f6e41befff6ca2a578ee7951edb1e49a566430f816f9a8acf631a62a
      lastState: {}
      name: metadata-agent
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:04Z"
    - containerID: docker://9a45525e5d709927003c7542d8dd2d3e6d7dc96d9a86d7b48aa3dd5b1b7ec51c
      image: k8s.gcr.io/addon-resizer:1.8.7
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:30b3b12e471c534949e12d2da958fdf33848d153f2a0a88565bdef7ca999b5ad
      lastState: {}
      name: metadata-agent-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:24Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.2
    qosClass: Guaranteed
    startTime: "2020-04-21T13:09:37Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== resourcequotas manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    creationTimestamp: "2020-03-15T10:07:11Z"
    name: gke-resource-quotas
    namespace: default
    resourceVersion: "13428037"
    selfLink: /api/v1/namespaces/default/resourcequotas/gke-resource-quotas
    uid: bcb7e0bb-66a4-11ea-b80b-42010a800288
  spec:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
  status:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
    used:
      count/ingresses.extensions: "0"
      count/jobs.batch: "0"
      pods: "1"
      services: "2"
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    creationTimestamp: "2020-03-15T10:07:11Z"
    name: gke-resource-quotas
    namespace: kube-node-lease
    resourceVersion: "1117"
    selfLink: /api/v1/namespaces/kube-node-lease/resourcequotas/gke-resource-quotas
    uid: bcbcd7a0-66a4-11ea-b80b-42010a800288
  spec:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
  status:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
    used:
      count/ingresses.extensions: "0"
      count/jobs.batch: "0"
      pods: "0"
      services: "0"
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    creationTimestamp: "2020-03-15T10:07:12Z"
    name: gke-resource-quotas
    namespace: kube-public
    resourceVersion: "1125"
    selfLink: /api/v1/namespaces/kube-public/resourcequotas/gke-resource-quotas
    uid: bd4cfecf-66a4-11ea-b80b-42010a800288
  spec:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
  status:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
    used:
      count/ingresses.extensions: "0"
      count/jobs.batch: "0"
      pods: "0"
      services: "0"
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    creationTimestamp: "2020-03-15T10:07:13Z"
    name: gke-resource-quotas
    namespace: kube-system
    resourceVersion: "10399052"
    selfLink: /api/v1/namespaces/kube-system/resourcequotas/gke-resource-quotas
    uid: be028177-66a4-11ea-b80b-42010a800288
  spec:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
  status:
    hard:
      count/ingresses.extensions: "100"
      count/jobs.batch: 5k
      pods: "1500"
      services: "500"
    used:
      count/ingresses.extensions: "0"
      count/jobs.batch: "0"
      pods: "11"
      services: "4"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== secrets manifests ========

apiVersion: v1
items:
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: ZGVmYXVsdA==
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSmtaV1poZFd4MElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WldOeVpYUXVibUZ0WlNJNkltUmxabUYxYkhRdGRHOXJaVzR0YkRaM2FqUWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2laR1ZtWVhWc2RDSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqY3laR0l3WlRJNExUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHBrWldaaGRXeDBPbVJsWm1GMWJIUWlmUS5VVXZpRDJ6cDFBNExSdk9FM0JjWHJoVlZYSVVQRW5USTQzYzFxdGktajREQzc4OHhHejEzS1JfdFNmaVNHdFY3WnZRT3ZWR3ViWHJwaUo3bjFkbnZUTzJ0aWhwYVhnU1lfdk5PS25CajZBV1dHQlQ2T3BKNkhRWG5LdGlzM3prdkhQdUx6YXM3MDJ1YkdiZWIzMVhhVjB2OWlJdHVLT0lFaDMxcElYdGczRkc5U2ZBSHB5aU9TMUpCcXhfd1Jnb0xvQ0JIQkFlQk5vQUR4eEJEUFAzZGdqX2FkdUxCNkU3UjB3YjkzTHllNFJEZ18tRE42M2pSUGdfUjVfR0tfRVJNcENYT0h3bXp2RDJTeG5hNHVNWFB1Q2wzTzN2ZzhkQjM3STNEN3FaVTctMFVwS29yT0dQS2I0bGJPdlJpMklEcmZxWG1palZjN1VCeVhQeXFuN05NZ3c=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: 72db0e28-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default-token-l6wj4
    namespace: default
    resourceVersion: "263"
    selfLink: /api/v1/namespaces/default/secrets/default-token-l6wj4
    uid: 72e0c2c2-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1ub2RlLWxlYXNl
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFc1dlpHVXRiR1ZoYzJVaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sWTNKbGRDNXVZVzFsSWpvaVpHVm1ZWFZzZEMxMGIydGxiaTAxT0hjME5TSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMbTVoYldVaU9pSmtaV1poZFd4MElpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaU56SmpOMkZpWWpZdE5qWmhOQzB4TVdWaExXSTRNR0l0TkRJd01UQmhPREF3TWpnNElpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGJtOWtaUzFzWldGelpUcGtaV1poZFd4MEluMC5maXZlMTA4SlNYUkw3cW5PR3M4VFFEMndBUzdJTFhUVzZtUjI0aDZHRTV3YXpXS19pamxlei02TVMxN1l5dzA2ZnZQQVVhV0xHWEtXUl9fbkVxMEg4UXRxUFNDX3lTM3FWRWtOYzZxRGdvaEhueUgtUVZIYmJNaWxyLU45NG1IVW9yMWhXS09JN0FlSGcwTk8zUmpkR2tFUnBNV1hfV3d3dXFFT2RhQWNNS2pzTWlEc3dyWElMbDRlTkluMWxpa2NpTHhETmdrRTJIYU42UjZ3X2I4VmdpUHJNZngzNUJfSTlydWZtbzh6VlFYUGhiUFFQNDVGVlNHNVJySmJiWHQycEtWdVlkbWpjX29xM3dWbmN0UTktRndhcmdndHdhQXRuMGRBek0xeGY1TWJiRk9URDNoNWJOU3RDWG9qTldWSjhqWXVPX0VtMnFOVGQ5cmFocHl4ekE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: 72c7abb6-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default-token-58w45
    namespace: kube-node-lease
    resourceVersion: "262"
    selfLink: /api/v1/namespaces/kube-node-lease/secrets/default-token-58w45
    uid: 72e11af2-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1wdWJsaWM=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhCMVlteHBZeUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUprWldaaGRXeDBMWFJ2YTJWdUxUUnVPVFJtSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1SbFptRjFiSFFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzTW1KbU16UTVaUzAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF3ZFdKc2FXTTZaR1ZtWVhWc2RDSjkuT3l6RTVxVEpJTjFvdnJ0TVkyX2k1OGdYc3kyNFlNaXZjLWZlTGxzSlBCWmdDejc5UmhVQlhIRVlDVEJEa3lPcFA3cTB0Z1A5Ry1LT2FQYTFFWGZTUWxtbGVBWGxjbUNjQkw5MDV0ZHAzZnFUQU1UNXY3cDVOeGItbFZZVUc2dHczZUxOTzFJYUNjTUp2b3FUSDAzXzZhUjVrR0p1VHhnN3pYT2tZcmNQaGlRcmxSMHptVTZsMmdDTnRCejFRczc1YzY5ZGNkSXJPaHVyRWlTTV9EVWlmVzBybHNlMXcxejVLU3QzSXp2Y0pCY3hhNk9XdldVR1VUZDQzUFRNcmRMbExsWUxlU2U3dnYyTDNVUVI1cllKbkxxRlhvcmttNm9OOHBWNnJrWFRCellDb1Atc3hqM2JSR1hzNTBfQ3pjbHcxZmdnaENJb3RTZnZqdjBGV2ZScTdB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: 72bf349e-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default-token-4n94f
    namespace: kube-public
    resourceVersion: "256"
    selfLink: /api/v1/namespaces/kube-public/secrets/default-token-4n94f
    uid: 72cc7645-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpoZEhSaFkyaGtaWFJoWTJndFkyOXVkSEp2Ykd4bGNpMTBiMnRsYmkxM05uRXliaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUpoZEhSaFkyaGtaWFJoWTJndFkyOXVkSEp2Ykd4bGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqY3haR1ppTUdVM0xUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwaGRIUmhZMmhrWlhSaFkyZ3RZMjl1ZEhKdmJHeGxjaUo5Lk5jdDF6S0R1OWlqWlMtUVlsNVY0MWNfMTNaZlhLZExMZnhBT1ZNbjRBU1dWLUMtLWVOVDBrSmd4cGp3MUZaMmQ5NXV5a0tpSW9yNzduZ3lNalpTRHU5NTlMYTh2NmdyZU1tbzk0cmdkSEUyRExEVm9ZcE9LelB3VHZDOWh2NmlDUWlwMnM5SW9wb0RuTHpLdXQ0M2lwODI2UmdiUEJ6LXNqVnRDRlRBa2pSeUpTY2ZYVkVOTmRUY3YxRWw2SWJONnFkTEdGbTRQSmRoNy12Sjh3Tm5tdzBwc1h6QUdqZTVYUGg3UFhoOG42QjZMSjlKVEFocFh2X3c5X2FLVEFnNHQ3V3I2ajBSZUJMZlNNa2JBWFlhOXJvcWVWSGdvUHhwM3FYbVd0TmFZX3NtMEJUN2VCSktpcHpzSUhXU05WYndvcnczd1VRYjRKdlpacl9DWVpubEI4dw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: attachdetach-controller
      kubernetes.io/service-account.uid: 71dfb0e7-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:06Z"
    name: attachdetach-controller-token-w6q2n
    namespace: kube-system
    resourceVersion: "236"
    selfLink: /api/v1/namespaces/kube-system/secrets/attachdetach-controller-token-w6q2n
    uid: 72314e7f-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpqWlhKMGFXWnBZMkYwWlMxamIyNTBjbTlzYkdWeUxYUnZhMlZ1TFdKNGFIWnRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1Ym1GdFpTSTZJbU5sY25ScFptbGpZWFJsTFdOdmJuUnliMnhzWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lJM01qaG1aRFl4TUMwMk5tRTBMVEV4WldFdFlqZ3dZaTAwTWpBeE1HRTRNREF5T0RnaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2WTJWeWRHbG1hV05oZEdVdFkyOXVkSEp2Ykd4bGNpSjkubnZqSFFDMU9oZUxQT2g1RDQzREJuREVOYTNtVmZhbkM0cFViVFU5OEVySmt1YTVQX2hFQkYxdE1fOEpVNXVXR25ROE95b3dHNXNTQVR2US0waU1NTE9FS2VuVUlyQllGS3JDY1IxVm1ITktzTXJhMjZEM0FVSTFxYkQ2SkpKX0l0dGtrVHdBSTgxdEp4RHNmVVVWMXdsZFJ2SkxLZ2tPZDJNbHVyTy1HX2tTMURSZmFFNHJ2bDREYURFZXBqV3ByZVdTLXdoQldaeFk2MWdybjU3b09ubE5INzBqVV85QVhqMlZKRWVlVW9VRWZSLW4wcGFILUIxVmx1dHNNZFpUVk0xQmpBOWtTXzVCQmJsOXA1eVhnMHNGcEJjVnhDa3pxLV9MdldtaHYwY2dPcHRTemR6U3d6Z2xfRHpwZlV5QmZtQ3pxS2hkY3JrYkpTeXRDY3Y0SEZB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: certificate-controller
      kubernetes.io/service-account.uid: 728fd610-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: certificate-controller-token-bxhvm
    namespace: kube-system
    resourceVersion: "246"
    selfLink: /api/v1/namespaces/kube-system/secrets/certificate-controller-token-bxhvm
    uid: 72943d16-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpqYkc5MVpDMXdjbTkyYVdSbGNpMTBiMnRsYmkxc2QzTnVheUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUpqYkc5MVpDMXdjbTkyYVdSbGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqWTVNVGMzWTJVM0xUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwamJHOTFaQzF3Y205MmFXUmxjaUo5LmZZam9hNGdoN2NRdlZ0TUVzS0Vtd2pma0t6R0VWeFEyMWRwNldubEZpVS14a1FMbnkweDVObzhnVkhKR1c1cXBLQUFsNGNOWW5JYk4yeF9vX3M3MGNjZDhacnNPSWpXVk9uR05Ralhtbm1zZUxLa1lHMGYzR0VkNUJxQUJXaDlVVnZNMlYyYkUzbkVMTS1pWlZ2TC1LTm9nNUdDenQ3N29Bcnk4a1JHMkI5dDNmT0VoMXk1bDZIUld3bjJwa1BOOEdsME9qdzVrMHY2UDA1ZzRlYXk3YlBGTlR6aW5YdFAzZG9uYXBtcFY5TFNsOFhRbjM3MVg3eFhoRVdzYWhyS0FnV1F2TFlLZmxOck1SeUhsam0tbFQwdGNPdVhwaG44OUxrZm9tQTd1dklacHNPcXZYWkk3eVF4bU5OT2J5SC1FaF8xUHRtRHljaUJDUmM0VGZ3U1BnQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: cloud-provider
      kubernetes.io/service-account.uid: 69177ce7-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: cloud-provider-token-lwsnk
    namespace: kube-system
    resourceVersion: "151"
    selfLink: /api/v1/namespaces/kube-system/secrets/cloud-provider-token-lwsnk
    uid: 6924337b-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpqYkhWemRHVnljbTlzWlMxaFoyZHlaV2RoZEdsdmJpMWpiMjUwY205c2JHVnlMWFJ2YTJWdUxUZHRhbk5rSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1Oc2RYTjBaWEp5YjJ4bExXRm5aM0psWjJGMGFXOXVMV052Ym5SeWIyeHNaWElpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkyWm1RME5qTXhNUzAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZZMngxYzNSbGNuSnZiR1V0WVdkbmNtVm5ZWFJwYjI0dFkyOXVkSEp2Ykd4bGNpSjkuRnl2SmFqbHJoOGhza2tYRlFDQmlfTlAweTJNblE0ZkhuV0ZHc1BOVTZrLTgyVERLUTV2c3NjbzRseFdzNVBIZ2FlQ1JxMlVMb3hxdnF0TkczbVRXY1NEVW90YjYtVVRUazlhcWR1ODlybzY1M2pZc0ZSZzBYeExzeTlRd1h1aGY2YklpbGpZanlMMjdkRUx0d25aZ2R4TVQzdjdVTXczaFlZX1hNQUExMjgxNm9JRVNJSFNUTU01OVJodldHZ3JTcmNWeTAtSjdjZDVpd0MweEtJd244dTNQQnJYSFJncUstNTg0VmtsUm9TUUlNRnZpM2s1X2pPQTZ5UHlERG1qU3k0S2hLUHZUdk1MUW1odkJIT1ZXak4zRFAtOFJTUjVpZU1LREJuZWtZdzdLTzB1amxJYWhKajVhYnpyZkladmdQZ2lwaDM5aGZHTVNfeFdKckhIbkx3
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: clusterrole-aggregation-controller
      kubernetes.io/service-account.uid: 6fd46311-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: clusterrole-aggregation-controller-token-7mjsd
    namespace: kube-system
    resourceVersion: "184"
    selfLink: /api/v1/namespaces/kube-system/secrets/clusterrole-aggregation-controller-token-7mjsd
    uid: 6fd8671b-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpqY205dWFtOWlMV052Ym5SeWIyeHNaWEl0ZEc5clpXNHRhR1ExTkRjaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaVkzSnZibXB2WWkxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaU56RXdZVGd3WkRNdE5qWmhOQzB4TVdWaExXSTRNR0l0TkRJd01UQmhPREF3TWpnNElpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T21OeWIyNXFiMkl0WTI5dWRISnZiR3hsY2lKOS51Q2hBNTZxUEF6UnBnSGF1VlhRWkhWQVpWWUJvRXJ4Q2FLR0dnSll6bUZJUk1ZUkhBNkhfVklfUHdic2dhQ0pUMFVzbDhTTm1wWlNwYlhJWUY0aG5FWjhqYlpXUENKYjNIS2NvanU2V2UwU20xM2pTTllzcWJCbGw2dVhXRldMczhNbTBQRE5KeEhhbTJ5aTlEbXV6THdUMGNfUjRwODV4cWdqMVJEcEFGREJGYTgxNGUtZFAtUUZtb0VGZXpuOXRZMkpDR3ItNTA2akVhQjRJM0J4NUpJT3dKQ2drdU0tQVpTVWx4NUpyTGVydnZFNTVsemdzbjhUQ3BaY2c4LXItRlZNcUF5dk1sUEgwQTNtdDlPY0N3Ym9kX0RXZDRMbHl4LW1sbUJPVHVtMVNDV2VTbVhSMmtzTGtUb1NGU0VWZ2xlQWZXdHhYWlRjbnJsVG1hNnVOeGc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: cronjob-controller
      kubernetes.io/service-account.uid: 710a80d3-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: cronjob-controller-token-hd547
    namespace: kube-system
    resourceVersion: "218"
    selfLink: /api/v1/namespaces/kube-system/secrets/cronjob-controller-token-hd547
    uid: 710d86bc-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUprWVdWdGIyNHRjMlYwTFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0ZDJScmJIb2lMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2laR0ZsYlc5dUxYTmxkQzFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTnpJNE9ESmhabU10TmpaaE5DMHhNV1ZoTFdJNE1HSXROREl3TVRCaE9EQXdNamc0SWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbVJoWlcxdmJpMXpaWFF0WTI5dWRISnZiR3hsY2lKOS5CX2UzUUJpV0ZGYUl1Q293S2JiN2VBSmwzY2pwekpRUnpmRXgtZ2lQblpOcmMwbHlfTENQWEFxZDN6SDc2UlRHUC1LRjJjN3BjOEJsRENUOXhZS2VMNG9OVmdMemI0R1lvQmNyMHZ2c3BEWlNreVZWNWVzVzVPN0h4TWVUYkdSWUxfVmZhVGRsZWpUVGYyMml2NG8tSkJiazFxa0FOYjZ3NlEzZTdqSl9rVDFMVkxDVExDTC1rSmVpV3p0b3JUVWJqZUtWMlFHZGtoajh6WUZrdTJ0a1NuLXlHTGR2c1FzcF9UTkxUVXZKSHNyeHA3dGpmRFBDYng4VWprZ0VJc2EzYk55N3AyNFBxS0MtdVZlTE9oUVlValBWMnBydl81UDNIZkhDcHMxbWxZVnFBOHJHOG91UWhXNXQwaV9qaE1CdkpiTS1lOUxfYWJsM0pDcExZbld4Q1E=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: daemon-set-controller
      kubernetes.io/service-account.uid: 72882afc-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: daemon-set-controller-token-wdklz
    namespace: kube-system
    resourceVersion: "243"
    selfLink: /api/v1/namespaces/kube-system/secrets/daemon-set-controller-token-wdklz
    uid: 728b8791-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUprWldaaGRXeDBMWFJ2YTJWdUxUSXljbWRvSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1SbFptRjFiSFFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzTW1JME5tTTJaaTAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZaR1ZtWVhWc2RDSjkuTlFjdmNScFIzLXlqb1kzU05WZFlyZ1FUcDNtYXp5cWZfbGRtX3hJc2lNZTBHY1N1X1dWVWx6WkFEVmRmaWZmcHBCUlZFVWhUQ1pYNUp5bzk5SG9yV2l1QWhkWWhmR2lrVUt5NU5CZ1VlYWVfb0F6UDI2TDFYZjVnenpHdkFLTFMxODM1aVY1TjdMc0RURWxZbGNOUEs4OFBaSDJoVDV1OEUta3VTR3ctMG5iZENPT2QwM1V4alRIZHo4YUpGZ0NSbWh5TjYyRVpIQXJad1pXVXpNc21JZy1FZW16WFIyNnlhSzFZSG5xSkdiV2FXX19GOV9fckFYSkJzNGxJb1lKT0JNWWpTWHdScnh2aVZTVGdqbG1SQWpaSWpQRDZNLUJ5VHlYbEVEeVYzWWhuNFEwZDRUVG9HeTlCSDZHZk9KOWlnV1lhOVhSVDRnVlpHVXp2SjRhR2x3
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: default
      kubernetes.io/service-account.uid: 72b46c6f-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default-token-22rgh
    namespace: kube-system
    resourceVersion: "255"
    selfLink: /api/v1/namespaces/kube-system/secrets/default-token-22rgh
    uid: 72c9d940-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUprWlhCc2IzbHRaVzUwTFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0YkhoNFpEUWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2laR1Z3Ykc5NWJXVnVkQzFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTnpFNU0yUXpZVFF0TmpaaE5DMHhNV1ZoTFdJNE1HSXROREl3TVRCaE9EQXdNamc0SWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbVJsY0d4dmVXMWxiblF0WTI5dWRISnZiR3hsY2lKOS5DeExRTEhqRzIzR0IxUUdKN01aSUZEeE5Fc000VUNGZUxQdXZZQWZBTUk4dG1ISE1FVDR6M3BqNDdiRnBqTzhyRy1WY1RicURVcUJWaUEzb2pVZ3hXMXF0Ym15VERLM3dIUFNjTG1pel9MejBzU3BLVm5YYW1mdW5MeHJiTGNuZXo0VlNpOGJtRFAtOWtKd0N5NlBkdDk0eEdmNC1HanRRRldrTDNHOFZHdXJKa2ZSWTBfWWRnN01ONzhHODh4SkFNUllvUWtMRTNQTEdINFppRDhtVEp2LVVUcGtYUC12OTNqMXBSTmVPa0VOVmNISTBYaTNENXB4VUdHRFFPNTdwTHJGaGNSWlZLWWcybGxWVW44SmF0NmVTOEMxVnpVT2o3Njg1a0RwdThKRTZmRkluWjdkMnFlT3NjLUlrV3FkaU9wejJuZHMxemk0YUJOMVVuZ3drREE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: deployment-controller
      kubernetes.io/service-account.uid: 7193d3a4-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: deployment-controller-token-lxxd4
    namespace: kube-system
    resourceVersion: "229"
    selfLink: /api/v1/namespaces/kube-system/secrets/deployment-controller-token-lxxd4
    uid: 71972ae5-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUprYVhOeWRYQjBhVzl1TFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0YW5kcmJEWWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2laR2x6Y25Wd2RHbHZiaTFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTnpGaU9UaGpZakF0TmpaaE5DMHhNV1ZoTFdJNE1HSXROREl3TVRCaE9EQXdNamc0SWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbVJwYzNKMWNIUnBiMjR0WTI5dWRISnZiR3hsY2lKOS5PQmxCcUF0Rk53X0dQVHN0bUttdlhOTF91Yl9yeDRCMUtnNXlDbUliRUVaN3RjUV9jaTh4Tk5nTXdCSjZ2RkZCV09OajEtOWJtZzBiajdseHFwZlV6dVJJck9abzdjMVJKSVZmbXVTa0ZCS3FwQnNRN2NKV08wUF80c0pmTnRNRkFoaWdnelBpNHNaMFNWNGNZdUtqSnpUYXNIVlNESDBzOUZzTG0wODhSV1FVelA0bjJ6SlhwNlozZkQ4bVdvdjl1aW1vWHVudWNCZzU0Y2N3V2tCMWJTeXdOUE1WMjJIcnJGWWJpbHJqNHRVN0dwZ3ZqYkpVeVRMWklud0JKVnZaV0ViaFZJQnY2NllZWldraFpqSlcwVlphVEJDRE1CZDA0bVdocXJESDNhMHhIQmJuNmNCaDBZWTVqRExPZGVNbHpwS1VYcUl0VDhaeXNpaUpWSW9udUE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: disruption-controller
      kubernetes.io/service-account.uid: 71b98cb0-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: disruption-controller-token-jwkl6
    namespace: kube-system
    resourceVersion: "232"
    selfLink: /api/v1/namespaces/kube-system/secrets/disruption-controller-token-jwkl6
    uid: 71bc2908-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpsYm1Sd2IybHVkQzFqYjI1MGNtOXNiR1Z5TFhSdmEyVnVMWGcwY2psb0lpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltVnVaSEJ2YVc1MExXTnZiblJ5YjJ4c1pYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSTJabVJtT1RBNFppMDJObUUwTFRFeFpXRXRZamd3WWkwME1qQXhNR0U0TURBeU9EZ2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNlpXNWtjRzlwYm5RdFkyOXVkSEp2Ykd4bGNpSjkuQTd5Y3lNMmJadThoTXRzOEZEbDVkaUVkaUVtSVNoZUx6V0lZZkZSVF9hRmQ3aElNeTBOQVRlTE9iTlIyOThueVBodXA1VTBHLUZhaEJZcEFkbjFCVk95cHM2djZEV3hxYXR1aVplOFlZV3NvR0tMRFN0MmNMNW5xazAxSk9fckZVOXF6WFFMbGxuWkdSRFVMY0R5bllCS2x6bU9LUUdGaEtXUWw5LWpwZmZGQnpIazFiS1FsS3VqdzYwdjBOdnhfRWlodVU3R3BBc25WNGFCVlJHc3A2cDZaTTBiOTVGaEcyZHJZQ2VpZkVvUEZ6N2N6Z0JsM1RTVE1RZWdFNWx4NGp0Qkw4Wnh4dGlnM0hsSEtvSkUxTHBUOUppclNYVDlmX2dyeHpwekhleGZuVll4eUY2RkVpNmwwcTdtUEoybnJGYXhXWGQzTFZhOVRsbmxqME9BR2pn
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: endpoint-controller
      kubernetes.io/service-account.uid: 6fdf908f-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: endpoint-controller-token-x4r9h
    namespace: kube-system
    resourceVersion: "187"
    selfLink: /api/v1/namespaces/kube-system/secrets/endpoint-controller-token-x4r9h
    uid: 6fe335f8-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpsZG1WdWRDMWxlSEJ2Y25SbGNpMXpZUzEwYjJ0bGJpMTROVGhvTWlJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKbGRtVnVkQzFsZUhCdmNuUmxjaTF6WVNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SWpjNFlqazRNVEV6TFRZMllUUXRNVEZsWVMxaU9EQmlMVFF5TURFd1lUZ3dNREk0T0NJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHBsZG1WdWRDMWxlSEJ2Y25SbGNpMXpZU0o5Lk1pOWZ3bkk2QWlTa1VNQjRVdk9welYtaXFSMjFHQlZvVFdTcmVscXZoYVc2VlJlLW0xWGJtc2t2dG9HVE5aSl80bkhRRnBjbUhYSVZvTjhmQ1FYaC1YOVZfWlRJSnh1UUZjSmlLaDRzeHNHRVNBc1BJYWxPZmZLY0ctc0w0dTc5WWZQUnFPWjZONDZ1eko0TmdaNGlsNHVRZTM4MUlIQlNQTnBUMXRyVWFsNzI2NWhjR2tyTTR5NG5KX1doVTloM0t6eUxkNVpqYmR1NllJUk1Mb21GWDFzZmF2dnRhZGRwYzlTQVRVXzVrbk1LT2NfVG9KbVVLYzBxRnpqUy1tZUNWNEt1ZE9CU0Zxd3pFbEZtWlRpZUFjSnNZRVZGd0x1aVZCZzRqSWxzOTd6M2Fod3ZheDVSUHduY1dqaWpacmZ5OGI0QVBMM2kzUlp5TzVKYlZBZ0lPZw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: event-exporter-sa
      kubernetes.io/service-account.uid: 78b98113-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:17Z"
    name: event-exporter-sa-token-x58h2
    namespace: kube-system
    resourceVersion: "345"
    selfLink: /api/v1/namespaces/kube-system/secrets/event-exporter-sa-token-x58h2
    uid: 78bc4411-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpsZUhCaGJtUXRZMjl1ZEhKdmJHeGxjaTEwYjJ0bGJpMDJOVFJ5YkNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKbGVIQmhibVF0WTI5dWRISnZiR3hsY2lJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SWpjd05XRTVNR1JpTFRZMllUUXRNVEZsWVMxaU9EQmlMVFF5TURFd1lUZ3dNREk0T0NJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHBsZUhCaGJtUXRZMjl1ZEhKdmJHeGxjaUo5Lm9HRUFfRXNIZFZYQkc3YXJNR0VWRUVJekg5QWpGZmNWTkowdHBoRUg2N3BUZ1owWEVaVHhIWXpJRkdsWmxzNGZaLWxGQTFheVhTeHd6bTNKeVQwNUpvbmxBR2Z6NUZTT0RkbmtuZkhHWWZ3YlQ2Y0ROdHJrYUVpWUpPNlI5MFNBZS1ESlFsdGlZT2tnd05QOGlwT3dINFV1NXN3M3gyUi04QTBWYzFHaGMxZHlMaEZ1ZHdrQ2Mxa1RrbzFNd0FwRFpQVnFqLWE3cjExVzNMeVRUcmVjRlM4ckd6QjhHNTBUd0tWNGZZTGRwN0d4Ynh2NVBDdmVzRktHWTBjU3Y0b1NsaEFiaVAwc0FYQl9yQkpvR1Z0TWNmbFR2c3UxMUJCWlhVUTR1MzVfVHFkdEhyWU9pM0lPMEdSQmRPdkNsNzlnV1loVXRTMXM3Qm1WNlhLSHFoMHp3UQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: expand-controller
      kubernetes.io/service-account.uid: 705a90db-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: expand-controller-token-654rl
    namespace: kube-system
    resourceVersion: "204"
    selfLink: /api/v1/namespaces/kube-system/secrets/expand-controller-token-654rl
    uid: 7074c8fa-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUptYkhWbGJuUmtMV2RqY0MxelkyRnNaWEl0ZEc5clpXNHRPR2RrZG5FaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaVpteDFaVzUwWkMxblkzQXRjMk5oYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaU56aG1NVFEyTXpBdE5qWmhOQzB4TVdWaExXSTRNR0l0TkRJd01UQmhPREF3TWpnNElpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T21ac2RXVnVkR1F0WjJOd0xYTmpZV3hsY2lKOS5GM3NBcm1ySk96MWt3cmlJZzF2YndxS1J1V2c5cUZzcXlfYmliMV9qa2pFMWh3anpTVzhFSjdMS3kwNkRsaG5kRXd5UXI4bHh0Y2FQN1UwOXQ3ZWRKOTZrQjMzUjMwUnFqbnVOUFBUZi1Wd3RzSXoweTNXM0puaGZ3TzVvV0hkVkZsdmZCbGdEN1BWWjdKOHQzY1FtU1Z4Y05rYnN2RzdzRUM4aW05TlhTZ2FKVVR5aV9tLXhydXRGZk9nTjJiUy1tajRoTk10NFNCQmZYYmFDUFRMNFEzNGJGdjNRaWN4VDZaYTNwQlpyOVlWdlR2VGR4TEwxU2hpX092TTNWOVZjUTY4QTlhMnpsTXF6cjA2bnVORDRLRFVWeER0bFNXczJhVGJiNWVNNzd2dUQyTmY1d2t2a05wX3lCc1lraXFDMHZiMVFtMkNQaHZPcUR1TUVnRHF3a1E=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: fluentd-gcp-scaler
      kubernetes.io/service-account.uid: 78f14630-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:17Z"
    name: fluentd-gcp-scaler-token-8gdvq
    namespace: kube-system
    resourceVersion: "366"
    selfLink: /api/v1/namespaces/kube-system/secrets/fluentd-gcp-scaler-token-8gdvq
    uid: 78f2b279-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUptYkhWbGJuUmtMV2RqY0MxMGIydGxiaTA0TldoNll5SXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMbTVoYldVaU9pSm1iSFZsYm5Sa0xXZGpjQ0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJamM0WlRCallXRTBMVFkyWVRRdE1URmxZUzFpT0RCaUxUUXlNREV3WVRnd01ESTRPQ0lzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwcmRXSmxMWE41YzNSbGJUcG1iSFZsYm5Sa0xXZGpjQ0o5Lk1vZllYdTM0YWEyZUh1ZC0ycWxneWlaamloM1VPaTF5REN1MGtkQnR2YUhocjg1bi1rbGZFb0MwQW43N0MyT2JCOXlEZjNyczVHcXJuUTdOU0JIamh2UWxUY2ZfcFhseFVKTzN0bVdzUzREQVpLN1VFNVQwd0NpMFFYZzFKOTJuUUcxVmZWakpiWnFmRE5aakxKOGJQdjhWejc2Wm1PTHMtLXRNVHpKY19iRnNxWjhadEpQY251cUtIUTlidmQ4bkl1OE1TbW1lYUx0TGNpUzVyZkJUdGtiMEhkdkI0Ykh2T0tSOUg3OWs1OUI2Vkc5MnYwbmlBdjNJaXN2T2NELTh2TzJRdTJ6MjYtVmVJTUVRRnZmbTc5N29BTHkyNnAyWmhXenV0UHZtcmFDUldBb3BPTkViQW9ra0prS3QtZDVwRkx0d05abUhoaTJrYkhxdnlUTmE0Zw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: fluentd-gcp
      kubernetes.io/service-account.uid: 78e0caa4-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:17Z"
    name: fluentd-gcp-token-85hzc
    namespace: kube-system
    resourceVersion: "361"
    selfLink: /api/v1/namespaces/kube-system/secrets/fluentd-gcp-token-85hzc
    uid: 78e229ef-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpuWlc1bGNtbGpMV2RoY21KaFoyVXRZMjlzYkdWamRHOXlMWFJ2YTJWdUxYSnFPR001SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1kbGJtVnlhV010WjJGeVltRm5aUzFqYjJ4c1pXTjBiM0lpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzTUdFM01URTBaaTAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZaMlZ1WlhKcFl5MW5ZWEppWVdkbExXTnZiR3hsWTNSdmNpSjkuZ0g2bzZzUkplM1RaWFJxYTV3Z2dWQ3lxOXJGd0plT1RhQ0FKWUhfdW5pbzl0X3Q2b0FXaW0xZk9Ba2hmMDFZTGxMTjVTSnd1SklvbjlIUlNSYmNXeWUtbmFrUFVya0NHZ0NqMzVYbWZ3R2Y0dXBZeHluTGZKaGxlaV9RSGFmRTQ4SnBZcFZfYUJXeXZoM2tIUS1HeTl2VDNqYXd1Vk9NN3E3Z2JLU29BT0p1R05pN0cwMkN6Q1FSQWl3WC0xNjU4X3ltekdReVh1YXZpMDFLRUNxVTJqMndndWdlVlZNT29UenJra0RWMzlGcS16N20yWTJ0bXRsSGx4QzhrWFRmbmtPaDc5SVRvUUxRcnFJT3lDOE9mQ3pXbG9wNDRKSGJneERrQmtJNVdJU2p1SzI4QlNzNjJhTlcyNnRNSnhaVEpLN041N0c1RnNFdHFNT1lfTWJoSzJB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: generic-garbage-collector
      kubernetes.io/service-account.uid: 70a7114f-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: generic-garbage-collector-token-rj8c9
    namespace: kube-system
    resourceVersion: "210"
    selfLink: /api/v1/namespaces/kube-system/secrets/generic-garbage-collector-token-rj8c9
    uid: 70a9ad74-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpvWldGd2MzUmxjaTEwYjJ0bGJpMTRPR3A0TlNJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKb1pXRndjM1JsY2lJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SWpjM1pEbGlZemt3TFRZMllUUXRNVEZsWVMxaU9EQmlMVFF5TURFd1lUZ3dNREk0T0NJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHBvWldGd2MzUmxjaUo5LnFqY0trU0pUemtsVmw2MWdvR1kwcHJaVWU5akR0czRDbU5fdTFwM2pWN2NvQmlfWG9uUDBSalZ3Q09hdVNQeTJvcm1UMVdPTTNPaHlMc1ZHcUFBcHBFVkcxSFhrVVNJMmtaU3oyM2ZVUEFEYm9OOUdZREs5dV96d3dXNGZWaF8wOHM5WlBqY0VKcUx6ODhMTEYzZnA5N2ZSOWlvQU1UVVBSV2VDT1VsZFN5MmNwYnp0M3psOUU0a2Jibk5tdFd5STZtQ3llN0F6Nk9HV2Uyam5oc01zWUcwV2xwclFJVXRrbVVUdlJVQUJ1dzl4MGpoYS1Gdm90X2RrMURneHFHS1NIcmNYbmpYMEhPeDhyRm8wVHpDa2RaQ1NpcURZdk9OWElaLWF0akw4d0JhYi1ORkRKOFNsOEVZRHlHWS1vUEV5YU5zSzQ0LTBmUTNxd2JOME9OVDhnUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: heapster
      kubernetes.io/service-account.uid: 77d9bc90-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:15Z"
    name: heapster-token-x8jx5
    namespace: kube-system
    resourceVersion: "327"
    selfLink: /api/v1/namespaces/kube-system/secrets/heapster-token-x8jx5
    uid: 77dc7234-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpvYjNKcGVtOXVkR0ZzTFhCdlpDMWhkWFJ2YzJOaGJHVnlMWFJ2YTJWdUxXcDJOVFkzSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW1odmNtbDZiMjUwWVd3dGNHOWtMV0YxZEc5elkyRnNaWElpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzTURFeU5XSXhNQzAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZhRzl5YVhwdmJuUmhiQzF3YjJRdFlYVjBiM05qWVd4bGNpSjkuY1JvSEE2Mk9yNWJjVHE1ei1NNlluTklzT2Q5d3lQM3QtYmdGbmZlRm82d0ZSRklPdGNHVjU3bVIxVDgwd2JrZ2tLUjZ5TW1yVnhHNjJVZTFFWXdGSUNVdWlzdVhzMXZwaXhUUW8xXzg2amYyUDl5SFZRWG04TEJyR2sxT1BXNW9WOWhncEtfSnBtMl92UDRSMzVtNGFxMDdwNjVJX0ZiWmlnN19yY2FVNWpZQngwaDVTX1JzMEdXbGRjN19MVjJyMEtDRlFXcERxRVpxU1hPdlVkbUxmTi1mbGg3UEtpb1dTUzRCQTNUYlpTVkEwLXFuQmdrRDRtZlY4VDJ0NkxrNFNBdVJvLUp5T0FWaXNFMGhEMEZpeWQ5TElobll4U1I5WENFZGVPZ0dVWEdZN3BCN0JRUUtWYWlYelQxQUZaVVVUSnpJYk55dVRsTUFJR2Zka0VDTzBB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: horizontal-pod-autoscaler
      kubernetes.io/service-account.uid: 70125b10-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: horizontal-pod-autoscaler-token-jv567
    namespace: kube-system
    resourceVersion: "200"
    selfLink: /api/v1/namespaces/kube-system/secrets/horizontal-pod-autoscaler-token-jv567
    uid: 70173189-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpxYjJJdFkyOXVkSEp2Ykd4bGNpMTBiMnRsYmkxck5uQm1jU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUpxYjJJdFkyOXVkSEp2Ykd4bGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqWm1aamN6WkRrMkxUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwcWIySXRZMjl1ZEhKdmJHeGxjaUo5LlhGUnNQMkIwcGlhamdjSlktYnlnVDVtZTY2TE1wMk9OOWNEcWp2V3NLLXQ2N0MyVktBeXhqNjBmNG02SUFndU0xTGx3QWUyN2hJZUotUVJqUFlpN2ZPUHQ5b2N0azJZRGIyNEFlbFFCRGN1djN2UXBBbV9ZdkdkUE9zVmxDRDVHRjh0dEdlR2xZeXNIVV9JOVByb19ZMjVHQ2FwSkoxcGptNC1OR0JrY2xYSDJUSm9sYWhuSUEtV3hvdzhzNS1pUjFrRHRWSEpMRnhobEZ3NDZkckJEXzJQTGhST3l6SnVib3VQNWlCMkFTbjFKZUNud0Y2TEVmYlRnY0RNRFgydG5DUTBoVlBWQ3RuYXlucTVIV2hSSU9GNW1Hell6SkRoOFpIU29pUUhwd3kyZVRRU3UzcVN4YzFQZHBkdGhzZVRjRE5TWFdTWU01OTl0Wml2SjcweFYzUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: job-controller
      kubernetes.io/service-account.uid: 6ff73d96-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: job-controller-token-k6pfq
    namespace: kube-system
    resourceVersion: "194"
    selfLink: /api/v1/namespaces/kube-system/secrets/job-controller-token-k6pfq
    uid: 6ffc17a8-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpyZFdKbExXUnVjeTFoZFhSdmMyTmhiR1Z5TFhSdmEyVnVMVzFtY0hGd0lpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVibUZ0WlNJNkltdDFZbVV0Wkc1ekxXRjFkRzl6WTJGc1pYSWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzUxYVdRaU9pSTNZalptTVdZek1TMDJObUUwTFRFeFpXRXRZamd3WWkwME1qQXhNR0U0TURBeU9EZ2lMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2YTNWaVpTMXplWE4wWlcwNmEzVmlaUzFrYm5NdFlYVjBiM05qWVd4bGNpSjkuUW5yTXd6aWk4cFFVa0VVTlVXRnNiaThBeUxNd1A2djk1Z2ViMkNQYmpUTU1fR2tqbEFNSC03TFhwWDVKUDJfLW12NXdRNUxGMmFlOHBRXzhNUm12Vmp4ZC1aMExlYS1NYU9xeVdOODlPWGM5Tkx1OWJqUEozU3pDbjY0Z3RuTTM1VmJTYlU0bnB5SDF0SlpCVlc3VC1VSkx0NnlJUTdhWVhKM0prMWdJU2ItaC1rS3hsdTBLZm1hT1pQYTNBak82TGdOVkgzZmg1bTEycFdWU0loSWVBYUpZVldFeUQ2dGdRR2ZiNDdjVXNOaFVwRlo2Sm1aY3Vxa1NQZ2tRZDlMZWVLSEF5b1V0WjRXd1ZBOUpnczBxMnhVQm5BbkVBVXp5aHhxaDlGQlYxZEVtQzlWbUFVOGxDRG1ydnQzNTVzZlljUEpsWG42cWJ6QWZUMDFOWHU3QVJn
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: kube-dns-autoscaler
      kubernetes.io/service-account.uid: 7b6f1f31-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:21Z"
    name: kube-dns-autoscaler-token-mfpqp
    namespace: kube-system
    resourceVersion: "441"
    selfLink: /api/v1/namespaces/kube-system/secrets/kube-dns-autoscaler-token-mfpqp
    uid: 7b7024e6-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUpyZFdKbExXUnVjeTEwYjJ0bGJpMHlhalp5Y1NJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKcmRXSmxMV1J1Y3lJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SWpjMllXWmtabVF6TFRZMllUUXRNVEZsWVMxaU9EQmlMVFF5TURFd1lUZ3dNREk0T0NJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHByZFdKbExXUnVjeUo5LnBtc2pGcEhoUldETHlDalJPN2F2bjJhZEg4V01jWndDYXZTN3AwNmItc2hkb0lSanAyNTRuLXRIdVJsNkVHR3RnM0xlajNiUjlLYmhfMC1oRlcwVWx6d3FRaHRFQVp6V20tdjB6OHV1RzJnNGRtTjFaQXplQXZZdGVYdEIxTUZCU1hQWWpKaHpTbnotN3BiRkZtd29QV1B0VEJqQ2daT3VqXzJMVWhTR1JicFRrT3kxWnJqNjA0bTg1RHl4ODhKTXZZZ00wQkRMTDVmcU1pOUdhLU0zeWhmWU5XYmU1ekV2UFdWQW5zMnJtOVpZdjZhUGZGOFpnQVNESEhoenF1V1ZpSGU3OWdoMTBqOEg2SVFOOWowQnJzYk9nalNOeEdvWU1ISDUxMGh1eDJWZUJHYWtrU05tbXpKeThFSldjUDYxSGpSdjFacnF3cFRCVy1Md1ZHRXZyUQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: kube-dns
      kubernetes.io/service-account.uid: 76afdfd3-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:14Z"
    name: kube-dns-token-2j6rq
    namespace: kube-system
    resourceVersion: "286"
    selfLink: /api/v1/namespaces/kube-system/secrets/kube-dns-token-2j6rq
    uid: 76b2946a-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp0WlhSaFpHRjBZUzFoWjJWdWRDMTBiMnRsYmkwNWFtcHdiaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUp0WlhSaFpHRjBZUzFoWjJWdWRDSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqYzRaamc0WVdObExUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwdFpYUmhaR0YwWVMxaFoyVnVkQ0o5LklVSEZrYnJKcnozMXBfWjctU0NRdUZ0Yl9QWUdpb0FLWGQwYnhoRFVvUV95RG5hLXhqZ1g3Qm00VXpZVHBGWncyWUcxU3NIX2otdE5sc0Qwbmp5aTZoTGVaVG9oWVZDQlFHVEd1NnVWQ3RxV3JhZFdoWG85aGdQUUROblBFZUh0anZ5M1hMNjlfMGFKc0lMSDhwS2lmTkVtdlU2WFd3NDVHX0ladVJ6MTQtTHNLN21uN05hbmNvcndFVlZuOTBwYmxjTnZCTTZIbVFGaDMxUU5fTGtkRFJqZzNKdHBoazFHd1kxcHZCY3p4QUJJbk9DdjVJaUtBcVhCdmJ0X0VrMVUtWGw3UUNZdlFZTzRUU0QzRUEwclBxM09mRmFwTWRLekFnSlVLVmthZFAzcExrdTgzMFBCOEM2Tkt4Y3VUbDM3R0NLa1lCNlNDTXNKbUhjd3lxblhYZw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: metadata-agent
      kubernetes.io/service-account.uid: 78f88ace-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:17Z"
    name: metadata-agent-token-9jjpn
    namespace: kube-system
    resourceVersion: "371"
    selfLink: /api/v1/namespaces/kube-system/secrets/metadata-agent-token-9jjpn
    uid: 78f98f50-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp0WlhSaFpHRjBZUzF3Y205NGVTMTBiMnRsYmkxcVkydHFaeUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUp0WlhSaFpHRjBZUzF3Y205NGVTSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqYzVNMlEwWVdReExUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwdFpYUmhaR0YwWVMxd2NtOTRlU0o5LkhHQUlnQ3B6OUlISVhkWDRzMF91TVgza0N6UUFPcDNWUFp4TDc1ME1HanY1YkY4NDJQQzMyclNmU2ZzLUtJcV9lNVk4bGMwR0JKSDAtQUdJdHgzUkh1dUpBLW4yV29yM09zS00xTkdNTFgxb2VmbVlTM2NkMHhaQmFkT3lvRUpwR3RhcXRhYk5wTjFNeXdkckQ5M3dyRFhBdkFubXplcEJseVlKcXhDellIQUlTTjhjX3Jma3MxcXFaaV9VTXR0VDZnWTM4SVJLaXRzemxfYUEyMlhZZ3otZUI1VHFZOGFVSGFkbnZBbkJRcVpVSjd5Uk02ZGQ1cEhKR2hwV0JCdHdKT1ozVHJjLURWbC1qaDNOTF9GOUN4UGJBSk1GcHlkN1ZMUW1KUXl4SGtKM0Y1Sk9RbkhScWg3NnpBWXBwemF1NFdhRUY3WktRVVVYYWxZcWctUGl4UQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: metadata-proxy
      kubernetes.io/service-account.uid: 793d4ad1-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:18Z"
    name: metadata-proxy-token-jckjg
    namespace: kube-system
    resourceVersion: "392"
    selfLink: /api/v1/namespaces/kube-system/secrets/metadata-proxy-token-jckjg
    uid: 793e8f98-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp0WlhSeWFXTnpMWE5sY25abGNpMTBiMnRsYmkxNE5tUTViU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUp0WlhSeWFXTnpMWE5sY25abGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqYzVOekZtTmpZekxUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwdFpYUnlhV056TFhObGNuWmxjaUo5LlB1TUphcU4wNmZkb1JxWmlZZVdISlZ4b2VlM1hpbVVObC1fLVJpUHV2Ujg1TnhwemtHTUFteERWMkRrMENpRWhyY2JQc0duaEp6LWFQaVRRSHVtLUNwRnFrVUE3WjJwcHFzYnB6OTRNUHByRkF0RUU1WmMzV1VDbGc2WVJGWFZIc3Rlb0tTYlFLVEZKZmtMYkNTX0hlZ1JEc0pkNWVqYlJPaUpQZnJyUFZTMm1OVnQzeWZQQkMwN2dWV0tjdnlGczRVVFljVGpVZndMb0RsVW5kOEdrYW56dktvNkZmWFRwUWNVd1JOcFNBaU9HSlZhSlhJV0JENGs4cTVldWU5MUEteDZ6bUhwQjV2UC1KdW50NGRwdlF6UGkzM1ZCZGxMbjZkdnBzZmRDVTlYYVVWSVhXUFZHcV9OUWZQOHIwTERFMzF3dGpEOFNnSGUwWUgxUjREYXk0UQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: metrics-server
      kubernetes.io/service-account.uid: 7971f663-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:18Z"
    name: metrics-server-token-x6d9m
    namespace: kube-system
    resourceVersion: "402"
    selfLink: /api/v1/namespaces/kube-system/secrets/metrics-server-token-x6d9m
    uid: 798dde18-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp1WVcxbGMzQmhZMlV0WTI5dWRISnZiR3hsY2kxMGIydGxiaTB5Ym1aclppSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMbTVoYldVaU9pSnVZVzFsYzNCaFkyVXRZMjl1ZEhKdmJHeGxjaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJamN4Tm1RMk16Tm1MVFkyWVRRdE1URmxZUzFpT0RCaUxUUXlNREV3WVRnd01ESTRPQ0lzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwcmRXSmxMWE41YzNSbGJUcHVZVzFsYzNCaFkyVXRZMjl1ZEhKdmJHeGxjaUo5Lm80ZWNWYlN1c2FuQUlkZkQtZVgxeDBUQUppOE80VE5CdzR3UVd5OEJnZ2Y5U1pTXzIyZlY2dWV1emhDVkJvWlZvU01OQzBldTlUSXZSZ1NXZDFpUy1rQVg0YjZRSmtJSDlyZkhreW4wQ1Y4OGdNek9qYnk1eld1SHQ2ZElKbjU3NjYxZDRDXy1uYy1KcjRCdnpJcEhONnJOUWhRMjNIM0ExTGFVSXM4UWY5QWRfUk1QZkxwQklqV19Nb2tjTHpxTDdsVHZtR3l1cG0wQkpQM1g5U2ZXc1M0UG00RHhjTVBJTnh0NmlLZURhODNFQnJlTUR3SW1ZWV9wRGNab0MwMU9qS1dtU2ozNGJIdDNnUzd6MGRmMUIweFZpaUlmVmpKRUg5c0NERE5zZGZEYzNNdmY4S3FHVW4zNjVrQUt4c292YnRNM0xMYnpTeUNyWmlxelVjN2tOQQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: namespace-controller
      kubernetes.io/service-account.uid: 716d633f-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: namespace-controller-token-2nfkf
    namespace: kube-system
    resourceVersion: "226"
    selfLink: /api/v1/namespaces/kube-system/secrets/namespace-controller-token-2nfkf
    uid: 717352c5-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp1YjJSbExXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dGNtaDJkRElpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pYm05a1pTMWpiMjUwY205c2JHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lOamswT0RVMFl6WXROalpoTkMweE1XVmhMV0k0TUdJdE5ESXdNVEJoT0RBd01qZzRJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9tNXZaR1V0WTI5dWRISnZiR3hsY2lKOS5PVUtMSG9HeXBkU2RrS21PZE5nd1ZNUDk4SDc3VkJ4RkwwMkdSdEt1T2J3ZkRZMEdCUnVSLUg1WW95a3JDMW9ING16Y3Zhd0liMU5BVnJhVEdqa0NFLURTSG9uOXE1NUoxZVA3TjJFS2lTeDZLeDF5Y3BWZ080SzJvaFFKMU1pSElyNmF4VFZZS0FBZlZXNUQzdGdoWllCV0RLUl9RWE1MMkZnZlZ5NV9WSnJNTnV2MjJSLV9Jejlia0VTbFRjQzRDVnpDb2hqaGFzcGIzVFdlSTFRbDgxbEJxaDVYbEdoWmZoZUpoT3FQSjJLOUlXdUJycHgwS1duWTllQWI4ZmQtMFhhRUtSU1VpakFkbTkyR2NXNm5HM2EtcGJyVjlvdkNIZkJHdFR5eWJwekh3UmcwUE9DWHNKYnFQY09pakxnTmpKNXVWR285WW91SjhKeEp4NEpIOFE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: node-controller
      kubernetes.io/service-account.uid: 694854c6-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: node-controller-token-rhvt2
    namespace: kube-system
    resourceVersion: "163"
    selfLink: /api/v1/namespaces/kube-system/secrets/node-controller-token-rhvt2
    uid: 69551927-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp3WlhKemFYTjBaVzUwTFhadmJIVnRaUzFpYVc1a1pYSXRkRzlyWlc0dGRISm5jV01pTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pY0dWeWMybHpkR1Z1ZEMxMmIyeDFiV1V0WW1sdVpHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lOekUwTnpFNE5qQXROalpoTkMweE1XVmhMV0k0TUdJdE5ESXdNVEJoT0RBd01qZzRJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9uQmxjbk5wYzNSbGJuUXRkbTlzZFcxbExXSnBibVJsY2lKOS5ZZ0N1Nm5xZ1JxQ0VwVDREanhtQkR3QWZpVmQ1RHFWcXBhTElFUkgyZHBFV1dPWHJObWZFb2dWVThJd3lyMkc5bHo4MWs3SGNDc0k2NnVwT29qY0Z2bl9KbHhnZGJUN01Sc0FuNlpjQXltWFZRT282YldkNm9pXzQ5NlFDMHFZOE4zb3U4NElMMjQwRXZjc0dWbG12dEZodXVfRVUydkQwamkyd1l5YVpmd0ZwRGJzX1pJWHdUa09pem1aNzBjeWFqUGNJTm9IeDBycG1ET1ROUm8zNG1xOElhcDJOUnRpd1FKUk5TTG9IQnpCdnpxS2hJT09WMldqVjc4Vmk4WU1INVVIYTEzbnZzelJkWVFuTnp0YzBHYWZsYm4tSGdOOXN3VU1sMC1qbmRGelY4aUw3UUJERFRrMTllVmVtSmRNTTdISGotY2p0MGlFa2cwaWMxREFReUE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: persistent-volume-binder
      kubernetes.io/service-account.uid: 71471860-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: persistent-volume-binder-token-trgqc
    namespace: kube-system
    resourceVersion: "222"
    selfLink: /api/v1/namespaces/kube-system/secrets/persistent-volume-binder-token-trgqc
    uid: 7149ce3b-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp3YjJRdFoyRnlZbUZuWlMxamIyeHNaV04wYjNJdGRHOXJaVzR0ZUd0emRuTWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2ljRzlrTFdkaGNtSmhaMlV0WTI5c2JHVmpkRzl5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTnpBNE1HWmhOREV0TmpaaE5DMHhNV1ZoTFdJNE1HSXROREl3TVRCaE9EQXdNamc0SWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbkJ2WkMxbllYSmlZV2RsTFdOdmJHeGxZM1J2Y2lKOS5qbksyamVTcS1GZDNsT2FZRVpSTXN3TjBVWF9UZzdJck01SkphVzFFbGZzM0pYVjVOX2lTS1N0MVBhY1VxckZYTWVVSVNCeVY1a1NYMnJHNnBzY3hZNEsybmlMZEJIMm5NMUZHVHYtaExtSzZUSWt4b1M0ZHRqSmJuSVVjS3RwR3lYdEhwR1lKZVlfYW5wTEc0N3VkMkpFc1gxUml3OURqZkxWSHRIaEtOZ1N1R2RwOVc2Z0NUMERwM2ludm4tSm1pUVR4aExzZmZPSmx1UmNlS1BqcWs2a0RzSXp6dEtEZTRYOTY3QVZzc0h5NGVUWHNEU0VZR1A2SHQxUDBSSHp2SkR6LXJIdGRsWklkM0J4Q09MWFl3NFRLRW8ycjUyX1psYnZBR1k4R1R2SFlTSFB3Vkt2RndJSjN4ZXAwbl9rWklyRVMwQWo2YTZmMy01YWJ5SXd5Vnc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: pod-garbage-collector
      kubernetes.io/service-account.uid: 7080fa41-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: pod-garbage-collector-token-xksvs
    namespace: kube-system
    resourceVersion: "207"
    selfLink: /api/v1/namespaces/kube-system/secrets/pod-garbage-collector-token-xksvs
    uid: 7083fad2-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp3Y205dFpYUm9aWFZ6TFhSdkxYTmtMWFJ2YTJWdUxXZzNjbXRySWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW5CeWIyMWxkR2hsZFhNdGRHOHRjMlFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzT1RFNU0ySmxZUzAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZjSEp2YldWMGFHVjFjeTEwYnkxelpDSjkuSm1hX2YtdEJIY29yY3hBUUs2U2w2dnZDdjhYa0FzOTFlMkpacGN2SWtJSHJnTXNDTTlzN1pxZTk0MUs4Rjl0WUQzblptaXo1bUNicnZrdFpzUjFaQk5zOWRVSkJYNGM1RUd2T3FoLTZkOVBnSXFYa1FaY0JUc2wyZUJzLUpxdFhnZTJZM1pVb05ZQ1JDZFAtX1hqUnc3NUk5ckZlbDg1UjB2dzlqX0JhRm4xN2Nna1BIYnJJekttZWI5NDlvbkc1dGhPTm80ajczUlk3U2hXdWU3ZnRjQUdvaExKRldqVG5FTnNPS2Rfa1piZ1ppbEgxb0MtZXh0YVlyM0dwMVoxc3pMa1ZMVUJQcEJTbXBXM05ZYl9FSzM0UE02Ry1NdjY5Ti16bHRrQzVYRkc3RW9LRGZvSV9xS0xfSjE0YWpoaEs2ZmdyTXRZNDJmR2JCa2lzNF83b3pB
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: prometheus-to-sd
      kubernetes.io/service-account.uid: 79193bea-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:18Z"
    name: prometheus-to-sd-token-h7rkk
    namespace: kube-system
    resourceVersion: "386"
    selfLink: /api/v1/namespaces/kube-system/secrets/prometheus-to-sd-token-h7rkk
    uid: 791a1a34-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp3ZGkxd2NtOTBaV04wYVc5dUxXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dFlucG9kSEFpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pY0hZdGNISnZkR1ZqZEdsdmJpMWpiMjUwY205c2JHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lOekkzWkdVd09HUXROalpoTkMweE1XVmhMV0k0TUdJdE5ESXdNVEJoT0RBd01qZzRJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9uQjJMWEJ5YjNSbFkzUnBiMjR0WTI5dWRISnZiR3hsY2lKOS5sTkFXOTM4RENoYkFSa0JqMldMYUwtX3BtZml6X1lHMU90MnJkY1REc3dUUWx2MjZuTGZBbjA4UVVzN040VXdKZHpXUm4yendBNlhfdmJwcjJyQUdSak5JLVhDSVotUWZDQlc4czhJbE9LRGswWFZEVmp4M0lvR0wtLXVLZWtIMkMwQzVTNU8tT3pDT0VDMGdRcFl0WkQ5VXNwdjg4MXEwS0lmdEtNd2F2azN4cWhpZVN6OWlQLVp2Y1dVMHdNRjh2cEt1VEEydDQ3Z0pnSUFKVVhFMEJwQ2ZGbHlkWXVBVnQ5YlJBNnVxTEw3Nld1cXhNdXhSZ2hOLXVsM3BESDNSWVhsX2lKUV9kZTBoaTMzVVVHWFk1UHdsNHhJbU5OU05waUgxVXZjTm5UUmQxMzNFQk1yVmNsNlk0bFZvXzZVM0JtVjVLX1hWSHI3Q1dIUlBMb0lDNGc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: pv-protection-controller
      kubernetes.io/service-account.uid: 727de08d-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:06Z"
    name: pv-protection-controller-token-bzhtp
    namespace: kube-system
    resourceVersion: "240"
    selfLink: /api/v1/namespaces/kube-system/secrets/pv-protection-controller-token-bzhtp
    uid: 72810a30-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp3ZG1NdGNISnZkR1ZqZEdsdmJpMWpiMjUwY205c2JHVnlMWFJ2YTJWdUxXNWtOSGMzSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWJtRnRaU0k2SW5CMll5MXdjbTkwWldOMGFXOXVMV052Ym5SeWIyeHNaWElpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1MWFXUWlPaUkzTUdZeVl6QmpOUzAyTm1FMExURXhaV0V0WWpnd1lpMDBNakF4TUdFNE1EQXlPRGdpTENKemRXSWlPaUp6ZVhOMFpXMDZjMlZ5ZG1salpXRmpZMjkxYm5RNmEzVmlaUzF6ZVhOMFpXMDZjSFpqTFhCeWIzUmxZM1JwYjI0dFkyOXVkSEp2Ykd4bGNpSjkucGh4RnlvLWxTTUJDRHVCdTllMDRLLWo3T3FXUTBxY1ZBSDdtc09CZ29mQzU0WWk1WGc2dWhlclZKU05oTmdZdFNpZ3N1N0RGOGZJekozNnVXWjFCZ2VJTVNwSWhaWXVCWGdmejlTMUVuNG5fVU5TMnB5Si1GeHIwbzRVaFRFU0w3M19IQS11c3RSUTFQTmxIWS1nbXQtMnJfenJiRnhwcHlLVDJxZDJKd3E5QVpXNFBGZGc4TWRyTU9RUTFNbS13R0libHhYX0xaS3FXZUFKTlRYb2h4TzF2aGZBNjdMaXA0Umwybk9EZl9VenNFS0ZNOUgtUzRpa2xlM3ptMFhvU0RfV0dzbHJzNFZDX2xYWVdqaWRVRE5oUVZjblhXLXFCZ2tINEM0U2JYMGR0RGVQNG01QnhlYU01M2ZVa3VMaUxBWmtFbzRFLXZEOW84eG1sd3BzOU1n
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: pvc-protection-controller
      kubernetes.io/service-account.uid: 70f2c0c5-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: pvc-protection-controller-token-nd4w7
    namespace: kube-system
    resourceVersion: "215"
    selfLink: /api/v1/namespaces/kube-system/secrets/pvc-protection-controller-token-nd4w7
    uid: 70f768ec-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp5WlhCc2FXTmhjMlYwTFdOdmJuUnliMnhzWlhJdGRHOXJaVzR0YlRKMmVIRWlMQ0pyZFdKbGNtNWxkR1Z6TG1sdkwzTmxjblpwWTJWaFkyTnZkVzUwTDNObGNuWnBZMlV0WVdOamIzVnVkQzV1WVcxbElqb2ljbVZ3YkdsallYTmxkQzFqYjI1MGNtOXNiR1Z5SWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTnpBd01qVmtOREl0TmpaaE5DMHhNV1ZoTFdJNE1HSXROREl3TVRCaE9EQXdNamc0SWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tdDFZbVV0YzNsemRHVnRPbkpsY0d4cFkyRnpaWFF0WTI5dWRISnZiR3hsY2lKOS5LZXdZcmI2WDA5OXRyenZRYXhrSktCdWJmbmlVY0g0OTFjN2luVGJiYllSREJaaDdBRUwxemRwVE1DTjlYWHFPM3lMQl9qRk5nLVc3Q3pQSmZ2cElOWXVZX3FJZFVxOXBLM2M3Wlh6cjBQTEFDOC01SWRSeGhxZ2JQU19ZR3haeVlqQVdOVEc5QTM0VEVZNUZlTWdkVnl6REhTekpLOHNTbVE1akxTQWhNN3JfUnJWT2VmS0h5NFFORjl2aFJ3NnpUMXdJbjNyOEhLVmRZMEs3NXpHOGVnalBWc2lmNFUwclZPYkVkbGFfb21DQngyNlZnckswRDg1ODZaQzJIbnBmdE9aaUd2blM4SzRHLWI5ZEpEcGlTdk1ReUcycjJoZDVfMW5uS2JZbjNLVDBLUTBtLTNpLWhzM1BfNnFBN243bmlkdThoQnFIWW5wZk84Z0xNZllieXc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: replicaset-controller
      kubernetes.io/service-account.uid: 70025d42-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: replicaset-controller-token-m2vxq
    namespace: kube-system
    resourceVersion: "197"
    selfLink: /api/v1/namespaces/kube-system/secrets/replicaset-controller-token-m2vxq
    uid: 700794e3-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp5WlhCc2FXTmhkR2x2YmkxamIyNTBjbTlzYkdWeUxYUnZhMlZ1TFRSMGFEVTVJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1Ym1GdFpTSTZJbkpsY0d4cFkyRjBhVzl1TFdOdmJuUnliMnhzWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lJMk9USmlNakpqTnkwMk5tRTBMVEV4WldFdFlqZ3dZaTAwTWpBeE1HRTRNREF5T0RnaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2Y21Wd2JHbGpZWFJwYjI0dFkyOXVkSEp2Ykd4bGNpSjkuUjZ4bTlaYUJsMVk0UkFsRlZCd2VXeUhRUUc0XzNfQTVFM3VZNEZ6V0hvcHNoYXU5LVlMVUtpUXozM2paTWJ5TEluYkh4YjlVNVRzZEVYdWdQSXZyajdqMUJVREFta0ZfT01RNlBGRENJY0lpSHF6Vko0TUVUbHRTWGdaMEJwTks0SUl2VFd6V2Q3SG9pOGNmczNWbVMxX1hSVjlBMXFkdHQyM3Vfb1hBaEc3ajhWWHphX1FTOE9wVE9zdUt1c3dMNE5Ea0w3MGZ5QTBtUlF4WjFUQU4xNFBqN2hlenlZNTIxQnprXzhmLUVUelUwT1k1U0FJZHRzNzRUYUFpQzJISkhBWmlZX3VfbnVXY2oyaWpMT2V1YnhfWnVySFk0YXN6YkpubG9iZmdMdGNUM18yVXo4UmU2XzZ2TWdPY1NTNHNZQXN1dXhsSVh0Z3lmQ3dGdmRFU3hR
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: replication-controller
      kubernetes.io/service-account.uid: 692b22c7-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: replication-controller-token-4th59
    namespace: kube-system
    resourceVersion: "154"
    selfLink: /api/v1/namespaces/kube-system/secrets/replication-controller-token-4th59
    uid: 692f275f-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp5WlhOdmRYSmpaWEYxYjNSaExXTnZiblJ5YjJ4c1pYSXRkRzlyWlc0dE5XWnFhbTRpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pY21WemIzVnlZMlZ4ZFc5MFlTMWpiMjUwY205c2JHVnlJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1ZFdsa0lqb2lObVkxWVdZM09EY3ROalpoTkMweE1XVmhMV0k0TUdJdE5ESXdNVEJoT0RBd01qZzRJaXdpYzNWaUlqb2ljM2x6ZEdWdE9uTmxjblpwWTJWaFkyTnZkVzUwT210MVltVXRjM2x6ZEdWdE9uSmxjMjkxY21ObGNYVnZkR0V0WTI5dWRISnZiR3hsY2lKOS5wa3dPLWNLU1dRbkZjV0Y3Q011cHltbEJVa3U0U3dNbktDVTRpek5Wd21sUDRIUEdUZTFqVEx3TmE0LUZ6eVFvdmlUeDFsT0JxM0FCOEpTVGthS3puTVJLTzRvb296SXF5aDN3QXNiZ2hvUGFCcU9XQ3FzZU8tZFNYZmpCMlV6LTI2cmFvdVZUX2tXeGZ3S1hRdXB5U0s1TlZ3WFFQVTN4SzE4S1I5eEZfXzVWX3psSTRVM0tBa3ZwWV9laDhTVFU2SHpiblA5cWZra3kxcDZFMkZJOG12cFhock1kek9MeEo2cWRqOTdfMGJtcG5fQmhfcENSNTNHcnp5NkR3dzZOWDYxSjhCR3p1Y29xTml3WUpfcnBnclF6UlBQOTNGdW5yRm1WdzQtX2tyRWZFTFJNc29aZUhyLUhqclZaY0FyZDdLemxGTVNLLWFKWEFJRVhYSHBiWHc=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: resourcequota-controller
      kubernetes.io/service-account.uid: 6f5af787-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: resourcequota-controller-token-5fjjn
    namespace: kube-system
    resourceVersion: "178"
    selfLink: /api/v1/namespaces/kube-system/secrets/resourcequota-controller-token-5fjjn
    uid: 6facde62-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp6WlhKMmFXTmxMV0ZqWTI5MWJuUXRZMjl1ZEhKdmJHeGxjaTEwYjJ0bGJpMXVjbmR0YmlJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExtNWhiV1VpT2lKelpYSjJhV05sTFdGalkyOTFiblF0WTI5dWRISnZiR3hsY2lJc0ltdDFZbVZ5Ym1WMFpYTXVhVzh2YzJWeWRtbGpaV0ZqWTI5MWJuUXZjMlZ5ZG1salpTMWhZMk52ZFc1MExuVnBaQ0k2SWpabVpXRTJOV1UzTFRZMllUUXRNVEZsWVMxaU9EQmlMVFF5TURFd1lUZ3dNREk0T0NJc0luTjFZaUk2SW5ONWMzUmxiVHB6WlhKMmFXTmxZV05qYjNWdWREcHJkV0psTFhONWMzUmxiVHB6WlhKMmFXTmxMV0ZqWTI5MWJuUXRZMjl1ZEhKdmJHeGxjaUo5LkpVNW5RMG5fUmIzVUxUb2pNalQtMFlaNS1XdFdmOEU5eDlsaE82Q2M4VW05REFrdmJvVjU3bExSZXY0VGFyM1BNcmhoRTgzODM4SmNKNC02aThQb1pRc1UxcW96RS16MXZIYUluYzV5Y3Uwa3h1S09DTVVRZTYxYUJ5SzRoQjNTZUVRa21iMDFpSjlvZkx6X3k5YTRKaW11MEo4ZGFBRTJ5RmlWNFhsWUlJYWc4cHpuSmpaYk5TT085bV9razNOQ3Rsb2cwRHlUSlBoV0dfMHQxNjNyVkFaaVQ2ZEszY0VBaW1JRS1teGxUUWJ1VmZWRzNVX0o0VW9SRDdUMjR5bUdHQ3ZmN3JxT2FPTExINlJhaVhFMWx3TWhZU3lSUTRlZ0FQWGRNOEU3azIxeUpHcXRmRFFwTUxrYW9qM1daUWdmTDdOazFCSFQtaVNpVEZhTDlCbHJfdw==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: service-account-controller
      kubernetes.io/service-account.uid: 6fea65e7-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: service-account-controller-token-nrwmn
    namespace: kube-system
    resourceVersion: "190"
    selfLink: /api/v1/namespaces/kube-system/secrets/service-account-controller-token-nrwmn
    uid: 6fefd647-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp6WlhKMmFXTmxMV052Ym5SeWIyeHNaWEl0ZEc5clpXNHRaMlJvTkdRaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWMyVnlkbWxqWlMxamIyNTBjbTlzYkdWeUlpd2lhM1ZpWlhKdVpYUmxjeTVwYnk5elpYSjJhV05sWVdOamIzVnVkQzl6WlhKMmFXTmxMV0ZqWTI5MWJuUXVkV2xrSWpvaU5tWmpPVFExWVRRdE5qWmhOQzB4TVdWaExXSTRNR0l0TkRJd01UQmhPREF3TWpnNElpd2ljM1ZpSWpvaWMzbHpkR1Z0T25ObGNuWnBZMlZoWTJOdmRXNTBPbXQxWW1VdGMzbHpkR1Z0T25ObGNuWnBZMlV0WTI5dWRISnZiR3hsY2lKOS5vUFRJVkhhbTB5Qk81Yi1rUXNnaXExX3I4QjkzZHM2Y1pITWtTejlzS0tCVUF0OWVGb25wcE11bVBjX25ZS3pYMF82cjg3eW5mVlNVZFhnSE0yd1RwaDQxSk1QS18zd2lsb3F6Sl9PcUU5eHNKQTk0dkFxMF9aekR0M2d2Nm1Xb29tTG9FejBRUzBFdGg5N2E2cVMyZm9FZEY4YmtwT2xmYnZKNlpJa3lKQjRycEowZHJXeUZxQ3Uxc2JkZ2o3emREMGZROUxSSzVGMjZNZTlxWERGYjdVU3BCU3RyaFRfTHQ5c2VqbDBVWkRjOVdPV3JlcDg5ZzJ0c0R1NXdkY0t3QXdHS3U1TmRsX0NkZFVqWVd0QkVCTmZpNUx4Nm9mNG5CUk9wV1RCYzhfeEM1WFhsTE9BMmc1TkQ4aTUwZTFNODdvVmJxbGhqZnF3c2xzQXZqb003dVE=
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: service-controller
      kubernetes.io/service-account.uid: 6fc945a4-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: service-controller-token-gdh4d
    namespace: kube-system
    resourceVersion: "181"
    selfLink: /api/v1/namespaces/kube-system/secrets/service-controller-token-gdh4d
    uid: 6fcc9ee5-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUp6ZEdGMFpXWjFiSE5sZEMxamIyNTBjbTlzYkdWeUxYUnZhMlZ1TFcxeFkyNTRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpYSjJhV05sTFdGalkyOTFiblF1Ym1GdFpTSTZJbk4wWVhSbFpuVnNjMlYwTFdOdmJuUnliMnhzWlhJaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lJMk9UTTBZakk0WlMwMk5tRTBMVEV4WldFdFlqZ3dZaTAwTWpBeE1HRTRNREF5T0RnaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZhM1ZpWlMxemVYTjBaVzA2YzNSaGRHVm1kV3h6WlhRdFkyOXVkSEp2Ykd4bGNpSjkuTEJVYmVfTHJwVTNadU1QYjMybG9oYUFNWkQwUjE3ZGRZNDBjWE84cWI4WDMzREhXeDZpOE51anFMQXVpUkJrcG1jTE1teVhSS1Y2UFZURGJPRWJTZnZtalgxVVBZNFltU1Y0Tk9QX21jMzkzM2psdHAzOHlyVWZJNENzR3VTNUFzRVRmRklsYWI2aC10Y3N1a3JxZ3ZZTXl5TDlhdVJvQTh2eWhLZXBjdlBWa2o1SVRiQ0FzUHVLUWRfX01Jd1YtbDJ6blk3U0xEek81dzNuOUc0d1hLZ0UwUFVqckxZdFpGSmNtOHdRc0E3eUF4NTB6Y0FQZFNra3ZkWmg3WXVXaW5uTGh3TS1xcWo4OGNPQk1EM2xfR1NCMWdDOU53UzZZMFBQQks4ak1veXFsYU53UmZsNDJaNzBRR2VReElYZThBOFd0OEdzaGttWGxUVFZHc3A2Wl9n
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: statefulset-controller
      kubernetes.io/service-account.uid: 6934b28e-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: statefulset-controller-token-mqcnx
    namespace: kube-system
    resourceVersion: "157"
    selfLink: /api/v1/namespaces/kube-system/secrets/statefulset-controller-token-mqcnx
    uid: 69380924-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
- apiVersion: v1
  data:
    ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    namespace: a3ViZS1zeXN0ZW0=
    token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklpSjkuZXlKcGMzTWlPaUpyZFdKbGNtNWxkR1Z6TDNObGNuWnBZMlZoWTJOdmRXNTBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5dVlXMWxjM0JoWTJVaU9pSnJkV0psTFhONWMzUmxiU0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVmpjbVYwTG01aGJXVWlPaUowZEd3dFkyOXVkSEp2Ykd4bGNpMTBiMnRsYmkxMk5IYzFaaUlzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG01aGJXVWlPaUowZEd3dFkyOXVkSEp2Ykd4bGNpSXNJbXQxWW1WeWJtVjBaWE11YVc4dmMyVnlkbWxqWldGalkyOTFiblF2YzJWeWRtbGpaUzFoWTJOdmRXNTBMblZwWkNJNklqWTVNMlJsWm1VeExUWTJZVFF0TVRGbFlTMWlPREJpTFRReU1ERXdZVGd3TURJNE9DSXNJbk4xWWlJNkluTjVjM1JsYlRwelpYSjJhV05sWVdOamIzVnVkRHByZFdKbExYTjVjM1JsYlRwMGRHd3RZMjl1ZEhKdmJHeGxjaUo5LnNWeTZfZ1ZpeVZYdlFOZ3JSSnQxcDNSZUM3a1RsTEs4WFQtbkZ2QlRDRGVlazJLUlNqWjFpOFdJS0h3TWgtTkhsN1hSd2JaZ1dMOHZSanRaOTlGSGphUnFzWUJsUE1ZR0c3SzJhc2diMWV1RkVmM2x0RHRtTDNqQzJveGp4aGlRbHJ2bmJpMWJTblVQNjhtU1RpMFN6Tk90aVRMS0lwTk1NVXc2eWxtZnNPUnJrT3VmOG5ZWlV3VmRYY25TeXg5MXBzZDhnU29yOTRYcjBHaDlRMkJlX1VMQ0VnZDdHY0QwNDU4WjlZX1NfRUxILUhibks2cXpybjBjaXdEdVRpZ2h6ZzNENHZvRjFJWS1Ed0Fwd21zSXBHLXhEV1FfNWNBTlVORzZMd25FUnJwd0U2SmFOUmtfZS1vakxtUm1Oc2JQekZfdElFUXdvYjgzQjE2NV9GRGZ0UQ==
  kind: Secret
  metadata:
    annotations:
      kubernetes.io/service-account.name: ttl-controller
      kubernetes.io/service-account.uid: 693defe1-66a4-11ea-b80b-42010a800288
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: ttl-controller-token-v4w5f
    namespace: kube-system
    resourceVersion: "160"
    selfLink: /api/v1/namespaces/kube-system/secrets/ttl-controller-token-v4w5f
    uid: 694068ae-66a4-11ea-b80b-42010a800288
  type: kubernetes.io/service-account-token
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== serviceaccounts manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default
    namespace: default
    resourceVersion: "265"
    selfLink: /api/v1/namespaces/default/serviceaccounts/default
    uid: 72db0e28-66a4-11ea-b80b-42010a800288
  secrets:
  - name: default-token-l6wj4
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default
    namespace: kube-node-lease
    resourceVersion: "264"
    selfLink: /api/v1/namespaces/kube-node-lease/serviceaccounts/default
    uid: 72c7abb6-66a4-11ea-b80b-42010a800288
  secrets:
  - name: default-token-58w45
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default
    namespace: kube-public
    resourceVersion: "259"
    selfLink: /api/v1/namespaces/kube-public/serviceaccounts/default
    uid: 72bf349e-66a4-11ea-b80b-42010a800288
  secrets:
  - name: default-token-4n94f
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: attachdetach-controller
    namespace: kube-system
    resourceVersion: "237"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/attachdetach-controller
    uid: 71dfb0e7-66a4-11ea-b80b-42010a800288
  secrets:
  - name: attachdetach-controller-token-w6q2n
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: certificate-controller
    namespace: kube-system
    resourceVersion: "247"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/certificate-controller
    uid: 728fd610-66a4-11ea-b80b-42010a800288
  secrets:
  - name: certificate-controller-token-bxhvm
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: cloud-provider
    namespace: kube-system
    resourceVersion: "152"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/cloud-provider
    uid: 69177ce7-66a4-11ea-b80b-42010a800288
  secrets:
  - name: cloud-provider-token-lwsnk
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: clusterrole-aggregation-controller
    namespace: kube-system
    resourceVersion: "185"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/clusterrole-aggregation-controller
    uid: 6fd46311-66a4-11ea-b80b-42010a800288
  secrets:
  - name: clusterrole-aggregation-controller-token-7mjsd
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: cronjob-controller
    namespace: kube-system
    resourceVersion: "219"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/cronjob-controller
    uid: 710a80d3-66a4-11ea-b80b-42010a800288
  secrets:
  - name: cronjob-controller-token-hd547
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: daemon-set-controller
    namespace: kube-system
    resourceVersion: "244"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/daemon-set-controller
    uid: 72882afc-66a4-11ea-b80b-42010a800288
  secrets:
  - name: daemon-set-controller-token-wdklz
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:07Z"
    name: default
    namespace: kube-system
    resourceVersion: "260"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/default
    uid: 72b46c6f-66a4-11ea-b80b-42010a800288
  secrets:
  - name: default-token-22rgh
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: deployment-controller
    namespace: kube-system
    resourceVersion: "230"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/deployment-controller
    uid: 7193d3a4-66a4-11ea-b80b-42010a800288
  secrets:
  - name: deployment-controller-token-lxxd4
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: disruption-controller
    namespace: kube-system
    resourceVersion: "233"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/disruption-controller
    uid: 71b98cb0-66a4-11ea-b80b-42010a800288
  secrets:
  - name: disruption-controller-token-jwkl6
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: endpoint-controller
    namespace: kube-system
    resourceVersion: "188"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/endpoint-controller
    uid: 6fdf908f-66a4-11ea-b80b-42010a800288
  secrets:
  - name: endpoint-controller-token-x4r9h
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"event-exporter","kubernetes.io/cluster-service":"true"},"name":"event-exporter-sa","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: event-exporter
      kubernetes.io/cluster-service: "true"
    name: event-exporter-sa
    namespace: kube-system
    resourceVersion: "346"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/event-exporter-sa
    uid: 78b98113-66a4-11ea-b80b-42010a800288
  secrets:
  - name: event-exporter-sa-token-x58h2
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: expand-controller
    namespace: kube-system
    resourceVersion: "205"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/expand-controller
    uid: 705a90db-66a4-11ea-b80b-42010a800288
  secrets:
  - name: expand-controller-token-654rl
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"fluentd-gcp","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: fluentd-gcp
    namespace: kube-system
    resourceVersion: "362"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/fluentd-gcp
    uid: 78e0caa4-66a4-11ea-b80b-42010a800288
  secrets:
  - name: fluentd-gcp-token-85hzc
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"fluentd-gcp-scaler","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: fluentd-gcp-scaler
    namespace: kube-system
    resourceVersion: "367"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/fluentd-gcp-scaler
    uid: 78f14630-66a4-11ea-b80b-42010a800288
  secrets:
  - name: fluentd-gcp-scaler-token-8gdvq
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: generic-garbage-collector
    namespace: kube-system
    resourceVersion: "211"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/generic-garbage-collector
    uid: 70a7114f-66a4-11ea-b80b-42010a800288
  secrets:
  - name: generic-garbage-collector-token-rj8c9
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"heapster","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: heapster
    namespace: kube-system
    resourceVersion: "328"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/heapster
    uid: 77d9bc90-66a4-11ea-b80b-42010a800288
  secrets:
  - name: heapster-token-x8jx5
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: horizontal-pod-autoscaler
    namespace: kube-system
    resourceVersion: "201"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/horizontal-pod-autoscaler
    uid: 70125b10-66a4-11ea-b80b-42010a800288
  secrets:
  - name: horizontal-pod-autoscaler-token-jv567
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: job-controller
    namespace: kube-system
    resourceVersion: "195"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/job-controller
    uid: 6ff73d96-66a4-11ea-b80b-42010a800288
  secrets:
  - name: job-controller-token-k6pfq
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kube-dns","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:14Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kube-dns
    namespace: kube-system
    resourceVersion: "287"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/kube-dns
    uid: 76afdfd3-66a4-11ea-b80b-42010a800288
  secrets:
  - name: kube-dns-token-2j6rq
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"kube-dns-autoscaler","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:21Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: kube-dns-autoscaler
    namespace: kube-system
    resourceVersion: "442"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/kube-dns-autoscaler
    uid: 7b6f1f31-66a4-11ea-b80b-42010a800288
  secrets:
  - name: kube-dns-autoscaler-token-mfpqp
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"metadata-agent","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: metadata-agent
    namespace: kube-system
    resourceVersion: "372"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/metadata-agent
    uid: 78f88ace-66a4-11ea-b80b-42010a800288
  secrets:
  - name: metadata-agent-token-9jjpn
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true"},"name":"metadata-proxy","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: metadata-proxy
      kubernetes.io/cluster-service: "true"
    name: metadata-proxy
    namespace: kube-system
    resourceVersion: "393"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/metadata-proxy
    uid: 793d4ad1-66a4-11ea-b80b-42010a800288
  secrets:
  - name: metadata-proxy-token-jckjg
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"metrics-server","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: metrics-server
    namespace: kube-system
    resourceVersion: "403"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/metrics-server
    uid: 7971f663-66a4-11ea-b80b-42010a800288
  secrets:
  - name: metrics-server-token-x6d9m
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:05Z"
    name: namespace-controller
    namespace: kube-system
    resourceVersion: "227"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/namespace-controller
    uid: 716d633f-66a4-11ea-b80b-42010a800288
  secrets:
  - name: namespace-controller-token-2nfkf
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: node-controller
    namespace: kube-system
    resourceVersion: "164"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/node-controller
    uid: 694854c6-66a4-11ea-b80b-42010a800288
  secrets:
  - name: node-controller-token-rhvt2
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: persistent-volume-binder
    namespace: kube-system
    resourceVersion: "223"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/persistent-volume-binder
    uid: 71471860-66a4-11ea-b80b-42010a800288
  secrets:
  - name: persistent-volume-binder-token-trgqc
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:03Z"
    name: pod-garbage-collector
    namespace: kube-system
    resourceVersion: "208"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/pod-garbage-collector
    uid: 7080fa41-66a4-11ea-b80b-42010a800288
  secrets:
  - name: pod-garbage-collector-token-xksvs
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"prometheus-to-sd","namespace":"kube-system"}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: prometheus-to-sd
    namespace: kube-system
    resourceVersion: "387"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/prometheus-to-sd
    uid: 79193bea-66a4-11ea-b80b-42010a800288
  secrets:
  - name: prometheus-to-sd-token-h7rkk
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:06Z"
    name: pv-protection-controller
    namespace: kube-system
    resourceVersion: "241"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/pv-protection-controller
    uid: 727de08d-66a4-11ea-b80b-42010a800288
  secrets:
  - name: pv-protection-controller-token-bzhtp
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:04Z"
    name: pvc-protection-controller
    namespace: kube-system
    resourceVersion: "216"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/pvc-protection-controller
    uid: 70f2c0c5-66a4-11ea-b80b-42010a800288
  secrets:
  - name: pvc-protection-controller-token-nd4w7
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: replicaset-controller
    namespace: kube-system
    resourceVersion: "198"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/replicaset-controller
    uid: 70025d42-66a4-11ea-b80b-42010a800288
  secrets:
  - name: replicaset-controller-token-m2vxq
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: replication-controller
    namespace: kube-system
    resourceVersion: "155"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/replication-controller
    uid: 692b22c7-66a4-11ea-b80b-42010a800288
  secrets:
  - name: replication-controller-token-4th59
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:01Z"
    name: resourcequota-controller
    namespace: kube-system
    resourceVersion: "179"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/resourcequota-controller
    uid: 6f5af787-66a4-11ea-b80b-42010a800288
  secrets:
  - name: resourcequota-controller-token-5fjjn
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: service-account-controller
    namespace: kube-system
    resourceVersion: "191"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/service-account-controller
    uid: 6fea65e7-66a4-11ea-b80b-42010a800288
  secrets:
  - name: service-account-controller-token-nrwmn
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:05:02Z"
    name: service-controller
    namespace: kube-system
    resourceVersion: "182"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/service-controller
    uid: 6fc945a4-66a4-11ea-b80b-42010a800288
  secrets:
  - name: service-controller-token-gdh4d
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: statefulset-controller
    namespace: kube-system
    resourceVersion: "158"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/statefulset-controller
    uid: 6934b28e-66a4-11ea-b80b-42010a800288
  secrets:
  - name: statefulset-controller-token-mqcnx
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    creationTimestamp: "2020-03-15T10:04:51Z"
    name: ttl-controller
    namespace: kube-system
    resourceVersion: "161"
    selfLink: /api/v1/namespaces/kube-system/serviceaccounts/ttl-controller
    uid: 693defe1-66a4-11ea-b80b-42010a800288
  secrets:
  - name: ttl-controller-token-v4w5f
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== services manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2020-03-17T16:59:54Z"
    labels:
      run: essbaseservice
    name: essbaseservice
    namespace: default
    resourceVersion: "687712"
    selfLink: /api/v1/namespaces/default/services/essbaseservice
    uid: b94abd5f-6870-11ea-b004-42010a80008c
  spec:
    clusterIP: 10.0.3.216
    externalTrafficPolicy: Cluster
    ports:
    - nodePort: 30669
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      run: essbaseservice
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 35.184.51.106
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "145"
    selfLink: /api/v1/namespaces/default/services/kubernetes
    uid: 6896dec3-66a4-11ea-b80b-42010a800288
  spec:
    clusterIP: 10.0.0.1
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"glbc","kubernetes.io/cluster-service":"true","kubernetes.io/name":"GLBCDefaultBackend"},"name":"default-http-backend","namespace":"kube-system"},"spec":{"ports":[{"name":"http","port":80,"protocol":"TCP","targetPort":8080}],"selector":{"k8s-app":"glbc"},"type":"NodePort"}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: glbc
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: GLBCDefaultBackend
    name: default-http-backend
    namespace: kube-system
    resourceVersion: "310"
    selfLink: /api/v1/namespaces/kube-system/services/default-http-backend
    uid: 7755f395-66a4-11ea-b80b-42010a800288
  spec:
    clusterIP: 10.0.8.172
    externalTrafficPolicy: Cluster
    ports:
    - name: http
      nodePort: 30456
      port: 80
      protocol: TCP
      targetPort: 8080
    selector:
      k8s-app: glbc
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true","kubernetes.io/name":"Heapster"},"name":"heapster","namespace":"kube-system"},"spec":{"ports":[{"port":80,"targetPort":8082}],"selector":{"k8s-app":"heapster"}}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Heapster
    name: heapster
    namespace: kube-system
    resourceVersion: "342"
    selfLink: /api/v1/namespaces/kube-system/services/heapster
    uid: 78a6b88d-66a4-11ea-b80b-42010a800288
  spec:
    clusterIP: 10.0.12.82
    ports:
    - port: 80
      protocol: TCP
      targetPort: 8082
    selector:
      k8s-app: heapster
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kube-dns","kubernetes.io/cluster-service":"true","kubernetes.io/name":"KubeDNS"},"name":"kube-dns","namespace":"kube-system"},"spec":{"clusterIP":"10.0.0.10","ports":[{"name":"dns","port":53,"protocol":"UDP"},{"name":"dns-tcp","port":53,"protocol":"TCP"}],"selector":{"k8s-app":"kube-dns"}}}
    creationTimestamp: "2020-03-15T10:05:13Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: KubeDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "283"
    selfLink: /api/v1/namespaces/kube-system/services/kube-dns
    uid: 769dc852-66a4-11ea-b80b-42010a800288
  spec:
    clusterIP: 10.0.0.10
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true","kubernetes.io/name":"Metrics-server"},"name":"metrics-server","namespace":"kube-system"},"spec":{"ports":[{"port":443,"protocol":"TCP","targetPort":"https"}],"selector":{"k8s-app":"metrics-server"}}}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: Metrics-server
    name: metrics-server
    namespace: kube-system
    resourceVersion: "417"
    selfLink: /api/v1/namespaces/kube-system/services/metrics-server
    uid: 7a0a7c78-66a4-11ea-b80b-42010a800288
  spec:
    clusterIP: 10.0.5.68
    ports:
    - port: 443
      protocol: TCP
      targetPort: https
    selector:
      k8s-app: metrics-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== mutatingwebhookconfigurations manifests ========

apiVersion: v1
items:
- apiVersion: admissionregistration.k8s.io/v1beta1
  kind: MutatingWebhookConfiguration
  metadata:
    annotations:
      common-webhooks.networking.gke.io/webhook-name: pod-ready
    creationTimestamp: "2020-03-15T10:05:04Z"
    generation: 1
    labels:
      networking.gke.io/common-webhooks: "true"
    name: pod-ready.config.common-webhooks.networking.gke.io
    resourceVersion: "213"
    selfLink: /apis/admissionregistration.k8s.io/v1beta1/mutatingwebhookconfigurations/pod-ready.config.common-webhooks.networking.gke.io
    uid: 70e420c8-66a4-11ea-b80b-42010a800288
  webhooks:
  - admissionReviewVersions:
    - v1beta1
    clientConfig:
      caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURERENDQWZTZ0F3SUJBZ0lSQUxOYXNybmJJU0YxenRqTmJCd3JOOXd3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa016VTBaVEEyTkRBdE5HTm1OaTAwTlROa0xXRTFNVEV0WWpsaU4ySXlNakZrTTJaagpNQjRYRFRJd01ETXhOVEE1TURJek1sb1hEVEkxTURNeE5ERXdNREl6TWxvd0x6RXRNQ3NHQTFVRUF4TWtNelUwClpUQTJOREF0TkdObU5pMDBOVE5rTFdFMU1URXRZamxpTjJJeU1qRmtNMlpqTUlJQklqQU5CZ2txaGtpRzl3MEIKQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBMTFIZG1yK3liQmdYQytNVFF6cDg5Q0xQSktjOENxNGFLYjJMSWthbgpCS1ZVTHZDQ0pua3R5bG9KZGRhS2x2Y2toRnNsR0tzSXJrQmd5WnJWZmpoVmpMYU9RdzNBVXRvM0tmYzU1bmllClBEK2ZTQ0l2Tm4vOFhpVVZvQmZhYXhOczk3NldjVVBXQktIc2FWVGpSWEt5UVNxb0N5SFMvSmhvdm9nNEhybGcKUHJodTZiZ1pubHE3YUY1VEV5TWxWQ3hxYnhBaEdQbnFpUklvUDZEZ0NKN0ZwdFhZRzRWNm1FYmpvZHRDZXpINQpEb0hqbWVPUFYzMVZ5M01DY0ZsS2N5SGtGRkhMWXNKcGFnUHBNcmZQQjZ0NjdtOXY5STlJeEtmbkt5ME02K2c0CmhEUDBQbWhRODdBTllxYWcreHFKUWxTbXZoOHNPS1J4MFlIQkZYUUlWWE1pd3dJREFRQUJveU13SVRBT0JnTlYKSFE4QkFmOEVCQU1DQWdRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQQpHK2d5MGRWZVczQVBHbjJRNExtYkJ3NDZ1R2ttQjF1UGJDVTllNnUxVnU1aGIxNE5ONFRoYmI5SHA1eGtGbmUvCjN2aDFDYW5wZmJielMvbEsxdWh4VnpXRTkvbzlONmZXUXB1UVBMYUY2bTd3QWJvREdnanQvYWZ2bUtRcUx3cWsKcVBSZHVUUGlzTmdSbHY3akdhd1FwclpDOWVNWWdZTTBkVTdXTkZKMnU1anN0ejlxUS9mRk9NdmFJVmNRMHpHNQpLalVrc0ZBUEozQmc5dFBLY0VoWGdWZGJDNGxLc0VHRnI5b0pUeml6blJsWkFNUGFndGhqRTJtcmEwSGx4TjduCmZvZHdqOE1sVGdLaHp3aHpWYUhKT3YzNUtpRHBlMlFhZnkrMEFYWkhiN2twUWh2SjZObHFTdk42dys2dlJjQmoKMU91NUdpcDUxODFGc3NDK3NTcy94dz09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
      url: https://localhost:5443/webhook/pod-ready
    failurePolicy: Ignore
    name: pod-ready.common-webhooks.networking.gke.io
    namespaceSelector: {}
    rules:
    - apiGroups:
      - ""
      apiVersions:
      - v1
      operations:
      - CREATE
      resources:
      - pods
      scope: '*'
    sideEffects: Unknown
    timeoutSeconds: 30
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== customresourcedefinitions manifests ========

apiVersion: v1
items:
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    creationTimestamp: "2020-03-15T10:05:24Z"
    generation: 1
    name: backendconfigs.cloud.google.com
    resourceVersion: "483"
    selfLink: /apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/backendconfigs.cloud.google.com
    uid: 7cab1e9b-66a4-11ea-b80b-42010a800288
  spec:
    conversion:
      strategy: None
    group: cloud.google.com
    names:
      kind: BackendConfig
      listKind: BackendConfigList
      plural: backendconfigs
      singular: backendconfig
    scope: Namespaced
    validation:
      openAPIV3Schema:
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: BackendConfigSpec is the spec for a BackendConfig resource
            properties:
              cdn:
                description: CDNConfig contains configuration for CDN-enabled backends.
                properties:
                  cachePolicy:
                    description: CacheKeyPolicy contains configuration for how requests
                      to a CDN-enabled backend are cached.
                    properties:
                      includeHost:
                        description: If true, requests to different hosts will be
                          cached separately.
                        type: boolean
                      includeProtocol:
                        description: If true, http and https requests will be cached
                          separately.
                        type: boolean
                      includeQueryString:
                        description: If true, query string parameters are included
                          in the cache key according to QueryStringBlacklist and QueryStringWhitelist.
                          If neither is set, the entire query string is included and
                          if false the entire query string is excluded.
                        type: boolean
                      queryStringBlacklist:
                        description: Names of query strint parameters to exclude from
                          cache keys. All other parameters are included. Either specify
                          QueryStringBlacklist or QueryStringWhitelist, but not both.
                        items:
                          type: string
                        type: array
                      queryStringWhitelist:
                        description: Names of query string parameters to include in
                          cache keys. All other parameters are excluded. Either specify
                          QueryStringBlacklist or QueryStringWhitelist, but not both.
                        items:
                          type: string
                        type: array
                    type: object
                  enabled:
                    type: boolean
                required:
                - enabled
                type: object
              connectionDraining:
                description: ConnectionDrainingConfig contains configuration for connection
                  draining. For now the draining timeout. May manage more settings
                  in the future.
                properties:
                  drainingTimeoutSec:
                    description: Draining timeout in seconds.
                    format: int64
                    type: integer
                type: object
              iap:
                description: IAPConfig contains configuration for IAP-enabled backends.
                properties:
                  enabled:
                    type: boolean
                  oauthclientCredentials:
                    description: OAuthClientCredentials contains credentials for a
                      single IAP-enabled backend.
                    properties:
                      clientID:
                        description: Direct reference to OAuth client id.
                        type: string
                      clientSecret:
                        description: Direct reference to OAuth client secret.
                        type: string
                      secretName:
                        description: The name of a k8s secret which stores the OAuth
                          client id & secret.
                        type: string
                    required:
                    - secretName
                    type: object
                required:
                - enabled
                - oauthclientCredentials
                type: object
              securityPolicy:
                type: object
              sessionAffinity:
                description: SessionAffinityConfig contains configuration for stickyness
                  parameters.
                properties:
                  affinityCookieTtlSec:
                    format: int64
                    type: integer
                  affinityType:
                    type: string
                type: object
              timeoutSec:
                format: int64
                type: integer
            type: object
          status:
            type: object
    version: v1beta1
    versions:
    - name: v1beta1
      served: true
      storage: true
  status:
    acceptedNames:
      kind: BackendConfig
      listKind: BackendConfigList
      plural: backendconfigs
      singular: backendconfig
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:24Z"
      message: no conflicts found
      reason: NoConflicts
      status: "True"
      type: NamesAccepted
    - lastTransitionTime: null
      message: the initial names have been accepted
      reason: InitialNamesAccepted
      status: "True"
      type: Established
    storedVersions:
    - v1beta1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apiextensions.k8s.io/v1beta1","kind":"CustomResourceDefinition","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"managedcertificates.networking.gke.io"},"spec":{"group":"networking.gke.io","names":{"kind":"ManagedCertificate","plural":"managedcertificates","shortNames":["mcrt"],"singular":"managedcertificate"},"scope":"Namespaced","validation":{"openAPIV3Schema":{"properties":{"spec":{"properties":{"domains":{"items":{"maxLength":63,"pattern":"^(([a-zA-Z0-9]+|[a-zA-Z0-9][-a-zA-Z0-9]*[a-zA-Z0-9])\\.)+[a-zA-Z][-a-zA-Z0-9]*[a-zA-Z0-9]\\.?$","type":"string"},"maxItems":1,"type":"array"}}},"status":{"properties":{"certificateName":{"type":"string"},"certificateStatus":{"type":"string"},"domainStatus":{"items":{"properties":{"domain":{"type":"string"},"status":{"type":"string"}},"required":["domain","status"],"type":"object"},"type":"array"},"expireTime":{"format":"date-time","type":"string"}}}}}},"version":"v1beta1"}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: managedcertificates.networking.gke.io
    resourceVersion: "448"
    selfLink: /apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/managedcertificates.networking.gke.io
    uid: 7b7440ea-66a4-11ea-b80b-42010a800288
  spec:
    conversion:
      strategy: None
    group: networking.gke.io
    names:
      kind: ManagedCertificate
      listKind: ManagedCertificateList
      plural: managedcertificates
      shortNames:
      - mcrt
      singular: managedcertificate
    scope: Namespaced
    validation:
      openAPIV3Schema:
        properties:
          spec:
            properties:
              domains:
                items:
                  maxLength: 63
                  pattern: ^(([a-zA-Z0-9]+|[a-zA-Z0-9][-a-zA-Z0-9]*[a-zA-Z0-9])\.)+[a-zA-Z][-a-zA-Z0-9]*[a-zA-Z0-9]\.?$
                  type: string
                maxItems: 1
                type: array
          status:
            properties:
              certificateName:
                type: string
              certificateStatus:
                type: string
              domainStatus:
                items:
                  properties:
                    domain:
                      type: string
                    status:
                      type: string
                  required:
                  - domain
                  - status
                  type: object
                type: array
              expireTime:
                format: date-time
                type: string
    version: v1beta1
    versions:
    - name: v1beta1
      served: true
      storage: true
  status:
    acceptedNames:
      kind: ManagedCertificate
      listKind: ManagedCertificateList
      plural: managedcertificates
      shortNames:
      - mcrt
      singular: managedcertificate
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: no conflicts found
      reason: NoConflicts
      status: "True"
      type: NamesAccepted
    - lastTransitionTime: null
      message: the initial names have been accepted
      reason: InitialNamesAccepted
      status: "True"
      type: Established
    storedVersions:
    - v1beta1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apiextensions.k8s.io/v1beta1","kind":"CustomResourceDefinition","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"scalingpolicies.scalingpolicy.kope.io"},"spec":{"group":"scalingpolicy.kope.io","names":{"kind":"ScalingPolicy","plural":"scalingpolicies"},"scope":"Namespaced","version":"v1alpha1"}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: scalingpolicies.scalingpolicy.kope.io
    resourceVersion: "463"
    selfLink: /apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/scalingpolicies.scalingpolicy.kope.io
    uid: 7b99d098-66a4-11ea-b80b-42010a800288
  spec:
    conversion:
      strategy: None
    group: scalingpolicy.kope.io
    names:
      kind: ScalingPolicy
      listKind: ScalingPolicyList
      plural: scalingpolicies
      singular: scalingpolicy
    scope: Namespaced
    version: v1alpha1
    versions:
    - name: v1alpha1
      served: true
      storage: true
  status:
    acceptedNames:
      kind: ScalingPolicy
      listKind: ScalingPolicyList
      plural: scalingpolicies
      singular: scalingpolicy
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: no conflicts found
      reason: NoConflicts
      status: "True"
      type: NamesAccepted
    - lastTransitionTime: null
      message: the initial names have been accepted
      reason: InitialNamesAccepted
      status: "True"
      type: Established
    storedVersions:
    - v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    annotations:
      components.gke.io/component-name: updateinfo-crd
      components.gke.io/component-version: 1.0.1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apiextensions.k8s.io/v1beta1","kind":"CustomResourceDefinition","metadata":{"annotations":{"components.gke.io/component-name":"updateinfo-crd","components.gke.io/component-version":"1.0.1"},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"updateinfos.nodemanagement.gke.io"},"spec":{"group":"nodemanagement.gke.io","names":{"kind":"UpdateInfo","plural":"updateinfos","shortNames":["updinf"],"singular":"updateinfo"},"scope":"Namespaced","validation":{"openAPIV3Schema":{"properties":{"spec":{"properties":{"ValidUntil":{"type":"date"},"surgeNode":{"type":"string"},"targetNode":{"type":"string"},"type":{"type":"string"}},"type":"object"}},"type":"object"}},"versions":[{"name":"v1alpha1","served":true,"storage":true}]}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: updateinfos.nodemanagement.gke.io
    resourceVersion: "4938118"
    selfLink: /apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/updateinfos.nodemanagement.gke.io
    uid: 7b9ecaa8-66a4-11ea-b80b-42010a800288
  spec:
    conversion:
      strategy: None
    group: nodemanagement.gke.io
    names:
      kind: UpdateInfo
      listKind: UpdateInfoList
      plural: updateinfos
      shortNames:
      - updinf
      singular: updateinfo
    scope: Namespaced
    validation:
      openAPIV3Schema:
        properties:
          spec:
            properties:
              ValidUntil:
                type: date
              surgeNode:
                type: string
              targetNode:
                type: string
              type:
                type: string
            type: object
        type: object
    version: v1alpha1
    versions:
    - name: v1alpha1
      served: true
      storage: true
  status:
    acceptedNames:
      kind: UpdateInfo
      listKind: UpdateInfoList
      plural: updateinfos
      shortNames:
      - updinf
      singular: updateinfo
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: no conflicts found
      reason: NoConflicts
      status: "True"
      type: NamesAccepted
    - lastTransitionTime: null
      message: the initial names have been accepted
      reason: InitialNamesAccepted
      status: "True"
      type: Established
    storedVersions:
    - v1alpha1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== apiservices manifests ========

apiVersion: v1
items:
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.
    resourceVersion: "4"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.
    uid: 66e23aec-66a4-11ea-b80b-42010a800288
  spec:
    groupPriorityMinimum: 18000
    service: null
    version: v1
    versionPriority: 1
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.apps
    resourceVersion: "3"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.apps
    uid: 66e2bf59-66a4-11ea-b80b-42010a800288
  spec:
    group: apps
    groupPriorityMinimum: 17800
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.authentication.k8s.io
    resourceVersion: "11"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.authentication.k8s.io
    uid: 66e82029-66a4-11ea-b80b-42010a800288
  spec:
    group: authentication.k8s.io
    groupPriorityMinimum: 17700
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.authorization.k8s.io
    resourceVersion: "8"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.authorization.k8s.io
    uid: 66e82a09-66a4-11ea-b80b-42010a800288
  spec:
    group: authorization.k8s.io
    groupPriorityMinimum: 17600
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.autoscaling
    resourceVersion: "14"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.autoscaling
    uid: 66ed7586-66a4-11ea-b80b-42010a800288
  spec:
    group: autoscaling
    groupPriorityMinimum: 17500
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.batch
    resourceVersion: "18"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.batch
    uid: 66ef72ab-66a4-11ea-b80b-42010a800288
  spec:
    group: batch
    groupPriorityMinimum: 17400
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.coordination.k8s.io
    resourceVersion: "20"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.coordination.k8s.io
    uid: 66f45cac-66a4-11ea-b80b-42010a800288
  spec:
    group: coordination.k8s.io
    groupPriorityMinimum: 16500
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.networking.k8s.io
    resourceVersion: "19"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.networking.k8s.io
    uid: 66f54bc0-66a4-11ea-b80b-42010a800288
  spec:
    group: networking.k8s.io
    groupPriorityMinimum: 17200
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.rbac.authorization.k8s.io
    resourceVersion: "29"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.rbac.authorization.k8s.io
    uid: 66fdb1e4-66a4-11ea-b80b-42010a800288
  spec:
    group: rbac.authorization.k8s.io
    groupPriorityMinimum: 17000
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.scheduling.k8s.io
    resourceVersion: "27"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.scheduling.k8s.io
    uid: 66fcf4ed-66a4-11ea-b80b-42010a800288
  spec:
    group: scheduling.k8s.io
    groupPriorityMinimum: 16600
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1.storage.k8s.io
    resourceVersion: "33"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1.storage.k8s.io
    uid: 6702bfa7-66a4-11ea-b80b-42010a800288
  spec:
    group: storage.k8s.io
    groupPriorityMinimum: 16800
    service: null
    version: v1
    versionPriority: 15
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: "true"
    name: v1alpha1.nodemanagement.gke.io
    resourceVersion: "466"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.nodemanagement.gke.io
    uid: 7b9f6397-66a4-11ea-b80b-42010a800288
  spec:
    group: nodemanagement.gke.io
    groupPriorityMinimum: 1000
    service: null
    version: v1alpha1
    versionPriority: 100
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: "true"
    name: v1alpha1.scalingpolicy.kope.io
    resourceVersion: "462"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.scalingpolicy.kope.io
    uid: 7b9a8388-66a4-11ea-b80b-42010a800288
  spec:
    group: scalingpolicy.kope.io
    groupPriorityMinimum: 1000
    service: null
    version: v1alpha1
    versionPriority: 100
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.admissionregistration.k8s.io
    resourceVersion: "6"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.admissionregistration.k8s.io
    uid: 66e2b3dd-66a4-11ea-b80b-42010a800288
  spec:
    group: admissionregistration.k8s.io
    groupPriorityMinimum: 16700
    service: null
    version: v1beta1
    versionPriority: 12
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.apiextensions.k8s.io
    resourceVersion: "7"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.apiextensions.k8s.io
    uid: 66e2ba64-66a4-11ea-b80b-42010a800288
  spec:
    group: apiextensions.k8s.io
    groupPriorityMinimum: 16700
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.apps
    resourceVersion: "5"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.apps
    uid: 66e2a9bd-66a4-11ea-b80b-42010a800288
  spec:
    group: apps
    groupPriorityMinimum: 17800
    service: null
    version: v1beta1
    versionPriority: 1
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.authentication.k8s.io
    resourceVersion: "12"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.authentication.k8s.io
    uid: 66e825e4-66a4-11ea-b80b-42010a800288
  spec:
    group: authentication.k8s.io
    groupPriorityMinimum: 17700
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.authorization.k8s.io
    resourceVersion: "10"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.authorization.k8s.io
    uid: 66e80d0e-66a4-11ea-b80b-42010a800288
  spec:
    group: authorization.k8s.io
    groupPriorityMinimum: 17600
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.batch
    resourceVersion: "15"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.batch
    uid: 66ef7769-66a4-11ea-b80b-42010a800288
  spec:
    group: batch
    groupPriorityMinimum: 17400
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.certificates.k8s.io
    resourceVersion: "17"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.certificates.k8s.io
    uid: 66ef69b6-66a4-11ea-b80b-42010a800288
  spec:
    group: certificates.k8s.io
    groupPriorityMinimum: 17300
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:05:24Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: "true"
    name: v1beta1.cloud.google.com
    resourceVersion: "482"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.cloud.google.com
    uid: 7cac4cf1-66a4-11ea-b80b-42010a800288
  spec:
    group: cloud.google.com
    groupPriorityMinimum: 1000
    service: null
    version: v1beta1
    versionPriority: 100
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:24Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.coordination.k8s.io
    resourceVersion: "22"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.coordination.k8s.io
    uid: 66f54244-66a4-11ea-b80b-42010a800288
  spec:
    group: coordination.k8s.io
    groupPriorityMinimum: 16500
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.extensions
    resourceVersion: "23"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.extensions
    uid: 66f5474f-66a4-11ea-b80b-42010a800288
  spec:
    group: extensions
    groupPriorityMinimum: 17900
    service: null
    version: v1beta1
    versionPriority: 1
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apiregistration.k8s.io/v1beta1","kind":"APIService","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"v1beta1.metrics.k8s.io"},"spec":{"group":"metrics.k8s.io","groupPriorityMinimum":100,"insecureSkipTLSVerify":true,"service":{"name":"metrics-server","namespace":"kube-system"},"version":"v1beta1","versionPriority":100}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: v1beta1.metrics.k8s.io
    resourceVersion: "10399247"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.metrics.k8s.io
    uid: 794d1d14-66a4-11ea-b80b-42010a800288
  spec:
    group: metrics.k8s.io
    groupPriorityMinimum: 100
    insecureSkipTLSVerify: true
    service:
      name: metrics-server
      namespace: kube-system
    version: v1beta1
    versionPriority: 100
  status:
    conditions:
    - lastTransitionTime: "2020-04-21T13:10:28Z"
      message: all checks passed
      reason: Passed
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: "true"
    name: v1beta1.networking.gke.io
    resourceVersion: "447"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.networking.gke.io
    uid: 7b7583b8-66a4-11ea-b80b-42010a800288
  spec:
    group: networking.gke.io
    groupPriorityMinimum: 1000
    service: null
    version: v1beta1
    versionPriority: 100
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.networking.k8s.io
    resourceVersion: "21"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.networking.k8s.io
    uid: 66f537ce-66a4-11ea-b80b-42010a800288
  spec:
    group: networking.k8s.io
    groupPriorityMinimum: 17200
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.node.k8s.io
    resourceVersion: "26"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.node.k8s.io
    uid: 66fcd578-66a4-11ea-b80b-42010a800288
  spec:
    group: node.k8s.io
    groupPriorityMinimum: 16300
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.policy
    resourceVersion: "28"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.policy
    uid: 66fdac3d-66a4-11ea-b80b-42010a800288
  spec:
    group: policy
    groupPriorityMinimum: 17100
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.rbac.authorization.k8s.io
    resourceVersion: "25"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.rbac.authorization.k8s.io
    uid: 66fdb6b5-66a4-11ea-b80b-42010a800288
  spec:
    group: rbac.authorization.k8s.io
    groupPriorityMinimum: 17000
    service: null
    version: v1beta1
    versionPriority: 12
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.scheduling.k8s.io
    resourceVersion: "31"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.scheduling.k8s.io
    uid: 66ff38c9-66a4-11ea-b80b-42010a800288
  spec:
    group: scheduling.k8s.io
    groupPriorityMinimum: 16600
    service: null
    version: v1beta1
    versionPriority: 12
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta1.storage.k8s.io
    resourceVersion: "32"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.storage.k8s.io
    uid: 670371a8-66a4-11ea-b80b-42010a800288
  spec:
    group: storage.k8s.io
    groupPriorityMinimum: 16800
    service: null
    version: v1beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v1beta2.apps
    resourceVersion: "9"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta2.apps
    uid: 66e795b6-66a4-11ea-b80b-42010a800288
  spec:
    group: apps
    groupPriorityMinimum: 17800
    service: null
    version: v1beta2
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
- apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    creationTimestamp: "2020-03-15T10:04:47Z"
    labels:
      kube-aggregator.kubernetes.io/automanaged: onstart
    name: v2beta1.autoscaling
    resourceVersion: "16"
    selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v2beta1.autoscaling
    uid: 66ef056f-66a4-11ea-b80b-42010a800288
  spec:
    group: autoscaling
    groupPriorityMinimum: 17500
    service: null
    version: v2beta1
    versionPriority: 9
  status:
    conditions:
    - lastTransitionTime: "2020-03-15T10:04:47Z"
      message: Local APIServices are always available
      reason: Local
      status: "True"
      type: Available
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== controllerrevisions manifests ========

apiVersion: v1
items:
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            EnableKnativeConfig: "false"
            EnableNodeJournal: "false"
            EnablePodSecurityPolicy: "false"
            PodLogEnabled: "false"
            SystemOnlyLogging: "false"
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: fluentd-gcp
            kubernetes.io/cluster-service: "true"
            version: v3.1.1
        spec:
          containers:
          - env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: STACKDRIVER_METADATA_AGENT_URL
              value: http://$(NODE_NAME):8799
            image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
            imagePullPolicy: IfNotPresent
            livenessProbe:
              exec:
                command:
                - /bin/sh
                - -c
                - |2

                  LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
                    exit 1;
                  fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
                    rm -rf /var/run/google-fluentd/buffers;
                    exit 1;
                  fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
                    exit 1;
                  fi;
              failureThreshold: 3
              initialDelaySeconds: 600
              periodSeconds: 60
              successThreshold: 1
              timeoutSeconds: 1
            name: fluentd-gcp
            resources:
              limits:
                cpu: "1"
                memory: 500Mi
              requests:
                cpu: 100m
                memory: 200Mi
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/run/google-fluentd
              name: varrun
            - mountPath: /var/log
              name: varlog
            - mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
            - mountPath: /etc/google-fluentd/config.d
              name: config-volume
          - command:
            - /monitor
            - --stackdriver-prefix=container.googleapis.com/internal/addons
            - --api-override=https://monitoring.googleapis.com/
            - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
            - --pod-id=$(POD_NAME)
            - --namespace-id=$(POD_NAMESPACE)
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            image: k8s.gcr.io/prometheus-to-sd:v0.5.0
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd-exporter
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: Default
          hostNetwork: true
          nodeSelector:
            beta.kubernetes.io/fluentd-ds-ready: "true"
            beta.kubernetes.io/os: linux
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: fluentd-gcp
          serviceAccountName: fluentd-gcp
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoExecute
            operator: Exists
          - effect: NoSchedule
            operator: Exists
          volumes:
          - hostPath:
              path: /var/run/google-fluentd
              type: ""
            name: varrun
          - hostPath:
              path: /var/log
              type: ""
            name: varlog
          - hostPath:
              path: /var/lib/docker/containers
              type: ""
            name: varlibdockercontainers
          - configMap:
              defaultMode: 420
              name: fluentd-gcp-config-v1.2.6
            name: config-volume
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"},"name":"fluentd-gcp-v3.1.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"template":{"metadata":{"annotations":{"EnableKnativeConfig":"false","EnableNodeJournal":"false","EnablePodSecurityPolicy":"false","PodLogEnabled":"false","SystemOnlyLogging":"false","scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"spec":{"containers":[{"env":[{"name":"NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"STACKDRIVER_METADATA_AGENT_URL","value":"http://$(NODE_NAME):8799"}],"image":"gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060","livenessProbe":{"exec":{"command":["/bin/sh","-c","\nLIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then\n  exit 1;\nfi; touch -d \"${STUCK_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-stuck; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)\" ]; then\n  rm -rf /var/run/google-fluentd/buffers;\n  exit 1;\nfi; touch -d \"${LIVENESS_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-liveness; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)\" ]; then\n  exit 1;\nfi;\n"]},"initialDelaySeconds":600,"periodSeconds":60},"name":"fluentd-gcp","volumeMounts":[{"mountPath":"/var/run/google-fluentd","name":"varrun"},{"mountPath":"/var/log","name":"varlog"},{"mountPath":"/var/lib/docker/containers","name":"varlibdockercontainers","readOnly":true},{"mountPath":"/etc/google-fluentd/config.d","name":"config-volume"}]},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/fluentd-ds-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"fluentd-gcp","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/run/google-fluentd"},"name":"varrun"},{"hostPath":{"path":"/var/log"},"name":"varlog"},{"hostPath":{"path":"/var/lib/docker/containers"},"name":"varlibdockercontainers"},{"configMap":{"name":"fluentd-gcp-config-v1.2.6"},"name":"config-volume"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-04-01T22:47:47Z"
    labels:
      controller-revision-hash: 57d5cdd48
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1-57d5cdd48
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.1.1
      uid: 779ca16d-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938075"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/fluentd-gcp-v3.1.1-57d5cdd48
    uid: cef45ace-746a-11ea-b920-42010a8002b4
  revision: 3
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: fluentd-gcp
            kubernetes.io/cluster-service: "true"
            version: v3.1.1
        spec:
          containers:
          - env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: STACKDRIVER_METADATA_AGENT_URL
              value: http://$(NODE_NAME):8799
            image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
            imagePullPolicy: IfNotPresent
            livenessProbe:
              exec:
                command:
                - /bin/sh
                - -c
                - |2

                  LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
                    exit 1;
                  fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
                    rm -rf /var/run/google-fluentd/buffers;
                    exit 1;
                  fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
                    exit 1;
                  fi;
              failureThreshold: 3
              initialDelaySeconds: 600
              periodSeconds: 60
              successThreshold: 1
              timeoutSeconds: 1
            name: fluentd-gcp
            resources:
              limits:
                cpu: "1"
                memory: 500Mi
              requests:
                cpu: 100m
                memory: 200Mi
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/run/google-fluentd
              name: varrun
            - mountPath: /var/log
              name: varlog
            - mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
            - mountPath: /etc/google-fluentd/config.d
              name: config-volume
          - command:
            - /monitor
            - --stackdriver-prefix=container.googleapis.com/internal/addons
            - --api-override=https://monitoring.googleapis.com/
            - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
            - --pod-id=$(POD_NAME)
            - --namespace-id=$(POD_NAMESPACE)
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            image: k8s.gcr.io/prometheus-to-sd:v0.5.0
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd-exporter
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: Default
          hostNetwork: true
          nodeSelector:
            beta.kubernetes.io/fluentd-ds-ready: "true"
            beta.kubernetes.io/os: linux
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: fluentd-gcp
          serviceAccountName: fluentd-gcp
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoExecute
            operator: Exists
          - effect: NoSchedule
            operator: Exists
          volumes:
          - hostPath:
              path: /var/run/google-fluentd
              type: ""
            name: varrun
          - hostPath:
              path: /var/log
              type: ""
            name: varlog
          - hostPath:
              path: /var/lib/docker/containers
              type: ""
            name: varlibdockercontainers
          - configMap:
              defaultMode: 420
              name: fluentd-gcp-config-v1.2.6
            name: config-volume
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"},"name":"fluentd-gcp-v3.1.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"spec":{"containers":[{"env":[{"name":"NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"STACKDRIVER_METADATA_AGENT_URL","value":"http://$(NODE_NAME):8799"}],"image":"gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060","livenessProbe":{"exec":{"command":["/bin/sh","-c","\nLIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then\n  exit 1;\nfi; touch -d \"${STUCK_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-stuck; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)\" ]; then\n  rm -rf /var/run/google-fluentd/buffers;\n  exit 1;\nfi; touch -d \"${LIVENESS_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-liveness; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)\" ]; then\n  exit 1;\nfi;\n"]},"initialDelaySeconds":600,"periodSeconds":60},"name":"fluentd-gcp","volumeMounts":[{"mountPath":"/var/run/google-fluentd","name":"varrun"},{"mountPath":"/var/log","name":"varlog"},{"mountPath":"/var/lib/docker/containers","name":"varlibdockercontainers","readOnly":true},{"mountPath":"/etc/google-fluentd/config.d","name":"config-volume"}]},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/fluentd-ds-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"fluentd-gcp","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/run/google-fluentd"},"name":"varrun"},{"hostPath":{"path":"/var/log"},"name":"varlog"},{"hostPath":{"path":"/var/lib/docker/containers"},"name":"varlibdockercontainers"},{"configMap":{"name":"fluentd-gcp-config-v1.2.6"},"name":"config-volume"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:39Z"
    labels:
      controller-revision-hash: 8c545b584
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1-8c545b584
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.1.1
      uid: 779ca16d-66a4-11ea-b80b-42010a800288
    resourceVersion: "678"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/fluentd-gcp-v3.1.1-8c545b584
    uid: 86049bcc-66a4-11ea-b80b-42010a800288
  revision: 2
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: fluentd-gcp
            kubernetes.io/cluster-service: "true"
            version: v3.1.1
        spec:
          containers:
          - env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: STACKDRIVER_METADATA_AGENT_URL
              value: http://$(NODE_NAME):8799
            image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
            imagePullPolicy: IfNotPresent
            livenessProbe:
              exec:
                command:
                - /bin/sh
                - -c
                - |2

                  LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
                    exit 1;
                  fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
                    rm -rf /var/run/google-fluentd/buffers;
                    exit 1;
                  fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
                    exit 1;
                  fi;
              failureThreshold: 3
              initialDelaySeconds: 600
              periodSeconds: 60
              successThreshold: 1
              timeoutSeconds: 1
            name: fluentd-gcp
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /var/run/google-fluentd
              name: varrun
            - mountPath: /var/log
              name: varlog
            - mountPath: /var/lib/docker/containers
              name: varlibdockercontainers
              readOnly: true
            - mountPath: /etc/google-fluentd/config.d
              name: config-volume
          - command:
            - /monitor
            - --stackdriver-prefix=container.googleapis.com/internal/addons
            - --api-override=https://monitoring.googleapis.com/
            - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
            - --pod-id=$(POD_NAME)
            - --namespace-id=$(POD_NAMESPACE)
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            image: k8s.gcr.io/prometheus-to-sd:v0.5.0
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd-exporter
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: Default
          hostNetwork: true
          nodeSelector:
            beta.kubernetes.io/fluentd-ds-ready: "true"
            beta.kubernetes.io/os: linux
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: fluentd-gcp
          serviceAccountName: fluentd-gcp
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoExecute
            operator: Exists
          - effect: NoSchedule
            operator: Exists
          volumes:
          - hostPath:
              path: /var/run/google-fluentd
              type: ""
            name: varrun
          - hostPath:
              path: /var/log
              type: ""
            name: varlog
          - hostPath:
              path: /var/lib/docker/containers
              type: ""
            name: varlibdockercontainers
          - configMap:
              defaultMode: 420
              name: fluentd-gcp-config-v1.2.6
            name: config-volume
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"},"name":"fluentd-gcp-v3.1.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"spec":{"containers":[{"env":[{"name":"NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"STACKDRIVER_METADATA_AGENT_URL","value":"http://$(NODE_NAME):8799"}],"image":"gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060","livenessProbe":{"exec":{"command":["/bin/sh","-c","\nLIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then\n  exit 1;\nfi; touch -d \"${STUCK_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-stuck; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)\" ]; then\n  rm -rf /var/run/google-fluentd/buffers;\n  exit 1;\nfi; touch -d \"${LIVENESS_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-liveness; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)\" ]; then\n  exit 1;\nfi;\n"]},"initialDelaySeconds":600,"periodSeconds":60},"name":"fluentd-gcp","volumeMounts":[{"mountPath":"/var/run/google-fluentd","name":"varrun"},{"mountPath":"/var/log","name":"varlog"},{"mountPath":"/var/lib/docker/containers","name":"varlibdockercontainers","readOnly":true},{"mountPath":"/etc/google-fluentd/config.d","name":"config-volume"}]},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/fluentd-ds-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"fluentd-gcp","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/run/google-fluentd"},"name":"varrun"},{"hostPath":{"path":"/var/log"},"name":"varlog"},{"hostPath":{"path":"/var/lib/docker/containers"},"name":"varlibdockercontainers"},{"configMap":{"name":"fluentd-gcp-config-v1.2.6"},"name":"config-volume"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      controller-revision-hash: dd85dcb57
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1-dd85dcb57
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.1.1
      uid: 779ca16d-66a4-11ea-b80b-42010a800288
    resourceVersion: "320"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/fluentd-gcp-v3.1.1-dd85dcb57
    uid: 77a02d34-66a4-11ea-b80b-42010a800288
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: metadata-proxy
            kubernetes.io/cluster-service: "true"
            version: v0.1
        spec:
          containers:
          - image: k8s.gcr.io/metadata-proxy:v0.1.11
            imagePullPolicy: IfNotPresent
            name: metadata-proxy
            resources:
              limits:
                cpu: 30m
                memory: 25Mi
              requests:
                cpu: 30m
                memory: 25Mi
            securityContext:
              privileged: true
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          - command:
            - /monitor
            - --stackdriver-prefix=container.googleapis.com/internal/addons
            - --api-override=https://monitoring.googleapis.com/
            - --source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count
            - --pod-id=$(POD_NAME)
            - --namespace-id=$(POD_NAMESPACE)
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            image: k8s.gcr.io/prometheus-to-sd:v0.5.0
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd-exporter
            resources:
              limits:
                cpu: 2m
                memory: 20Mi
              requests:
                cpu: 2m
                memory: 20Mi
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: Default
          hostNetwork: true
          nodeSelector:
            beta.kubernetes.io/metadata-proxy-ready: "true"
            beta.kubernetes.io/os: linux
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: metadata-proxy
          serviceAccountName: metadata-proxy
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoExecute
            operator: Exists
          - effect: NoSchedule
            operator: Exists
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"},"name":"metadata-proxy-v0.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metadata-proxy","version":"v0.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"}},"spec":{"containers":[{"image":"k8s.gcr.io/metadata-proxy:v0.1.11","name":"metadata-proxy","resources":{"limits":{"cpu":"30m","memory":"25Mi"},"requests":{"cpu":"30m","memory":"25Mi"}},"securityContext":{"privileged":true}},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter","resources":{"limits":{"cpu":"2m","memory":"20Mi"},"requests":{"cpu":"2m","memory":"20Mi"}}}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/metadata-proxy-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"metadata-proxy","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      controller-revision-hash: 9567b9dd6
      k8s-app: metadata-proxy
      kubernetes.io/cluster-service: "true"
      version: v0.1
    name: metadata-proxy-v0.1-9567b9dd6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: metadata-proxy-v0.1
      uid: 7944d08a-66a4-11ea-b80b-42010a800288
    resourceVersion: "395"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/metadata-proxy-v0.1-9567b9dd6
    uid: 7945be24-66a4-11ea-b80b-42010a800288
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          annotations:
            scheduler.alpha.kubernetes.io/critical-pod: ""
          creationTimestamp: null
          labels:
            k8s-app: nvidia-gpu-device-plugin
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: cloud.google.com/gke-accelerator
                    operator: Exists
          containers:
          - command:
            - /usr/bin/nvidia-gpu-device-plugin
            - -logtostderr
            image: k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa
            imagePullPolicy: IfNotPresent
            name: nvidia-gpu-device-plugin
            resources:
              limits:
                cpu: 50m
                memory: 10Mi
              requests:
                cpu: 50m
                memory: 10Mi
            securityContext:
              privileged: true
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /device-plugin
              name: device-plugin
            - mountPath: /dev
              name: dev
          dnsPolicy: ClusterFirst
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoExecute
            operator: Exists
          - effect: NoSchedule
            operator: Exists
          volumes:
          - hostPath:
              path: /var/lib/kubelet/device-plugins
              type: ""
            name: device-plugin
          - hostPath:
              path: /dev
              type: ""
            name: dev
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"nvidia-gpu-device-plugin"},"name":"nvidia-gpu-device-plugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"nvidia-gpu-device-plugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"nvidia-gpu-device-plugin"}},"spec":{"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchExpressions":[{"key":"cloud.google.com/gke-accelerator","operator":"Exists"}]}]}}},"containers":[{"command":["/usr/bin/nvidia-gpu-device-plugin","-logtostderr"],"image":"k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa","name":"nvidia-gpu-device-plugin","resources":{"limits":{"cpu":"50m","memory":"10Mi"},"requests":{"cpu":"50m","memory":"10Mi"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/device-plugin","name":"device-plugin"},{"mountPath":"/dev","name":"dev"}]}],"priorityClassName":"system-node-critical","tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/lib/kubelet/device-plugins"},"name":"device-plugin"},{"hostPath":{"path":"/dev"},"name":"dev"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:21Z"
    labels:
      controller-revision-hash: b5469599c
      k8s-app: nvidia-gpu-device-plugin
    name: nvidia-gpu-device-plugin-b5469599c
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: nvidia-gpu-device-plugin
      uid: 7b6be270-66a4-11ea-b80b-42010a800288
    resourceVersion: "438"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/nvidia-gpu-device-plugin-b5469599c
    uid: 7b6cde28-66a4-11ea-b80b-42010a800288
  revision: 1
- apiVersion: apps/v1
  data:
    spec:
      template:
        $patch: replace
        metadata:
          creationTimestamp: null
          labels:
            k8s-app: prometheus-to-sd
        spec:
          containers:
          - command:
            - /monitor
            - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
            - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
            - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
            - --stackdriver-prefix=container.googleapis.com/internal/nodes
            - --api-override=https://monitoring.googleapis.com/
            - --export-interval=120s
            image: k8s.gcr.io/prometheus-to-sd:v0.8.2
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          - command:
            - /monitor
            - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=kubernetes.io/internal/addons
            - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
            - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
            - --stackdriver-prefix=kubernetes.io/internal/nodes
            - --api-override=https://monitoring.googleapis.com/
            - --monitored-resource-type-prefix=k8s_
            - --monitored-resource-labels=location=us-central1-c
            - --export-interval=120s
            image: k8s.gcr.io/prometheus-to-sd:v0.8.2
            imagePullPolicy: IfNotPresent
            name: prometheus-to-sd-new-model
            resources:
              limits:
                cpu: 3m
                memory: 20Mi
              requests:
                cpu: 1m
                memory: 20Mi
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          hostNetwork: true
          nodeSelector:
            beta.kubernetes.io/os: linux
          priorityClassName: system-node-critical
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccount: prometheus-to-sd
          serviceAccountName: prometheus-to-sd
          terminationGracePeriodSeconds: 30
          tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
  kind: ControllerRevision
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"prometheus-to-sd","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"prometheus-to-sd"}},"template":{"metadata":{"labels":{"k8s-app":"prometheus-to-sd"}},"spec":{"containers":[{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=container.googleapis.com/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=container.googleapis.com/internal/nodes","--api-override=https://monitoring.googleapis.com/","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd"},{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=kubernetes.io/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=kubernetes.io/internal/nodes","--api-override=https://monitoring.googleapis.com/","--monitored-resource-type-prefix=k8s_","--monitored-resource-labels=location=us-central1-c","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd-new-model","resources":{"limits":{"cpu":"3m","memory":"20Mi"},"requests":{"cpu":"1m","memory":"20Mi"}}}],"hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"prometheus-to-sd","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}]}}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      controller-revision-hash: 6cbdc4dbd7
      k8s-app: prometheus-to-sd
    name: prometheus-to-sd-6cbdc4dbd7
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 792a47e1-66a4-11ea-b80b-42010a800288
    resourceVersion: "389"
    selfLink: /apis/apps/v1/namespaces/kube-system/controllerrevisions/prometheus-to-sd-6cbdc4dbd7
    uid: 792bb548-66a4-11ea-b80b-42010a800288
  revision: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== daemonsets manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"},"name":"fluentd-gcp-v3.1.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"template":{"metadata":{"annotations":{"EnableKnativeConfig":"false","EnableNodeJournal":"false","EnablePodSecurityPolicy":"false","PodLogEnabled":"false","SystemOnlyLogging":"false","scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"spec":{"containers":[{"env":[{"name":"NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"STACKDRIVER_METADATA_AGENT_URL","value":"http://$(NODE_NAME):8799"}],"image":"gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060","livenessProbe":{"exec":{"command":["/bin/sh","-c","\nLIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then\n  exit 1;\nfi; touch -d \"${STUCK_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-stuck; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)\" ]; then\n  rm -rf /var/run/google-fluentd/buffers;\n  exit 1;\nfi; touch -d \"${LIVENESS_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-liveness; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)\" ]; then\n  exit 1;\nfi;\n"]},"initialDelaySeconds":600,"periodSeconds":60},"name":"fluentd-gcp","volumeMounts":[{"mountPath":"/var/run/google-fluentd","name":"varrun"},{"mountPath":"/var/log","name":"varlog"},{"mountPath":"/var/lib/docker/containers","name":"varlibdockercontainers","readOnly":true},{"mountPath":"/etc/google-fluentd/config.d","name":"config-volume"}]},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/fluentd-ds-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"fluentd-gcp","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/run/google-fluentd"},"name":"varrun"},{"hostPath":{"path":"/var/log"},"name":"varlog"},{"hostPath":{"path":"/var/lib/docker/containers"},"name":"varlibdockercontainers"},{"configMap":{"name":"fluentd-gcp-config-v1.2.6"},"name":"config-volume"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1
    namespace: kube-system
    resourceVersion: "10399164"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.1.1
    uid: 779ca16d-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: fluentd-gcp
        kubernetes.io/cluster-service: "true"
        version: v3.1.1
    template:
      metadata:
        annotations:
          EnableKnativeConfig: "false"
          EnableNodeJournal: "false"
          EnablePodSecurityPolicy: "false"
          PodLogEnabled: "false"
          SystemOnlyLogging: "false"
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp
          kubernetes.io/cluster-service: "true"
          version: v3.1.1
      spec:
        containers:
        - env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: STACKDRIVER_METADATA_AGENT_URL
            value: http://$(NODE_NAME):8799
          image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - |2

                LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
                  exit 1;
                fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
                  rm -rf /var/run/google-fluentd/buffers;
                  exit 1;
                fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
                  exit 1;
                fi;
            failureThreshold: 3
            initialDelaySeconds: 600
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 1
          name: fluentd-gcp
          resources:
            limits:
              cpu: "1"
              memory: 500Mi
            requests:
              cpu: 100m
              memory: 200Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run/google-fluentd
            name: varrun
          - mountPath: /var/log
            name: varlog
          - mountPath: /var/lib/docker/containers
            name: varlibdockercontainers
            readOnly: true
          - mountPath: /etc/google-fluentd/config.d
            name: config-volume
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/fluentd-ds-ready: "true"
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp
        serviceAccountName: fluentd-gcp
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/run/google-fluentd
            type: ""
          name: varrun
        - hostPath:
            path: /var/log
            type: ""
          name: varlog
        - hostPath:
            path: /var/lib/docker/containers
            type: ""
          name: varlibdockercontainers
        - configMap:
            defaultMode: 420
            name: fluentd-gcp-config-v1.2.6
          name: config-volume
    templateGeneration: 3
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 3
    updatedNumberScheduled: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"},"name":"metadata-proxy-v0.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metadata-proxy","version":"v0.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"}},"spec":{"containers":[{"image":"k8s.gcr.io/metadata-proxy:v0.1.11","name":"metadata-proxy","resources":{"limits":{"cpu":"30m","memory":"25Mi"},"requests":{"cpu":"30m","memory":"25Mi"}},"securityContext":{"privileged":true}},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter","resources":{"limits":{"cpu":"2m","memory":"20Mi"},"requests":{"cpu":"2m","memory":"20Mi"}}}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/metadata-proxy-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"metadata-proxy","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: metadata-proxy
      kubernetes.io/cluster-service: "true"
      version: v0.1
    name: metadata-proxy-v0.1
    namespace: kube-system
    resourceVersion: "396"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1
    uid: 7944d08a-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: metadata-proxy
        version: v0.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: metadata-proxy
          kubernetes.io/cluster-service: "true"
          version: v0.1
      spec:
        containers:
        - image: k8s.gcr.io/metadata-proxy:v0.1.11
          imagePullPolicy: IfNotPresent
          name: metadata-proxy
          resources:
            limits:
              cpu: 30m
              memory: 25Mi
            requests:
              cpu: 30m
              memory: 25Mi
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources:
            limits:
              cpu: 2m
              memory: 20Mi
            requests:
              cpu: 2m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/metadata-proxy-ready: "true"
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-proxy
        serviceAccountName: metadata-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 0
    desiredNumberScheduled: 0
    numberMisscheduled: 0
    numberReady: 0
    observedGeneration: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"nvidia-gpu-device-plugin"},"name":"nvidia-gpu-device-plugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"nvidia-gpu-device-plugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"nvidia-gpu-device-plugin"}},"spec":{"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchExpressions":[{"key":"cloud.google.com/gke-accelerator","operator":"Exists"}]}]}}},"containers":[{"command":["/usr/bin/nvidia-gpu-device-plugin","-logtostderr"],"image":"k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa","name":"nvidia-gpu-device-plugin","resources":{"limits":{"cpu":"50m","memory":"10Mi"},"requests":{"cpu":"50m","memory":"10Mi"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/device-plugin","name":"device-plugin"},{"mountPath":"/dev","name":"dev"}]}],"priorityClassName":"system-node-critical","tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/lib/kubelet/device-plugins"},"name":"device-plugin"},{"hostPath":{"path":"/dev"},"name":"dev"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:21Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: nvidia-gpu-device-plugin
    name: nvidia-gpu-device-plugin
    namespace: kube-system
    resourceVersion: "439"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/nvidia-gpu-device-plugin
    uid: 7b6be270-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: nvidia-gpu-device-plugin
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: nvidia-gpu-device-plugin
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: cloud.google.com/gke-accelerator
                  operator: Exists
        containers:
        - command:
          - /usr/bin/nvidia-gpu-device-plugin
          - -logtostderr
          image: k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa
          imagePullPolicy: IfNotPresent
          name: nvidia-gpu-device-plugin
          resources:
            limits:
              cpu: 50m
              memory: 10Mi
            requests:
              cpu: 50m
              memory: 10Mi
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /device-plugin
            name: device-plugin
          - mountPath: /dev
            name: dev
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/lib/kubelet/device-plugins
            type: ""
          name: device-plugin
        - hostPath:
            path: /dev
            type: ""
          name: dev
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 0
    desiredNumberScheduled: 0
    numberMisscheduled: 0
    numberReady: 0
    observedGeneration: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"prometheus-to-sd","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"prometheus-to-sd"}},"template":{"metadata":{"labels":{"k8s-app":"prometheus-to-sd"}},"spec":{"containers":[{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=container.googleapis.com/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=container.googleapis.com/internal/nodes","--api-override=https://monitoring.googleapis.com/","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd"},{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=kubernetes.io/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=kubernetes.io/internal/nodes","--api-override=https://monitoring.googleapis.com/","--monitored-resource-type-prefix=k8s_","--monitored-resource-labels=location=us-central1-c","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd-new-model","resources":{"limits":{"cpu":"3m","memory":"20Mi"},"requests":{"cpu":"1m","memory":"20Mi"}}}],"hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"prometheus-to-sd","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}]}}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: prometheus-to-sd
    namespace: kube-system
    resourceVersion: "10399098"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/prometheus-to-sd
    uid: 792a47e1-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: prometheus-to-sd
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: prometheus-to-sd
      spec:
        containers:
        - command:
          - /monitor
          - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
          - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
          - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
          - --stackdriver-prefix=container.googleapis.com/internal/nodes
          - --api-override=https://monitoring.googleapis.com/
          - --export-interval=120s
          image: k8s.gcr.io/prometheus-to-sd:v0.8.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=kubernetes.io/internal/addons
          - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
          - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
          - --stackdriver-prefix=kubernetes.io/internal/nodes
          - --api-override=https://monitoring.googleapis.com/
          - --monitored-resource-type-prefix=k8s_
          - --monitored-resource-labels=location=us-central1-c
          - --export-interval=120s
          image: k8s.gcr.io/prometheus-to-sd:v0.8.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-new-model
          resources:
            limits:
              cpu: 3m
              memory: 20Mi
            requests:
              cpu: 1m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: prometheus-to-sd
        serviceAccountName: prometheus-to-sd
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== deployments manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "35"
    creationTimestamp: "2020-03-17T16:58:41Z"
    generation: 62
    labels:
      run: essbaseservice
    name: essbaseservice
    namespace: default
    resourceVersion: "13428053"
    selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/essbaseservice
    uid: 8dfc8260-6870-11ea-b004-42010a80008c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        run: essbaseservice
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-17T16:58:41Z"
      lastUpdateTime: "2020-04-27T18:02:42Z"
      message: ReplicaSet "essbaseservice-f5f56b5b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-05-02T06:58:31Z"
      lastUpdateTime: "2020-05-02T06:58:31Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 62
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1beta1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"event-exporter","kubernetes.io/cluster-service":"true","version":"v0.2.5"},"name":"event-exporter-v0.2.5","namespace":"kube-system"},"spec":{"replicas":1,"template":{"metadata":{"labels":{"k8s-app":"event-exporter","version":"v0.2.5"}},"spec":{"containers":[{"command":["/event-exporter","-sink-opts=-stackdriver-resource-model=new"],"image":"k8s.gcr.io/event-exporter:v0.2.5","name":"event-exporter"},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"serviceAccountName":"event-exporter-sa","terminationGracePeriodSeconds":30,"volumes":[{"hostPath":{"path":"/etc/ssl/certs"},"name":"ssl-certs"}]}}}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: event-exporter
      kubernetes.io/cluster-service: "true"
      version: v0.2.5
    name: event-exporter-v0.2.5
    namespace: kube-system
    resourceVersion: "10399195"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/event-exporter-v0.2.5
    uid: 78c77da7-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 2
    selector:
      matchLabels:
        k8s-app: event-exporter
        version: v0.2.5
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: event-exporter
          version: v0.2.5
      spec:
        containers:
        - command:
          - /event-exporter
          - -sink-opts=-stackdriver-resource-model=new
          image: k8s.gcr.io/event-exporter:v0.2.5
          imagePullPolicy: IfNotPresent
          name: event-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: event-exporter-sa
        serviceAccountName: event-exporter-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: ""
          name: ssl-certs
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-03-15T10:06:01Z"
      message: ReplicaSet "event-exporter-v0.2.5-7df89f4b8f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:10:15Z"
      lastUpdateTime: "2020-04-21T13:10:15Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp-scaler","version":"v0.5.1"},"name":"fluentd-gcp-scaler","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp-scaler"}},"template":{"metadata":{"labels":{"k8s-app":"fluentd-gcp-scaler"}},"spec":{"containers":[{"command":["/scaler.sh","--ds-name=fluentd-gcp-v3.1.1","--scaling-policy=fluentd-gcp-scaling-policy"],"env":[{"name":"CPU_REQUEST","value":"100m"},{"name":"MEMORY_REQUEST","value":"200Mi"},{"name":"CPU_LIMIT","value":"1"},{"name":"MEMORY_LIMIT","value":"500Mi"}],"image":"k8s.gcr.io/fluentd-gcp-scaler:0.5.2","name":"fluentd-gcp-scaler"}],"serviceAccountName":"fluentd-gcp-scaler"}}}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: fluentd-gcp-scaler
      version: v0.5.1
    name: fluentd-gcp-scaler
    namespace: kube-system
    resourceVersion: "10399096"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/fluentd-gcp-scaler
    uid: 7b7c5076-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: fluentd-gcp-scaler
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp-scaler
      spec:
        containers:
        - command:
          - /scaler.sh
          - --ds-name=fluentd-gcp-v3.1.1
          - --scaling-policy=fluentd-gcp-scaling-policy
          env:
          - name: CPU_REQUEST
            value: 100m
          - name: MEMORY_REQUEST
            value: 200Mi
          - name: CPU_LIMIT
            value: "1"
          - name: MEMORY_LIMIT
            value: 500Mi
          image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
          imagePullPolicy: IfNotPresent
          name: fluentd-gcp-scaler
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp-scaler
        serviceAccountName: fluentd-gcp-scaler
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      lastUpdateTime: "2020-03-15T10:05:34Z"
      message: ReplicaSet "fluentd-gcp-scaler-54ccb89d5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:48Z"
      lastUpdateTime: "2020-04-21T13:09:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"heapster","kubernetes.io/cluster-service":"true","version":"v1.7.2"},"name":"heapster-gke","namespace":"kube-system"},"spec":{"replicas":1,"selector":{"matchLabels":{"k8s-app":"heapster"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"heapster","version":"v1.7.2"}},"spec":{"containers":[{"command":["/heapster","--source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id","--sink=stackdriver:?cluster_name=indra20k8\u0026use_old_resources=false\u0026use_new_resources=true\u0026min_interval_sec=100\u0026batch_export_timeout_sec=110\u0026cluster_location=us-central1-c"],"image":"gke.gcr.io/heapster:v1.7.2","livenessProbe":{"httpGet":{"path":"/healthz","port":8082,"scheme":"HTTP"},"initialDelaySeconds":180,"timeoutSeconds":5},"name":"heapster"},{"command":["/monitor","--source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prom-to-sd"},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=10m","--extra-cpu=0.5m","--memory=100Mi","--extra-memory=4Mi","--threshold=5","--deployment=heapster-gke","--container=heapster","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/addon-resizer:1.8.3","name":"heapster-nanny","resources":{"limits":{"cpu":"50m","memory":"92560Ki"},"requests":{"cpu":"50m","memory":"92560Ki"}},"volumeMounts":[{"mountPath":"/etc/config","name":"heapster-config-volume"}]}],"priorityClassName":"system-cluster-critical","securityContext":{"fsGroup":65534,"supplementalGroups":[65534]},"serviceAccountName":"heapster","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"heapster-config"},"name":"heapster-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:16Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: heapster
      kubernetes.io/cluster-service: "true"
      version: v1.7.2
    name: heapster-gke
    namespace: kube-system
    resourceVersion: "10399252"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/heapster-gke
    uid: 77ee5493-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: heapster
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:16Z"
      lastUpdateTime: "2020-04-01T22:47:56Z"
      message: ReplicaSet "heapster-gke-7df9bb754d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:10:29Z"
      lastUpdateTime: "2020-04-21T13:10:29Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kube-dns","kubernetes.io/cluster-service":"true"},"name":"kube-dns","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"kube-dns"}},"strategy":{"rollingUpdate":{"maxSurge":"10%","maxUnavailable":0}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"kube-dns"}},"spec":{"containers":[{"args":["--domain=cluster.local.","--dns-port=10053","--config-dir=/kube-dns-config","--v=2"],"env":[{"name":"PROMETHEUS_PORT","value":"10055"}],"image":"k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthcheck/kubedns","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"kubedns","ports":[{"containerPort":10053,"name":"dns-local","protocol":"UDP"},{"containerPort":10053,"name":"dns-tcp-local","protocol":"TCP"},{"containerPort":10055,"name":"metrics","protocol":"TCP"}],"readinessProbe":{"httpGet":{"path":"/readiness","port":8081,"scheme":"HTTP"},"initialDelaySeconds":3,"timeoutSeconds":5},"resources":{"limits":{"memory":"170Mi"},"requests":{"cpu":"100m","memory":"70Mi"}},"volumeMounts":[{"mountPath":"/kube-dns-config","name":"kube-dns-config"}]},{"args":["-v=2","-logtostderr","-configDir=/etc/k8s/dns/dnsmasq-nanny","-restartDnsmasq=true","--","-k","--cache-size=1000","--no-negcache","--log-facility=-","--server=/cluster.local/127.0.0.1#10053","--server=/in-addr.arpa/127.0.0.1#10053","--server=/ip6.arpa/127.0.0.1#10053"],"image":"k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthcheck/dnsmasq","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"dnsmasq","ports":[{"containerPort":53,"name":"dns","protocol":"UDP"},{"containerPort":53,"name":"dns-tcp","protocol":"TCP"}],"resources":{"requests":{"cpu":"150m","memory":"20Mi"}},"volumeMounts":[{"mountPath":"/etc/k8s/dns/dnsmasq-nanny","name":"kube-dns-config"}]},{"args":["--v=2","--logtostderr","--probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV","--probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV"],"image":"k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/metrics","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"sidecar","ports":[{"containerPort":10054,"name":"metrics","protocol":"TCP"}],"resources":{"requests":{"cpu":"10m","memory":"20Mi"}}},{"command":["/monitor","--source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)","--v=2"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.4.2","name":"prometheus-to-sd"}],"dnsPolicy":"Default","priorityClassName":"system-cluster-critical","serviceAccountName":"kube-dns","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"kube-dns","optional":true},"name":"kube-dns-config"}]}}}}
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
    name: kube-dns
    namespace: kube-system
    resourceVersion: "10399309"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/kube-dns
    uid: 76bed5da-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 2147483647
    replicas: 1
    revisionHistoryLimit: 2147483647
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 10%
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        containers:
        - args:
          - --domain=cluster.local.
          - --dns-port=10053
          - --config-dir=/kube-dns-config
          - --v=2
          env:
          - name: PROMETHEUS_PORT
            value: "10055"
          image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/kubedns
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kubedns
          ports:
          - containerPort: 10053
            name: dns-local
            protocol: UDP
          - containerPort: 10053
            name: dns-tcp-local
            protocol: TCP
          - containerPort: 10055
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readiness
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /kube-dns-config
            name: kube-dns-config
        - args:
          - -v=2
          - -logtostderr
          - -configDir=/etc/k8s/dns/dnsmasq-nanny
          - -restartDnsmasq=true
          - --
          - -k
          - --cache-size=1000
          - --no-negcache
          - --log-facility=-
          - --server=/cluster.local/127.0.0.1#10053
          - --server=/in-addr.arpa/127.0.0.1#10053
          - --server=/ip6.arpa/127.0.0.1#10053
          image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/dnsmasq
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: dnsmasq
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          resources:
            requests:
              cpu: 150m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/k8s/dns/dnsmasq-nanny
            name: kube-dns-config
        - args:
          - --v=2
          - --logtostderr
          - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
          - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
          image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: sidecar
          ports:
          - containerPort: 10054
            name: metrics
            protocol: TCP
          resources:
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          - --v=2
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.4.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-dns
        serviceAccountName: kube-dns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-dns
            optional: true
          name: kube-dns-config
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-04-21T13:10:45Z"
      lastUpdateTime: "2020-04-21T13:10:45Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kube-dns-autoscaler","kubernetes.io/cluster-service":"true"},"name":"kube-dns-autoscaler","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"kube-dns-autoscaler"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"kube-dns-autoscaler"}},"spec":{"containers":[{"command":["/cluster-proportional-autoscaler","--namespace=kube-system","--configmap=kube-dns-autoscaler","--target=Deployment/kube-dns","--default-params={\"linear\":{\"coresPerReplica\":256,\"nodesPerReplica\":16,\"preventSinglePointFailure\":true}}","--logtostderr=true","--v=2"],"image":"gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0","name":"autoscaler","resources":{"requests":{"cpu":"20m","memory":"10Mi"}}}],"priorityClassName":"system-cluster-critical","securityContext":{"fsGroup":65534,"supplementalGroups":[65534]},"serviceAccountName":"kube-dns-autoscaler","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}]}}}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns-autoscaler
      kubernetes.io/cluster-service: "true"
    name: kube-dns-autoscaler
    namespace: kube-system
    resourceVersion: "10399083"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/kube-dns-autoscaler
    uid: 7776165d-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns-autoscaler
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns-autoscaler
      spec:
        containers:
        - command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          - --target=Deployment/kube-dns
          - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
          - --logtostderr=true
          - --v=2
          image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
          imagePullPolicy: IfNotPresent
          name: autoscaler
          resources:
            requests:
              cpu: 20m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: kube-dns-autoscaler
        serviceAccountName: kube-dns-autoscaler
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:15Z"
      lastUpdateTime: "2020-03-15T10:05:32Z"
      message: ReplicaSet "kube-dns-autoscaler-8687c64fc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:47Z"
      lastUpdateTime: "2020-04-21T13:09:47Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"glbc","kubernetes.io/cluster-service":"true","kubernetes.io/name":"GLBC"},"name":"l7-default-backend","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"glbc"}},"template":{"metadata":{"annotations":{"seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"glbc","name":"glbc"}},"spec":{"containers":[{"image":"k8s.gcr.io/defaultbackend-amd64:1.5","livenessProbe":{"httpGet":{"path":"/healthz","port":8080,"scheme":"HTTP"},"initialDelaySeconds":30,"timeoutSeconds":5},"name":"default-http-backend","ports":[{"containerPort":8080}],"resources":{"limits":{"cpu":"10m","memory":"20Mi"},"requests":{"cpu":"10m","memory":"20Mi"}}}]}}}}
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: glbc
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: GLBC
    name: l7-default-backend
    namespace: kube-system
    resourceVersion: "10399116"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/l7-default-backend
    uid: 770295af-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: glbc
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: glbc
          name: glbc
      spec:
        containers:
        - image: k8s.gcr.io/defaultbackend-amd64:1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: default-http-backend
          ports:
          - containerPort: 8080
            protocol: TCP
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:14Z"
      lastUpdateTime: "2020-03-15T10:05:48Z"
      message: ReplicaSet "l7-default-backend-8f479dd9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:53Z"
      lastUpdateTime: "2020-04-21T13:09:53Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metrics-server","kubernetes.io/cluster-service":"true","version":"v0.3.1"},"name":"metrics-server-v0.3.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metrics-server","version":"v0.3.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"metrics-server","version":"v0.3.1"},"name":"metrics-server"},"spec":{"containers":[{"command":["/metrics-server","--metric-resolution=30s","--kubelet-port=10255","--deprecated-kubelet-completely-insecure=true","--kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP"],"image":"k8s.gcr.io/metrics-server-amd64:v0.3.1","name":"metrics-server","ports":[{"containerPort":443,"name":"https","protocol":"TCP"}]},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=40m","--extra-cpu=0.5m","--memory=35Mi","--extra-memory=4Mi","--threshold=5","--deployment=metrics-server-v0.3.1","--container=metrics-server","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gke.gcr.io/addon-resizer:1.8.4-gke.0","name":"metrics-server-nanny","resources":{"limits":{"cpu":"100m","memory":"300Mi"},"requests":{"cpu":"5m","memory":"50Mi"}},"volumeMounts":[{"mountPath":"/etc/config","name":"metrics-server-config-volume"}]}],"priorityClassName":"system-cluster-critical","serviceAccountName":"metrics-server","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"metrics-server-config"},"name":"metrics-server-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:19Z"
    generation: 2
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: metrics-server
      kubernetes.io/cluster-service: "true"
      version: v0.3.1
    name: metrics-server-v0.3.1
    namespace: kube-system
    resourceVersion: "10399092"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/metrics-server-v0.3.1
    uid: 79cade0e-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: metrics-server
        version: v0.3.1
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources:
            limits:
              cpu: 43m
              memory: 55Mi
            requests:
              cpu: 43m
              memory: 55Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:19Z"
      lastUpdateTime: "2020-03-15T10:05:47Z"
      message: ReplicaSet "metrics-server-v0.3.1-5c6fbf777" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:48Z"
      lastUpdateTime: "2020-04-21T13:09:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","app":"stackdriver-metadata-agent","kubernetes.io/cluster-service":"true"},"name":"stackdriver-metadata-agent-cluster-level","namespace":"kube-system"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"stackdriver-metadata-agent","cluster-level":"true"}},"strategy":{"rollingUpdate":{"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app":"stackdriver-metadata-agent","cluster-level":"true"}},"spec":{"containers":[{"args":["-logtostderr","-v=1"],"env":[{"name":"CLUSTER_NAME","value":"indra20k8"},{"name":"CLUSTER_LOCATION","value":"us-central1-c"}],"image":"gcr.io/stackdriver-agents/metadata-agent-go:1.0.5","imagePullPolicy":"IfNotPresent","name":"metadata-agent","terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","volumeMounts":[{"mountPath":"/etc/ssl/certs","name":"ssl-certs"}]},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=40m","--extra-cpu=0.5m","--memory=20Mi","--extra-memory=1Mi","--threshold=5","--deployment=stackdriver-metadata-agent-cluster-level","--container=metadata-agent","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/addon-resizer:1.8.7","name":"metadata-agent-nanny","resources":{"limits":{"cpu":"50m","memory":"92560Ki"},"requests":{"cpu":"50m","memory":"92560Ki"}},"volumeMounts":[{"mountPath":"/etc/config","name":"metadata-agent-config-volume"}]}],"dnsPolicy":"ClusterFirst","priorityClassName":"system-cluster-critical","restartPolicy":"Always","schedulerName":"default-scheduler","securityContext":{},"serviceAccountName":"metadata-agent","terminationGracePeriodSeconds":5,"tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/etc/ssl/certs","type":"Directory"},"name":"ssl-certs"},{"configMap":{"name":"metadata-agent-config"},"name":"metadata-agent-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      app: stackdriver-metadata-agent
      kubernetes.io/cluster-service: "true"
    name: stackdriver-metadata-agent-cluster-level
    namespace: kube-system
    resourceVersion: "10399233"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/stackdriver-metadata-agent-cluster-level
    uid: 78ff7118-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            limits:
              cpu: 43m
              memory: 25Mi
            requests:
              cpu: 43m
              memory: 25Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-03-15T10:05:17Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-04-01T22:47:59Z"
      message: ReplicaSet "stackdriver-metadata-agent-cluster-level-865b464794" has
        successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== replicasets manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "31"
    creationTimestamp: "2020-04-21T19:16:25Z"
    generation: 7
    labels:
      pod-template-hash: 54794bdf9d
      run: essbaseservice
    name: essbaseservice-54794bdf9d
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "11026730"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-54794bdf9d
    uid: 984675b9-8404-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 54794bdf9d
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 54794bdf9d
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.4
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 7
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "34"
    creationTimestamp: "2020-04-27T17:49:28Z"
    generation: 2
    labels:
      pod-template-hash: 56547dc7f9
      run: essbaseservice
    name: essbaseservice-56547dc7f9
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "12162065"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-56547dc7f9
    uid: 712e59d4-88af-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 56547dc7f9
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 56547dc7f9
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "30"
    creationTimestamp: "2020-04-21T18:40:32Z"
    generation: 2
    labels:
      pod-template-hash: 567c46fdd5
      run: essbaseservice
    name: essbaseservice-567c46fdd5
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10470494"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-567c46fdd5
    uid: 94ac833e-83ff-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 567c46fdd5
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 567c46fdd5
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.3
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "24"
    creationTimestamp: "2020-04-18T09:34:30Z"
    generation: 10
    labels:
      pod-template-hash: 6bf544f9d7
      run: essbaseservice
    name: essbaseservice-6bf544f9d7
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10435004"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-6bf544f9d7
    uid: ce0bf8b9-8157-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 6bf544f9d7
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 6bf544f9d7
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v19.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 10
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "32"
    creationTimestamp: "2020-04-23T18:13:13Z"
    generation: 2
    labels:
      pod-template-hash: 77ccf98f4f
      run: essbaseservice
    name: essbaseservice-77ccf98f4f
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "11801964"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-77ccf98f4f
    uid: 18bb86b9-858e-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 77ccf98f4f
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 77ccf98f4f
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v21
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "27"
    creationTimestamp: "2020-04-21T17:07:08Z"
    generation: 2
    labels:
      pod-template-hash: 788c844cbc
      run: essbaseservice
    name: essbaseservice-788c844cbc
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10448598"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-788c844cbc
    uid: 8886e82b-83f2-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 788c844cbc
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 788c844cbc
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "33"
    creationTimestamp: "2020-04-26T11:39:13Z"
    generation: 2
    labels:
      pod-template-hash: 7b4b7f74db
      run: essbaseservice
    name: essbaseservice-7b4b7f74db
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "12159442"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-7b4b7f74db
    uid: 8d782d80-87b2-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 7b4b7f74db
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 7b4b7f74db
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v22
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "25"
    creationTimestamp: "2020-04-21T16:14:42Z"
    generation: 2
    labels:
      pod-template-hash: 7d49c7c4f6
      run: essbaseservice
    name: essbaseservice-7d49c7c4f6
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10442107"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-7d49c7c4f6
    uid: 35623118-83eb-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 7d49c7c4f6
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 7d49c7c4f6
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v19.2
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "29"
    creationTimestamp: "2020-04-21T17:29:31Z"
    generation: 2
    labels:
      pod-template-hash: 8487fb9456
      run: essbaseservice
    name: essbaseservice-8487fb9456
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10463374"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-8487fb9456
    uid: a8e4444e-83f5-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 8487fb9456
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 8487fb9456
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.2
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "26"
    creationTimestamp: "2020-04-21T16:51:18Z"
    generation: 2
    labels:
      pod-template-hash: c6bc79c7b
      run: essbaseservice
    name: essbaseservice-c6bc79c7b
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10445201"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-c6bc79c7b
    uid: 526b885f-83f0-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: c6bc79c7b
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: c6bc79c7b
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "35"
    creationTimestamp: "2020-04-27T18:02:40Z"
    generation: 3
    labels:
      pod-template-hash: f5f56b5b
      run: essbaseservice
    name: essbaseservice-f5f56b5b
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "13428051"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-f5f56b5b
    uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        pod-template-hash: f5f56b5b
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: f5f56b5b
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 1
    labels:
      k8s-app: event-exporter
      pod-template-hash: 7df89f4b8f
      version: v0.2.5
    name: event-exporter-v0.2.5-7df89f4b8f
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: event-exporter-v0.2.5
      uid: 78c77da7-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399194"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/event-exporter-v0.2.5-7df89f4b8f
    uid: 78c873a9-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: event-exporter
        pod-template-hash: 7df89f4b8f
        version: v0.2.5
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: event-exporter
          pod-template-hash: 7df89f4b8f
          version: v0.2.5
      spec:
        containers:
        - command:
          - /event-exporter
          - -sink-opts=-stackdriver-resource-model=new
          image: k8s.gcr.io/event-exporter:v0.2.5
          imagePullPolicy: IfNotPresent
          name: event-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: event-exporter-sa
        serviceAccountName: event-exporter-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: ""
          name: ssl-certs
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      k8s-app: fluentd-gcp-scaler
      pod-template-hash: 54ccb89d5
    name: fluentd-gcp-scaler-54ccb89d5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: fluentd-gcp-scaler
      uid: 7b7c5076-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399095"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/fluentd-gcp-scaler-54ccb89d5
    uid: 7b7d4c47-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: fluentd-gcp-scaler
        pod-template-hash: 54ccb89d5
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp-scaler
          pod-template-hash: 54ccb89d5
      spec:
        containers:
        - command:
          - /scaler.sh
          - --ds-name=fluentd-gcp-v3.1.1
          - --scaling-policy=fluentd-gcp-scaling-policy
          env:
          - name: CPU_REQUEST
            value: 100m
          - name: MEMORY_REQUEST
            value: 200Mi
          - name: CPU_LIMIT
            value: "1"
          - name: MEMORY_LIMIT
            value: 500Mi
          image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
          imagePullPolicy: IfNotPresent
          name: fluentd-gcp-scaler
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp-scaler
        serviceAccountName: fluentd-gcp-scaler
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-03-15T10:05:58Z"
    generation: 2
    labels:
      k8s-app: heapster
      pod-template-hash: 667d4944f6
      version: v1.7.2
    name: heapster-gke-667d4944f6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938171"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-667d4944f6
    uid: 90ef5064-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 667d4944f6
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 667d4944f6
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92960Ki
            requests:
              cpu: 50m
              memory: 92960Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:16Z"
    generation: 2
    labels:
      k8s-app: heapster
      pod-template-hash: 789949956d
      version: v1.7.2
    name: heapster-gke-789949956d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "844"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-789949956d
    uid: 77f0cca9-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 789949956d
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 789949956d
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92960Ki
            requests:
              cpu: 50m
              memory: 92960Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2020-04-01T22:47:48Z"
    generation: 1
    labels:
      k8s-app: heapster
      pod-template-hash: 7df9bb754d
      version: v1.7.2
    name: heapster-gke-7df9bb754d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399251"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-7df9bb754d
    uid: cf396f60-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 7df9bb754d
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 7df9bb754d
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 3
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5877696fb4
    name: kube-dns-5877696fb4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-dns
      uid: 76bed5da-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399307"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/kube-dns-5877696fb4
    uid: 76c1c78a-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 5877696fb4
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 5877696fb4
      spec:
        containers:
        - args:
          - --domain=cluster.local.
          - --dns-port=10053
          - --config-dir=/kube-dns-config
          - --v=2
          env:
          - name: PROMETHEUS_PORT
            value: "10055"
          image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/kubedns
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kubedns
          ports:
          - containerPort: 10053
            name: dns-local
            protocol: UDP
          - containerPort: 10053
            name: dns-tcp-local
            protocol: TCP
          - containerPort: 10055
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readiness
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /kube-dns-config
            name: kube-dns-config
        - args:
          - -v=2
          - -logtostderr
          - -configDir=/etc/k8s/dns/dnsmasq-nanny
          - -restartDnsmasq=true
          - --
          - -k
          - --cache-size=1000
          - --no-negcache
          - --log-facility=-
          - --server=/cluster.local/127.0.0.1#10053
          - --server=/in-addr.arpa/127.0.0.1#10053
          - --server=/ip6.arpa/127.0.0.1#10053
          image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/dnsmasq
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: dnsmasq
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          resources:
            requests:
              cpu: 150m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/k8s/dns/dnsmasq-nanny
            name: kube-dns-config
        - args:
          - --v=2
          - --logtostderr
          - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
          - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
          image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: sidecar
          ports:
          - containerPort: 10054
            name: metrics
            protocol: TCP
          resources:
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          - --v=2
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.4.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-dns
        serviceAccountName: kube-dns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-dns
            optional: true
          name: kube-dns-config
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 1
    labels:
      k8s-app: kube-dns-autoscaler
      pod-template-hash: 8687c64fc
    name: kube-dns-autoscaler-8687c64fc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-dns-autoscaler
      uid: 7776165d-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399082"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/kube-dns-autoscaler-8687c64fc
    uid: 7777872f-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns-autoscaler
        pod-template-hash: 8687c64fc
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns-autoscaler
          pod-template-hash: 8687c64fc
      spec:
        containers:
        - command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          - --target=Deployment/kube-dns
          - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
          - --logtostderr=true
          - --v=2
          image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
          imagePullPolicy: IfNotPresent
          name: autoscaler
          resources:
            requests:
              cpu: 20m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: kube-dns-autoscaler
        serviceAccountName: kube-dns-autoscaler
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 1
    labels:
      k8s-app: glbc
      name: glbc
      pod-template-hash: 8f479dd9
    name: l7-default-backend-8f479dd9
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: l7-default-backend
      uid: 770295af-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399115"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/l7-default-backend-8f479dd9
    uid: 77042a48-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: glbc
        pod-template-hash: 8f479dd9
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: glbc
          name: glbc
          pod-template-hash: 8f479dd9
      spec:
        containers:
        - image: k8s.gcr.io/defaultbackend-amd64:1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: default-http-backend
          ports:
          - containerPort: 8080
            protocol: TCP
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-03-15T10:05:35Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5c6fbf777
      version: v0.3.1
    name: metrics-server-v0.3.1-5c6fbf777
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server-v0.3.1
      uid: 79cade0e-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399090"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/metrics-server-v0.3.1-5c6fbf777
    uid: 83c10be5-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 5c6fbf777
        version: v0.3.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 5c6fbf777
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources:
            limits:
              cpu: 43m
              memory: 55Mi
            requests:
              cpu: 43m
              memory: 55Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:19Z"
    generation: 2
    labels:
      k8s-app: metrics-server
      pod-template-hash: 8559697b9c
      version: v0.3.1
    name: metrics-server-v0.3.1-8559697b9c
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server-v0.3.1
      uid: 79cade0e-66a4-11ea-b80b-42010a800288
    resourceVersion: "742"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/metrics-server-v0.3.1-8559697b9c
    uid: 79d32dbf-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 8559697b9c
        version: v0.3.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 8559697b9c
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-04-01T22:47:47Z"
    generation: 2
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 5dd546c8d6
    name: stackdriver-metadata-agent-cluster-level-5dd546c8d6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938145"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-5dd546c8d6
    uid: cf0cdb85-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 5dd546c8d6
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 5dd546c8d6
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 2
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 79bd67c4b5
    name: stackdriver-metadata-agent-cluster-level-79bd67c4b5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938086"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-79bd67c4b5
    uid: 79015194-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 79bd67c4b5
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 79bd67c4b5
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            requests:
              cpu: 40m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2020-04-01T22:47:53Z"
    generation: 1
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 865b464794
    name: stackdriver-metadata-agent-cluster-level-865b464794
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399232"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-865b464794
    uid: d28677b2-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 865b464794
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 865b464794
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            limits:
              cpu: 43m
              memory: 25Mi
            requests:
              cpu: 43m
              memory: 25Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== leases manifests ========

apiVersion: v1
items:
- apiVersion: coordination.k8s.io/v1
  kind: Lease
  metadata:
    creationTimestamp: "2020-03-17T16:27:54Z"
    name: gke-indra20k8-default-pool-b615b32b-kb0v
    namespace: kube-node-lease
    ownerReferences:
    - apiVersion: v1
      kind: Node
      name: gke-indra20k8-default-pool-b615b32b-kb0v
      uid: 4108a29a-686c-11ea-b004-42010a80008c
    resourceVersion: "13429989"
    selfLink: /apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/gke-indra20k8-default-pool-b615b32b-kb0v
    uid: 40e7b532-686c-11ea-b004-42010a80008c
  spec:
    holderIdentity: gke-indra20k8-default-pool-b615b32b-kb0v
    leaseDurationSeconds: 40
    renewTime: "2020-05-02T07:08:29.014469Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== daemonsets manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"},"name":"fluentd-gcp-v3.1.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"template":{"metadata":{"annotations":{"EnableKnativeConfig":"false","EnableNodeJournal":"false","EnablePodSecurityPolicy":"false","PodLogEnabled":"false","SystemOnlyLogging":"false","scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"fluentd-gcp","kubernetes.io/cluster-service":"true","version":"v3.1.1"}},"spec":{"containers":[{"env":[{"name":"NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"apiVersion":"v1","fieldPath":"spec.nodeName"}}},{"name":"STACKDRIVER_METADATA_AGENT_URL","value":"http://$(NODE_NAME):8799"}],"image":"gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060","livenessProbe":{"exec":{"command":["/bin/sh","-c","\nLIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then\n  exit 1;\nfi; touch -d \"${STUCK_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-stuck; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)\" ]; then\n  rm -rf /var/run/google-fluentd/buffers;\n  exit 1;\nfi; touch -d \"${LIVENESS_THRESHOLD_SECONDS} seconds ago\" /tmp/marker-liveness; if [ -z \"$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)\" ]; then\n  exit 1;\nfi;\n"]},"initialDelaySeconds":600,"periodSeconds":60},"name":"fluentd-gcp","volumeMounts":[{"mountPath":"/var/run/google-fluentd","name":"varrun"},{"mountPath":"/var/log","name":"varlog"},{"mountPath":"/var/lib/docker/containers","name":"varlibdockercontainers","readOnly":true},{"mountPath":"/etc/google-fluentd/config.d","name":"config-volume"}]},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/fluentd-ds-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"fluentd-gcp","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/run/google-fluentd"},"name":"varrun"},{"hostPath":{"path":"/var/log"},"name":"varlog"},{"hostPath":{"path":"/var/lib/docker/containers"},"name":"varlibdockercontainers"},{"configMap":{"name":"fluentd-gcp-config-v1.2.6"},"name":"config-volume"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1
    namespace: kube-system
    resourceVersion: "10399164"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.1.1
    uid: 779ca16d-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: fluentd-gcp
        kubernetes.io/cluster-service: "true"
        version: v3.1.1
    template:
      metadata:
        annotations:
          EnableKnativeConfig: "false"
          EnableNodeJournal: "false"
          EnablePodSecurityPolicy: "false"
          PodLogEnabled: "false"
          SystemOnlyLogging: "false"
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp
          kubernetes.io/cluster-service: "true"
          version: v3.1.1
      spec:
        containers:
        - env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: STACKDRIVER_METADATA_AGENT_URL
            value: http://$(NODE_NAME):8799
          image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /bin/sh
              - -c
              - |2

                LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
                  exit 1;
                fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
                  rm -rf /var/run/google-fluentd/buffers;
                  exit 1;
                fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
                  exit 1;
                fi;
            failureThreshold: 3
            initialDelaySeconds: 600
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 1
          name: fluentd-gcp
          resources:
            limits:
              cpu: "1"
              memory: 500Mi
            requests:
              cpu: 100m
              memory: 200Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run/google-fluentd
            name: varrun
          - mountPath: /var/log
            name: varlog
          - mountPath: /var/lib/docker/containers
            name: varlibdockercontainers
            readOnly: true
          - mountPath: /etc/google-fluentd/config.d
            name: config-volume
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/fluentd-ds-ready: "true"
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp
        serviceAccountName: fluentd-gcp
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/run/google-fluentd
            type: ""
          name: varrun
        - hostPath:
            path: /var/log
            type: ""
          name: varlog
        - hostPath:
            path: /var/lib/docker/containers
            type: ""
          name: varlibdockercontainers
        - configMap:
            defaultMode: 420
            name: fluentd-gcp-config-v1.2.6
          name: config-volume
    templateGeneration: 3
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 3
    updatedNumberScheduled: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"},"name":"metadata-proxy-v0.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metadata-proxy","version":"v0.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"metadata-proxy","kubernetes.io/cluster-service":"true","version":"v0.1"}},"spec":{"containers":[{"image":"k8s.gcr.io/metadata-proxy:v0.1.11","name":"metadata-proxy","resources":{"limits":{"cpu":"30m","memory":"25Mi"},"requests":{"cpu":"30m","memory":"25Mi"}},"securityContext":{"privileged":true}},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter","resources":{"limits":{"cpu":"2m","memory":"20Mi"},"requests":{"cpu":"2m","memory":"20Mi"}}}],"dnsPolicy":"Default","hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/metadata-proxy-ready":"true","beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"metadata-proxy","terminationGracePeriodSeconds":30,"tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: metadata-proxy
      kubernetes.io/cluster-service: "true"
      version: v0.1
    name: metadata-proxy-v0.1
    namespace: kube-system
    resourceVersion: "396"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1
    uid: 7944d08a-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: metadata-proxy
        version: v0.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: metadata-proxy
          kubernetes.io/cluster-service: "true"
          version: v0.1
      spec:
        containers:
        - image: k8s.gcr.io/metadata-proxy:v0.1.11
          imagePullPolicy: IfNotPresent
          name: metadata-proxy
          resources:
            limits:
              cpu: 30m
              memory: 25Mi
            requests:
              cpu: 30m
              memory: 25Mi
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources:
            limits:
              cpu: 2m
              memory: 20Mi
            requests:
              cpu: 2m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/metadata-proxy-ready: "true"
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-proxy
        serviceAccountName: metadata-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 0
    desiredNumberScheduled: 0
    numberMisscheduled: 0
    numberReady: 0
    observedGeneration: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"nvidia-gpu-device-plugin"},"name":"nvidia-gpu-device-plugin","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"nvidia-gpu-device-plugin"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":""},"labels":{"k8s-app":"nvidia-gpu-device-plugin"}},"spec":{"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchExpressions":[{"key":"cloud.google.com/gke-accelerator","operator":"Exists"}]}]}}},"containers":[{"command":["/usr/bin/nvidia-gpu-device-plugin","-logtostderr"],"image":"k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa","name":"nvidia-gpu-device-plugin","resources":{"limits":{"cpu":"50m","memory":"10Mi"},"requests":{"cpu":"50m","memory":"10Mi"}},"securityContext":{"privileged":true},"volumeMounts":[{"mountPath":"/device-plugin","name":"device-plugin"},{"mountPath":"/dev","name":"dev"}]}],"priorityClassName":"system-node-critical","tolerations":[{"effect":"NoExecute","operator":"Exists"},{"effect":"NoSchedule","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/var/lib/kubelet/device-plugins"},"name":"device-plugin"},{"hostPath":{"path":"/dev"},"name":"dev"}]}},"updateStrategy":{"type":"RollingUpdate"}}}
    creationTimestamp: "2020-03-15T10:05:21Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: nvidia-gpu-device-plugin
    name: nvidia-gpu-device-plugin
    namespace: kube-system
    resourceVersion: "439"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/nvidia-gpu-device-plugin
    uid: 7b6be270-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: nvidia-gpu-device-plugin
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
        creationTimestamp: null
        labels:
          k8s-app: nvidia-gpu-device-plugin
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: cloud.google.com/gke-accelerator
                  operator: Exists
        containers:
        - command:
          - /usr/bin/nvidia-gpu-device-plugin
          - -logtostderr
          image: k8s.gcr.io/nvidia-gpu-device-plugin@sha256:4b036e8844920336fa48f36edeb7d4398f426d6a934ba022848deed2edbf09aa
          imagePullPolicy: IfNotPresent
          name: nvidia-gpu-device-plugin
          resources:
            limits:
              cpu: 50m
              memory: 10Mi
            requests:
              cpu: 50m
              memory: 10Mi
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /device-plugin
            name: device-plugin
          - mountPath: /dev
            name: dev
        dnsPolicy: ClusterFirst
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/lib/kubelet/device-plugins
            type: ""
          name: device-plugin
        - hostPath:
            path: /dev
            type: ""
          name: dev
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 0
    desiredNumberScheduled: 0
    numberMisscheduled: 0
    numberReady: 0
    observedGeneration: 1
- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"prometheus-to-sd","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"prometheus-to-sd"}},"template":{"metadata":{"labels":{"k8s-app":"prometheus-to-sd"}},"spec":{"containers":[{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=container.googleapis.com/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=container.googleapis.com/internal/nodes","--api-override=https://monitoring.googleapis.com/","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd"},{"command":["/monitor","--source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds\u0026metricsPrefix=kubernetes.io/internal/addons","--source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count","--source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total\u0026podIdLabel=pod\u0026namespaceIdLabel=namespace\u0026containerNameLabel=container","--stackdriver-prefix=kubernetes.io/internal/nodes","--api-override=https://monitoring.googleapis.com/","--monitored-resource-type-prefix=k8s_","--monitored-resource-labels=location=us-central1-c","--export-interval=120s"],"image":"k8s.gcr.io/prometheus-to-sd:v0.8.2","imagePullPolicy":"IfNotPresent","name":"prometheus-to-sd-new-model","resources":{"limits":{"cpu":"3m","memory":"20Mi"},"requests":{"cpu":"1m","memory":"20Mi"}}}],"hostNetwork":true,"nodeSelector":{"beta.kubernetes.io/os":"linux"},"priorityClassName":"system-node-critical","serviceAccountName":"prometheus-to-sd","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}]}}}}
    creationTimestamp: "2020-03-15T10:05:18Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: prometheus-to-sd
    namespace: kube-system
    resourceVersion: "10399098"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/prometheus-to-sd
    uid: 792a47e1-66a4-11ea-b80b-42010a800288
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: prometheus-to-sd
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: prometheus-to-sd
      spec:
        containers:
        - command:
          - /monitor
          - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
          - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
          - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
          - --stackdriver-prefix=container.googleapis.com/internal/nodes
          - --api-override=https://monitoring.googleapis.com/
          - --export-interval=120s
          image: k8s.gcr.io/prometheus-to-sd:v0.8.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=kubernetes.io/internal/addons
          - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
          - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
          - --stackdriver-prefix=kubernetes.io/internal/nodes
          - --api-override=https://monitoring.googleapis.com/
          - --monitored-resource-type-prefix=k8s_
          - --monitored-resource-labels=location=us-central1-c
          - --export-interval=120s
          image: k8s.gcr.io/prometheus-to-sd:v0.8.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-new-model
          resources:
            limits:
              cpu: 3m
              memory: 20Mi
            requests:
              cpu: 1m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          beta.kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: prometheus-to-sd
        serviceAccountName: prometheus-to-sd
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
    templateGeneration: 1
    updateStrategy:
      rollingUpdate:
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== deployments manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "35"
    creationTimestamp: "2020-03-17T16:58:41Z"
    generation: 62
    labels:
      run: essbaseservice
    name: essbaseservice
    namespace: default
    resourceVersion: "13428053"
    selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/essbaseservice
    uid: 8dfc8260-6870-11ea-b004-42010a80008c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        run: essbaseservice
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-17T16:58:41Z"
      lastUpdateTime: "2020-04-27T18:02:42Z"
      message: ReplicaSet "essbaseservice-f5f56b5b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-05-02T06:58:31Z"
      lastUpdateTime: "2020-05-02T06:58:31Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 62
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1beta1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"event-exporter","kubernetes.io/cluster-service":"true","version":"v0.2.5"},"name":"event-exporter-v0.2.5","namespace":"kube-system"},"spec":{"replicas":1,"template":{"metadata":{"labels":{"k8s-app":"event-exporter","version":"v0.2.5"}},"spec":{"containers":[{"command":["/event-exporter","-sink-opts=-stackdriver-resource-model=new"],"image":"k8s.gcr.io/event-exporter:v0.2.5","name":"event-exporter"},{"command":["/monitor","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prometheus-to-sd-exporter"}],"serviceAccountName":"event-exporter-sa","terminationGracePeriodSeconds":30,"volumes":[{"hostPath":{"path":"/etc/ssl/certs"},"name":"ssl-certs"}]}}}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: event-exporter
      kubernetes.io/cluster-service: "true"
      version: v0.2.5
    name: event-exporter-v0.2.5
    namespace: kube-system
    resourceVersion: "10399195"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/event-exporter-v0.2.5
    uid: 78c77da7-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 2
    selector:
      matchLabels:
        k8s-app: event-exporter
        version: v0.2.5
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: event-exporter
          version: v0.2.5
      spec:
        containers:
        - command:
          - /event-exporter
          - -sink-opts=-stackdriver-resource-model=new
          image: k8s.gcr.io/event-exporter:v0.2.5
          imagePullPolicy: IfNotPresent
          name: event-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: event-exporter-sa
        serviceAccountName: event-exporter-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: ""
          name: ssl-certs
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-03-15T10:06:01Z"
      message: ReplicaSet "event-exporter-v0.2.5-7df89f4b8f" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:10:15Z"
      lastUpdateTime: "2020-04-21T13:10:15Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"fluentd-gcp-scaler","version":"v0.5.1"},"name":"fluentd-gcp-scaler","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"fluentd-gcp-scaler"}},"template":{"metadata":{"labels":{"k8s-app":"fluentd-gcp-scaler"}},"spec":{"containers":[{"command":["/scaler.sh","--ds-name=fluentd-gcp-v3.1.1","--scaling-policy=fluentd-gcp-scaling-policy"],"env":[{"name":"CPU_REQUEST","value":"100m"},{"name":"MEMORY_REQUEST","value":"200Mi"},{"name":"CPU_LIMIT","value":"1"},{"name":"MEMORY_LIMIT","value":"500Mi"}],"image":"k8s.gcr.io/fluentd-gcp-scaler:0.5.2","name":"fluentd-gcp-scaler"}],"serviceAccountName":"fluentd-gcp-scaler"}}}}
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: fluentd-gcp-scaler
      version: v0.5.1
    name: fluentd-gcp-scaler
    namespace: kube-system
    resourceVersion: "10399096"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/fluentd-gcp-scaler
    uid: 7b7c5076-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: fluentd-gcp-scaler
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp-scaler
      spec:
        containers:
        - command:
          - /scaler.sh
          - --ds-name=fluentd-gcp-v3.1.1
          - --scaling-policy=fluentd-gcp-scaling-policy
          env:
          - name: CPU_REQUEST
            value: 100m
          - name: MEMORY_REQUEST
            value: 200Mi
          - name: CPU_LIMIT
            value: "1"
          - name: MEMORY_LIMIT
            value: 500Mi
          image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
          imagePullPolicy: IfNotPresent
          name: fluentd-gcp-scaler
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp-scaler
        serviceAccountName: fluentd-gcp-scaler
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:22Z"
      lastUpdateTime: "2020-03-15T10:05:34Z"
      message: ReplicaSet "fluentd-gcp-scaler-54ccb89d5" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:48Z"
      lastUpdateTime: "2020-04-21T13:09:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"heapster","kubernetes.io/cluster-service":"true","version":"v1.7.2"},"name":"heapster-gke","namespace":"kube-system"},"spec":{"replicas":1,"selector":{"matchLabels":{"k8s-app":"heapster"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"heapster","version":"v1.7.2"}},"spec":{"containers":[{"command":["/heapster","--source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id","--sink=stackdriver:?cluster_name=indra20k8\u0026use_old_resources=false\u0026use_new_resources=true\u0026min_interval_sec=100\u0026batch_export_timeout_sec=110\u0026cluster_location=us-central1-c"],"image":"gke.gcr.io/heapster:v1.7.2","livenessProbe":{"httpGet":{"path":"/healthz","port":8082,"scheme":"HTTP"},"initialDelaySeconds":180,"timeoutSeconds":5},"name":"heapster"},{"command":["/monitor","--source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.5.0","name":"prom-to-sd"},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=10m","--extra-cpu=0.5m","--memory=100Mi","--extra-memory=4Mi","--threshold=5","--deployment=heapster-gke","--container=heapster","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/addon-resizer:1.8.3","name":"heapster-nanny","resources":{"limits":{"cpu":"50m","memory":"92560Ki"},"requests":{"cpu":"50m","memory":"92560Ki"}},"volumeMounts":[{"mountPath":"/etc/config","name":"heapster-config-volume"}]}],"priorityClassName":"system-cluster-critical","securityContext":{"fsGroup":65534,"supplementalGroups":[65534]},"serviceAccountName":"heapster","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"heapster-config"},"name":"heapster-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:16Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: heapster
      kubernetes.io/cluster-service: "true"
      version: v1.7.2
    name: heapster-gke
    namespace: kube-system
    resourceVersion: "10399252"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/heapster-gke
    uid: 77ee5493-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: heapster
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:16Z"
      lastUpdateTime: "2020-04-01T22:47:56Z"
      message: ReplicaSet "heapster-gke-7df9bb754d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:10:29Z"
      lastUpdateTime: "2020-04-21T13:10:29Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kube-dns","kubernetes.io/cluster-service":"true"},"name":"kube-dns","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"kube-dns"}},"strategy":{"rollingUpdate":{"maxSurge":"10%","maxUnavailable":0}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"kube-dns"}},"spec":{"containers":[{"args":["--domain=cluster.local.","--dns-port=10053","--config-dir=/kube-dns-config","--v=2"],"env":[{"name":"PROMETHEUS_PORT","value":"10055"}],"image":"k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthcheck/kubedns","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"kubedns","ports":[{"containerPort":10053,"name":"dns-local","protocol":"UDP"},{"containerPort":10053,"name":"dns-tcp-local","protocol":"TCP"},{"containerPort":10055,"name":"metrics","protocol":"TCP"}],"readinessProbe":{"httpGet":{"path":"/readiness","port":8081,"scheme":"HTTP"},"initialDelaySeconds":3,"timeoutSeconds":5},"resources":{"limits":{"memory":"170Mi"},"requests":{"cpu":"100m","memory":"70Mi"}},"volumeMounts":[{"mountPath":"/kube-dns-config","name":"kube-dns-config"}]},{"args":["-v=2","-logtostderr","-configDir=/etc/k8s/dns/dnsmasq-nanny","-restartDnsmasq=true","--","-k","--cache-size=1000","--no-negcache","--log-facility=-","--server=/cluster.local/127.0.0.1#10053","--server=/in-addr.arpa/127.0.0.1#10053","--server=/ip6.arpa/127.0.0.1#10053"],"image":"k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthcheck/dnsmasq","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"dnsmasq","ports":[{"containerPort":53,"name":"dns","protocol":"UDP"},{"containerPort":53,"name":"dns-tcp","protocol":"TCP"}],"resources":{"requests":{"cpu":"150m","memory":"20Mi"}},"volumeMounts":[{"mountPath":"/etc/k8s/dns/dnsmasq-nanny","name":"kube-dns-config"}]},{"args":["--v=2","--logtostderr","--probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV","--probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV"],"image":"k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4","livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/metrics","port":10054,"scheme":"HTTP"},"initialDelaySeconds":60,"successThreshold":1,"timeoutSeconds":5},"name":"sidecar","ports":[{"containerPort":10054,"name":"metrics","protocol":"TCP"}],"resources":{"requests":{"cpu":"10m","memory":"20Mi"}}},{"command":["/monitor","--source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits","--stackdriver-prefix=container.googleapis.com/internal/addons","--api-override=https://monitoring.googleapis.com/","--pod-id=$(POD_NAME)","--namespace-id=$(POD_NAMESPACE)","--v=2"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/prometheus-to-sd:v0.4.2","name":"prometheus-to-sd"}],"dnsPolicy":"Default","priorityClassName":"system-cluster-critical","serviceAccountName":"kube-dns","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"kube-dns","optional":true},"name":"kube-dns-config"}]}}}}
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
    name: kube-dns
    namespace: kube-system
    resourceVersion: "10399309"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/kube-dns
    uid: 76bed5da-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 2147483647
    replicas: 1
    revisionHistoryLimit: 2147483647
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 10%
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        containers:
        - args:
          - --domain=cluster.local.
          - --dns-port=10053
          - --config-dir=/kube-dns-config
          - --v=2
          env:
          - name: PROMETHEUS_PORT
            value: "10055"
          image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/kubedns
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kubedns
          ports:
          - containerPort: 10053
            name: dns-local
            protocol: UDP
          - containerPort: 10053
            name: dns-tcp-local
            protocol: TCP
          - containerPort: 10055
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readiness
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /kube-dns-config
            name: kube-dns-config
        - args:
          - -v=2
          - -logtostderr
          - -configDir=/etc/k8s/dns/dnsmasq-nanny
          - -restartDnsmasq=true
          - --
          - -k
          - --cache-size=1000
          - --no-negcache
          - --log-facility=-
          - --server=/cluster.local/127.0.0.1#10053
          - --server=/in-addr.arpa/127.0.0.1#10053
          - --server=/ip6.arpa/127.0.0.1#10053
          image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/dnsmasq
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: dnsmasq
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          resources:
            requests:
              cpu: 150m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/k8s/dns/dnsmasq-nanny
            name: kube-dns-config
        - args:
          - --v=2
          - --logtostderr
          - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
          - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
          image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: sidecar
          ports:
          - containerPort: 10054
            name: metrics
            protocol: TCP
          resources:
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          - --v=2
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.4.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-dns
        serviceAccountName: kube-dns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-dns
            optional: true
          name: kube-dns-config
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-04-21T13:10:45Z"
      lastUpdateTime: "2020-04-21T13:10:45Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kube-dns-autoscaler","kubernetes.io/cluster-service":"true"},"name":"kube-dns-autoscaler","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"kube-dns-autoscaler"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"kube-dns-autoscaler"}},"spec":{"containers":[{"command":["/cluster-proportional-autoscaler","--namespace=kube-system","--configmap=kube-dns-autoscaler","--target=Deployment/kube-dns","--default-params={\"linear\":{\"coresPerReplica\":256,\"nodesPerReplica\":16,\"preventSinglePointFailure\":true}}","--logtostderr=true","--v=2"],"image":"gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0","name":"autoscaler","resources":{"requests":{"cpu":"20m","memory":"10Mi"}}}],"priorityClassName":"system-cluster-critical","securityContext":{"fsGroup":65534,"supplementalGroups":[65534]},"serviceAccountName":"kube-dns-autoscaler","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}]}}}}
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kube-dns-autoscaler
      kubernetes.io/cluster-service: "true"
    name: kube-dns-autoscaler
    namespace: kube-system
    resourceVersion: "10399083"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/kube-dns-autoscaler
    uid: 7776165d-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns-autoscaler
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns-autoscaler
      spec:
        containers:
        - command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          - --target=Deployment/kube-dns
          - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
          - --logtostderr=true
          - --v=2
          image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
          imagePullPolicy: IfNotPresent
          name: autoscaler
          resources:
            requests:
              cpu: 20m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: kube-dns-autoscaler
        serviceAccountName: kube-dns-autoscaler
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:15Z"
      lastUpdateTime: "2020-03-15T10:05:32Z"
      message: ReplicaSet "kube-dns-autoscaler-8687c64fc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:47Z"
      lastUpdateTime: "2020-04-21T13:09:47Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"glbc","kubernetes.io/cluster-service":"true","kubernetes.io/name":"GLBC"},"name":"l7-default-backend","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"glbc"}},"template":{"metadata":{"annotations":{"seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"glbc","name":"glbc"}},"spec":{"containers":[{"image":"k8s.gcr.io/defaultbackend-amd64:1.5","livenessProbe":{"httpGet":{"path":"/healthz","port":8080,"scheme":"HTTP"},"initialDelaySeconds":30,"timeoutSeconds":5},"name":"default-http-backend","ports":[{"containerPort":8080}],"resources":{"limits":{"cpu":"10m","memory":"20Mi"},"requests":{"cpu":"10m","memory":"20Mi"}}}]}}}}
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: glbc
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: GLBC
    name: l7-default-backend
    namespace: kube-system
    resourceVersion: "10399116"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/l7-default-backend
    uid: 770295af-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: glbc
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: glbc
          name: glbc
      spec:
        containers:
        - image: k8s.gcr.io/defaultbackend-amd64:1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: default-http-backend
          ports:
          - containerPort: 8080
            protocol: TCP
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:14Z"
      lastUpdateTime: "2020-03-15T10:05:48Z"
      message: ReplicaSet "l7-default-backend-8f479dd9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:53Z"
      lastUpdateTime: "2020-04-21T13:09:53Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"metrics-server","kubernetes.io/cluster-service":"true","version":"v0.3.1"},"name":"metrics-server-v0.3.1","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metrics-server","version":"v0.3.1"}},"template":{"metadata":{"annotations":{"scheduler.alpha.kubernetes.io/critical-pod":"","seccomp.security.alpha.kubernetes.io/pod":"docker/default"},"labels":{"k8s-app":"metrics-server","version":"v0.3.1"},"name":"metrics-server"},"spec":{"containers":[{"command":["/metrics-server","--metric-resolution=30s","--kubelet-port=10255","--deprecated-kubelet-completely-insecure=true","--kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP"],"image":"k8s.gcr.io/metrics-server-amd64:v0.3.1","name":"metrics-server","ports":[{"containerPort":443,"name":"https","protocol":"TCP"}]},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=40m","--extra-cpu=0.5m","--memory=35Mi","--extra-memory=4Mi","--threshold=5","--deployment=metrics-server-v0.3.1","--container=metrics-server","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"gke.gcr.io/addon-resizer:1.8.4-gke.0","name":"metrics-server-nanny","resources":{"limits":{"cpu":"100m","memory":"300Mi"},"requests":{"cpu":"5m","memory":"50Mi"}},"volumeMounts":[{"mountPath":"/etc/config","name":"metrics-server-config-volume"}]}],"priorityClassName":"system-cluster-critical","serviceAccountName":"metrics-server","tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"configMap":{"name":"metrics-server-config"},"name":"metrics-server-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:19Z"
    generation: 2
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: metrics-server
      kubernetes.io/cluster-service: "true"
      version: v0.3.1
    name: metrics-server-v0.3.1
    namespace: kube-system
    resourceVersion: "10399092"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/metrics-server-v0.3.1
    uid: 79cade0e-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: metrics-server
        version: v0.3.1
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources:
            limits:
              cpu: 43m
              memory: 55Mi
            requests:
              cpu: 43m
              memory: 55Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:19Z"
      lastUpdateTime: "2020-03-15T10:05:47Z"
      message: ReplicaSet "metrics-server-v0.3.1-5c6fbf777" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2020-04-21T13:09:48Z"
      lastUpdateTime: "2020-04-21T13:09:48Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","app":"stackdriver-metadata-agent","kubernetes.io/cluster-service":"true"},"name":"stackdriver-metadata-agent-cluster-level","namespace":"kube-system"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"stackdriver-metadata-agent","cluster-level":"true"}},"strategy":{"rollingUpdate":{"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app":"stackdriver-metadata-agent","cluster-level":"true"}},"spec":{"containers":[{"args":["-logtostderr","-v=1"],"env":[{"name":"CLUSTER_NAME","value":"indra20k8"},{"name":"CLUSTER_LOCATION","value":"us-central1-c"}],"image":"gcr.io/stackdriver-agents/metadata-agent-go:1.0.5","imagePullPolicy":"IfNotPresent","name":"metadata-agent","terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","volumeMounts":[{"mountPath":"/etc/ssl/certs","name":"ssl-certs"}]},{"command":["/pod_nanny","--config-dir=/etc/config","--cpu=40m","--extra-cpu=0.5m","--memory=20Mi","--extra-memory=1Mi","--threshold=5","--deployment=stackdriver-metadata-agent-cluster-level","--container=metadata-agent","--poll-period=300000","--estimator=exponential","--minClusterSize=5"],"env":[{"name":"MY_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"MY_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"k8s.gcr.io/addon-resizer:1.8.7","name":"metadata-agent-nanny","resources":{"limits":{"cpu":"50m","memory":"92560Ki"},"requests":{"cpu":"50m","memory":"92560Ki"}},"volumeMounts":[{"mountPath":"/etc/config","name":"metadata-agent-config-volume"}]}],"dnsPolicy":"ClusterFirst","priorityClassName":"system-cluster-critical","restartPolicy":"Always","schedulerName":"default-scheduler","securityContext":{},"serviceAccountName":"metadata-agent","terminationGracePeriodSeconds":5,"tolerations":[{"key":"CriticalAddonsOnly","operator":"Exists"}],"volumes":[{"hostPath":{"path":"/etc/ssl/certs","type":"Directory"},"name":"ssl-certs"},{"configMap":{"name":"metadata-agent-config"},"name":"metadata-agent-config-volume"}]}}}}
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 3
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      app: stackdriver-metadata-agent
      kubernetes.io/cluster-service: "true"
    name: stackdriver-metadata-agent-cluster-level
    namespace: kube-system
    resourceVersion: "10399233"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/deployments/stackdriver-metadata-agent-cluster-level
    uid: 78ff7118-66a4-11ea-b80b-42010a800288
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            limits:
              cpu: 43m
              memory: 25Mi
            requests:
              cpu: 43m
              memory: 25Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-03-15T10:05:17Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2020-03-15T10:05:17Z"
      lastUpdateTime: "2020-04-01T22:47:59Z"
      message: ReplicaSet "stackdriver-metadata-agent-cluster-level-865b464794" has
        successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== replicasets manifests ========

apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "31"
    creationTimestamp: "2020-04-21T19:16:25Z"
    generation: 7
    labels:
      pod-template-hash: 54794bdf9d
      run: essbaseservice
    name: essbaseservice-54794bdf9d
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "11026730"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-54794bdf9d
    uid: 984675b9-8404-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 54794bdf9d
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 54794bdf9d
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.4
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 7
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "34"
    creationTimestamp: "2020-04-27T17:49:28Z"
    generation: 2
    labels:
      pod-template-hash: 56547dc7f9
      run: essbaseservice
    name: essbaseservice-56547dc7f9
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "12162065"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-56547dc7f9
    uid: 712e59d4-88af-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 56547dc7f9
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 56547dc7f9
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "30"
    creationTimestamp: "2020-04-21T18:40:32Z"
    generation: 2
    labels:
      pod-template-hash: 567c46fdd5
      run: essbaseservice
    name: essbaseservice-567c46fdd5
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10470494"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-567c46fdd5
    uid: 94ac833e-83ff-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 567c46fdd5
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 567c46fdd5
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.3
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "24"
    creationTimestamp: "2020-04-18T09:34:30Z"
    generation: 10
    labels:
      pod-template-hash: 6bf544f9d7
      run: essbaseservice
    name: essbaseservice-6bf544f9d7
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10435004"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-6bf544f9d7
    uid: ce0bf8b9-8157-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 6bf544f9d7
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 6bf544f9d7
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v19.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 10
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "32"
    creationTimestamp: "2020-04-23T18:13:13Z"
    generation: 2
    labels:
      pod-template-hash: 77ccf98f4f
      run: essbaseservice
    name: essbaseservice-77ccf98f4f
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "11801964"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-77ccf98f4f
    uid: 18bb86b9-858e-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 77ccf98f4f
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 77ccf98f4f
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v21
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "27"
    creationTimestamp: "2020-04-21T17:07:08Z"
    generation: 2
    labels:
      pod-template-hash: 788c844cbc
      run: essbaseservice
    name: essbaseservice-788c844cbc
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10448598"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-788c844cbc
    uid: 8886e82b-83f2-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 788c844cbc
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 788c844cbc
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "33"
    creationTimestamp: "2020-04-26T11:39:13Z"
    generation: 2
    labels:
      pod-template-hash: 7b4b7f74db
      run: essbaseservice
    name: essbaseservice-7b4b7f74db
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "12159442"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-7b4b7f74db
    uid: 8d782d80-87b2-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 7b4b7f74db
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 7b4b7f74db
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v22
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "25"
    creationTimestamp: "2020-04-21T16:14:42Z"
    generation: 2
    labels:
      pod-template-hash: 7d49c7c4f6
      run: essbaseservice
    name: essbaseservice-7d49c7c4f6
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10442107"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-7d49c7c4f6
    uid: 35623118-83eb-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 7d49c7c4f6
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 7d49c7c4f6
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v19.2
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "29"
    creationTimestamp: "2020-04-21T17:29:31Z"
    generation: 2
    labels:
      pod-template-hash: 8487fb9456
      run: essbaseservice
    name: essbaseservice-8487fb9456
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10463374"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-8487fb9456
    uid: a8e4444e-83f5-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: 8487fb9456
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: 8487fb9456
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20.2
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "26"
    creationTimestamp: "2020-04-21T16:51:18Z"
    generation: 2
    labels:
      pod-template-hash: c6bc79c7b
      run: essbaseservice
    name: essbaseservice-c6bc79c7b
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "10445201"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-c6bc79c7b
    uid: 526b885f-83f0-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        pod-template-hash: c6bc79c7b
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: c6bc79c7b
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v20
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "35"
    creationTimestamp: "2020-04-27T18:02:40Z"
    generation: 3
    labels:
      pod-template-hash: f5f56b5b
      run: essbaseservice
    name: essbaseservice-f5f56b5b
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: essbaseservice
      uid: 8dfc8260-6870-11ea-b004-42010a80008c
    resourceVersion: "13428051"
    selfLink: /apis/extensions/v1beta1/namespaces/default/replicasets/essbaseservice-f5f56b5b
    uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        pod-template-hash: f5f56b5b
        run: essbaseservice
    template:
      metadata:
        creationTimestamp: null
        labels:
          pod-template-hash: f5f56b5b
          run: essbaseservice
      spec:
        containers:
        - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
          imagePullPolicy: IfNotPresent
          name: essbaseservice
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 1
    labels:
      k8s-app: event-exporter
      pod-template-hash: 7df89f4b8f
      version: v0.2.5
    name: event-exporter-v0.2.5-7df89f4b8f
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: event-exporter-v0.2.5
      uid: 78c77da7-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399194"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/event-exporter-v0.2.5-7df89f4b8f
    uid: 78c873a9-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: event-exporter
        pod-template-hash: 7df89f4b8f
        version: v0.2.5
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: event-exporter
          pod-template-hash: 7df89f4b8f
          version: v0.2.5
      spec:
        containers:
        - command:
          - /event-exporter
          - -sink-opts=-stackdriver-resource-model=new
          image: k8s.gcr.io/event-exporter:v0.2.5
          imagePullPolicy: IfNotPresent
          name: event-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd-exporter
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: event-exporter-sa
        serviceAccountName: event-exporter-sa
        terminationGracePeriodSeconds: 30
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: ""
          name: ssl-certs
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:22Z"
    generation: 1
    labels:
      k8s-app: fluentd-gcp-scaler
      pod-template-hash: 54ccb89d5
    name: fluentd-gcp-scaler-54ccb89d5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: fluentd-gcp-scaler
      uid: 7b7c5076-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399095"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/fluentd-gcp-scaler-54ccb89d5
    uid: 7b7d4c47-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: fluentd-gcp-scaler
        pod-template-hash: 54ccb89d5
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: fluentd-gcp-scaler
          pod-template-hash: 54ccb89d5
      spec:
        containers:
        - command:
          - /scaler.sh
          - --ds-name=fluentd-gcp-v3.1.1
          - --scaling-policy=fluentd-gcp-scaling-policy
          env:
          - name: CPU_REQUEST
            value: 100m
          - name: MEMORY_REQUEST
            value: 200Mi
          - name: CPU_LIMIT
            value: "1"
          - name: MEMORY_LIMIT
            value: 500Mi
          image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
          imagePullPolicy: IfNotPresent
          name: fluentd-gcp-scaler
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: fluentd-gcp-scaler
        serviceAccountName: fluentd-gcp-scaler
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-03-15T10:05:58Z"
    generation: 2
    labels:
      k8s-app: heapster
      pod-template-hash: 667d4944f6
      version: v1.7.2
    name: heapster-gke-667d4944f6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938171"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-667d4944f6
    uid: 90ef5064-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 667d4944f6
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 667d4944f6
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92960Ki
            requests:
              cpu: 50m
              memory: 92960Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:16Z"
    generation: 2
    labels:
      k8s-app: heapster
      pod-template-hash: 789949956d
      version: v1.7.2
    name: heapster-gke-789949956d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "844"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-789949956d
    uid: 77f0cca9-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 789949956d
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 789949956d
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92960Ki
            requests:
              cpu: 50m
              memory: 92960Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2020-04-01T22:47:48Z"
    generation: 1
    labels:
      k8s-app: heapster
      pod-template-hash: 7df9bb754d
      version: v1.7.2
    name: heapster-gke-7df9bb754d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: heapster-gke
      uid: 77ee5493-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399251"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/heapster-gke-7df9bb754d
    uid: cf396f60-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: heapster
        pod-template-hash: 7df9bb754d
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: heapster
          pod-template-hash: 7df9bb754d
          version: v1.7.2
      spec:
        containers:
        - command:
          - /heapster
          - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
          - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
          image: gke.gcr.io/heapster:v1.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8082
              scheme: HTTP
            initialDelaySeconds: 180
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: heapster
          resources:
            limits:
              cpu: 13m
              memory: 120Mi
            requests:
              cpu: 13m
              memory: 120Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.5.0
          imagePullPolicy: IfNotPresent
          name: prom-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=10m
          - --extra-cpu=0.5m
          - --memory=100Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=heapster-gke
          - --container=heapster
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.3
          imagePullPolicy: IfNotPresent
          name: heapster-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: heapster-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: heapster
        serviceAccountName: heapster
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: heapster-config
          name: heapster-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 3
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5877696fb4
    name: kube-dns-5877696fb4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-dns
      uid: 76bed5da-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399307"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/kube-dns-5877696fb4
    uid: 76c1c78a-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 5877696fb4
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 5877696fb4
      spec:
        containers:
        - args:
          - --domain=cluster.local.
          - --dns-port=10053
          - --config-dir=/kube-dns-config
          - --v=2
          env:
          - name: PROMETHEUS_PORT
            value: "10055"
          image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/kubedns
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kubedns
          ports:
          - containerPort: 10053
            name: dns-local
            protocol: UDP
          - containerPort: 10053
            name: dns-tcp-local
            protocol: TCP
          - containerPort: 10055
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readiness
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /kube-dns-config
            name: kube-dns-config
        - args:
          - -v=2
          - -logtostderr
          - -configDir=/etc/k8s/dns/dnsmasq-nanny
          - -restartDnsmasq=true
          - --
          - -k
          - --cache-size=1000
          - --no-negcache
          - --log-facility=-
          - --server=/cluster.local/127.0.0.1#10053
          - --server=/in-addr.arpa/127.0.0.1#10053
          - --server=/ip6.arpa/127.0.0.1#10053
          image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthcheck/dnsmasq
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: dnsmasq
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          resources:
            requests:
              cpu: 150m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/k8s/dns/dnsmasq-nanny
            name: kube-dns-config
        - args:
          - --v=2
          - --logtostderr
          - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
          - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
          image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: 10054
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: sidecar
          ports:
          - containerPort: 10054
            name: metrics
            protocol: TCP
          resources:
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /monitor
          - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
          - --stackdriver-prefix=container.googleapis.com/internal/addons
          - --api-override=https://monitoring.googleapis.com/
          - --pod-id=$(POD_NAME)
          - --namespace-id=$(POD_NAMESPACE)
          - --v=2
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/prometheus-to-sd:v0.4.2
          imagePullPolicy: IfNotPresent
          name: prometheus-to-sd
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: Default
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-dns
        serviceAccountName: kube-dns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-dns
            optional: true
          name: kube-dns-config
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:15Z"
    generation: 1
    labels:
      k8s-app: kube-dns-autoscaler
      pod-template-hash: 8687c64fc
    name: kube-dns-autoscaler-8687c64fc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-dns-autoscaler
      uid: 7776165d-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399082"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/kube-dns-autoscaler-8687c64fc
    uid: 7777872f-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns-autoscaler
        pod-template-hash: 8687c64fc
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: kube-dns-autoscaler
          pod-template-hash: 8687c64fc
      spec:
        containers:
        - command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          - --target=Deployment/kube-dns
          - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
          - --logtostderr=true
          - --v=2
          image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
          imagePullPolicy: IfNotPresent
          name: autoscaler
          resources:
            requests:
              cpu: 20m
              memory: 10Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          supplementalGroups:
          - 65534
        serviceAccount: kube-dns-autoscaler
        serviceAccountName: kube-dns-autoscaler
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:14Z"
    generation: 1
    labels:
      k8s-app: glbc
      name: glbc
      pod-template-hash: 8f479dd9
    name: l7-default-backend-8f479dd9
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: l7-default-backend
      uid: 770295af-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399115"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/l7-default-backend-8f479dd9
    uid: 77042a48-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: glbc
        pod-template-hash: 8f479dd9
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: glbc
          name: glbc
          pod-template-hash: 8f479dd9
      spec:
        containers:
        - image: k8s.gcr.io/defaultbackend-amd64:1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: default-http-backend
          ports:
          - containerPort: 8080
            protocol: TCP
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-03-15T10:05:35Z"
    generation: 1
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5c6fbf777
      version: v0.3.1
    name: metrics-server-v0.3.1-5c6fbf777
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server-v0.3.1
      uid: 79cade0e-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399090"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/metrics-server-v0.3.1-5c6fbf777
    uid: 83c10be5-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 5c6fbf777
        version: v0.3.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 5c6fbf777
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources:
            limits:
              cpu: 43m
              memory: 55Mi
            requests:
              cpu: 43m
              memory: 55Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:19Z"
    generation: 2
    labels:
      k8s-app: metrics-server
      pod-template-hash: 8559697b9c
      version: v0.3.1
    name: metrics-server-v0.3.1-8559697b9c
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server-v0.3.1
      uid: 79cade0e-66a4-11ea-b80b-42010a800288
    resourceVersion: "742"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/metrics-server-v0.3.1-8559697b9c
    uid: 79d32dbf-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 8559697b9c
        version: v0.3.1
    template:
      metadata:
        annotations:
          scheduler.alpha.kubernetes.io/critical-pod: ""
          seccomp.security.alpha.kubernetes.io/pod: docker/default
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 8559697b9c
          version: v0.3.1
        name: metrics-server
      spec:
        containers:
        - command:
          - /metrics-server
          - --metric-resolution=30s
          - --kubelet-port=10255
          - --deprecated-kubelet-completely-insecure=true
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
          image: k8s.gcr.io/metrics-server-amd64:v0.3.1
          imagePullPolicy: IfNotPresent
          name: metrics-server
          ports:
          - containerPort: 443
            name: https
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=35Mi
          - --extra-memory=4Mi
          - --threshold=5
          - --deployment=metrics-server-v0.3.1
          - --container=metrics-server
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: gke.gcr.io/addon-resizer:1.8.4-gke.0
          imagePullPolicy: IfNotPresent
          name: metrics-server-nanny
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 5m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metrics-server-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: metrics-server-config
          name: metrics-server-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2020-04-01T22:47:47Z"
    generation: 2
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 5dd546c8d6
    name: stackdriver-metadata-agent-cluster-level-5dd546c8d6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938145"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-5dd546c8d6
    uid: cf0cdb85-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 5dd546c8d6
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 5dd546c8d6
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2020-03-15T10:05:17Z"
    generation: 2
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 79bd67c4b5
    name: stackdriver-metadata-agent-cluster-level-79bd67c4b5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "4938086"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-79bd67c4b5
    uid: 79015194-66a4-11ea-b80b-42010a800288
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 79bd67c4b5
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 79bd67c4b5
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            requests:
              cpu: 40m
              memory: 50Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: extensions/v1beta1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2020-04-01T22:47:53Z"
    generation: 1
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 865b464794
    name: stackdriver-metadata-agent-cluster-level-865b464794
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: stackdriver-metadata-agent-cluster-level
      uid: 78ff7118-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399232"
    selfLink: /apis/extensions/v1beta1/namespaces/kube-system/replicasets/stackdriver-metadata-agent-cluster-level-865b464794
    uid: d28677b2-746a-11ea-b920-42010a8002b4
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: stackdriver-metadata-agent
        cluster-level: "true"
        pod-template-hash: 865b464794
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: stackdriver-metadata-agent
          cluster-level: "true"
          pod-template-hash: 865b464794
      spec:
        containers:
        - args:
          - -logtostderr
          - -v=1
          env:
          - name: CLUSTER_NAME
            value: indra20k8
          - name: CLUSTER_LOCATION
            value: us-central1-c
          image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
          imagePullPolicy: IfNotPresent
          name: metadata-agent
          resources:
            limits:
              cpu: 43m
              memory: 25Mi
            requests:
              cpu: 43m
              memory: 25Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs
        - command:
          - /pod_nanny
          - --config-dir=/etc/config
          - --cpu=40m
          - --extra-cpu=0.5m
          - --memory=20Mi
          - --extra-memory=1Mi
          - --threshold=5
          - --deployment=stackdriver-metadata-agent-cluster-level
          - --container=metadata-agent
          - --poll-period=300000
          - --estimator=exponential
          - --minClusterSize=5
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: k8s.gcr.io/addon-resizer:1.8.7
          imagePullPolicy: IfNotPresent
          name: metadata-agent-nanny
          resources:
            limits:
              cpu: 50m
              memory: 92560Ki
            requests:
              cpu: 50m
              memory: 92560Ki
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: metadata-agent-config-volume
        dnsPolicy: ClusterFirst
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metadata-agent
        serviceAccountName: metadata-agent
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - hostPath:
            path: /etc/ssl/certs
            type: Directory
          name: ssl-certs
        - configMap:
            defaultMode: 420
            name: metadata-agent-config
          name: metadata-agent-config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== nodes manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Node
  metadata:
    annotations:
      container.googleapis.com/instance_id: "5140598096185740963"
      node.alpha.kubernetes.io/ttl: "0"
      volumes.kubernetes.io/controller-managed-attach-detach: "true"
    creationTimestamp: "2020-03-17T16:27:54Z"
    labels:
      beta.kubernetes.io/arch: amd64
      beta.kubernetes.io/fluentd-ds-ready: "true"
      beta.kubernetes.io/instance-type: n1-standard-1
      beta.kubernetes.io/os: linux
      cloud.google.com/gke-nodepool: default-pool
      cloud.google.com/gke-os-distribution: cos
      failure-domain.beta.kubernetes.io/region: us-central1
      failure-domain.beta.kubernetes.io/zone: us-central1-c
      kubernetes.io/arch: amd64
      kubernetes.io/hostname: gke-indra20k8-default-pool-b615b32b-kb0v
      kubernetes.io/os: linux
    name: gke-indra20k8-default-pool-b615b32b-kb0v
    resourceVersion: "13429981"
    selfLink: /api/v1/nodes/gke-indra20k8-default-pool-b615b32b-kb0v
    uid: 4108a29a-686c-11ea-b004-42010a80008c
  spec:
    podCIDR: 10.4.0.0/24
    providerID: gce://indrasolproj-2020/us-central1-c/gke-indra20k8-default-pool-b615b32b-kb0v
  status:
    addresses:
    - address: 10.128.0.6
      type: InternalIP
    - address: 104.197.156.53
      type: ExternalIP
    - address: gke-indra20k8-default-pool-b615b32b-kb0v.us-central1-c.c.indrasolproj-2020.internal
      type: InternalDNS
    - address: gke-indra20k8-default-pool-b615b32b-kb0v.us-central1-c.c.indrasolproj-2020.internal
      type: Hostname
    allocatable:
      attachable-volumes-gce-pd: "127"
      cpu: 940m
      ephemeral-storage: "47093746742"
      hugepages-2Mi: "0"
      memory: 2701244Ki
      pods: "110"
    capacity:
      attachable-volumes-gce-pd: "127"
      cpu: "1"
      ephemeral-storage: 98868448Ki
      hugepages-2Mi: "0"
      memory: 3786684Ki
      pods: "110"
    conditions:
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: docker overlay2 is functioning properly
      reason: NoCorruptDockerOverlay2
      status: "False"
      type: CorruptDockerOverlay2
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: node is functioning properly
      reason: NoFrequentUnregisterNetDevice
      status: "False"
      type: FrequentUnregisterNetDevice
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet is functioning properly
      reason: NoFrequentKubeletRestart
      status: "False"
      type: FrequentKubeletRestart
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: docker is functioning properly
      reason: NoFrequentDockerRestart
      status: "False"
      type: FrequentDockerRestart
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: containerd is functioning properly
      reason: NoFrequentContainerdRestart
      status: "False"
      type: FrequentContainerdRestart
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kernel has no deadlock
      reason: KernelHasNoDeadlock
      status: "False"
      type: KernelDeadlock
    - lastHeartbeatTime: "2020-05-02T07:08:05Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: Filesystem is not read-only
      reason: FilesystemIsNotReadOnly
      status: "False"
      type: ReadonlyFilesystem
    - lastHeartbeatTime: "2020-04-01T22:47:08Z"
      lastTransitionTime: "2020-04-01T22:47:08Z"
      message: NodeController create implicit route
      reason: RouteCreated
      status: "False"
      type: NetworkUnavailable
    - lastHeartbeatTime: "2020-05-02T07:08:27Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has sufficient memory available
      reason: KubeletHasSufficientMemory
      status: "False"
      type: MemoryPressure
    - lastHeartbeatTime: "2020-05-02T07:08:27Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has no disk pressure
      reason: KubeletHasNoDiskPressure
      status: "False"
      type: DiskPressure
    - lastHeartbeatTime: "2020-05-02T07:08:27Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet has sufficient PID available
      reason: KubeletHasSufficientPID
      status: "False"
      type: PIDPressure
    - lastHeartbeatTime: "2020-05-02T07:08:27Z"
      lastTransitionTime: "2020-04-21T13:09:36Z"
      message: kubelet is posting ready status. AppArmor enabled
      reason: KubeletReady
      status: "True"
      type: Ready
    daemonEndpoints:
      kubeletEndpoint:
        Port: 10250
    images:
    - names:
      - gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:79ddc530f0e558da80c3857c2e02d8b6dcce64c4c875fb94e3a420f53c502492
      - gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      sizeBytes: 413364992
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:7a485bd251330431a6591f9c190979743f058340c37e4234e771b6c9df7ec093
      - gcr.io/indrasolproj-2020/essbaseservice:v20.3
      sizeBytes: 152863693
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:1fd7293607be9d2c7b59c38b242244064a1ba9f260600bc8d6126a5eeaa78ab8
      - gcr.io/indrasolproj-2020/essbaseservice:v20.2
      sizeBytes: 152862650
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:0d3db443f4d9ae0fd6cd45bd3b91c867800dcce4f3852d66b591d31c3e91e16e
      - gcr.io/indrasolproj-2020/essbaseservice:v20.1
      sizeBytes: 152862641
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:38f3fbe38ea655a58a39c393170d0ac78fd313b4860456f48db54cfe93d87370
      - gcr.io/indrasolproj-2020/essbaseservice:v19.1
      - gcr.io/indrasolproj-2020/essbaseservice:v19.2
      sizeBytes: 152862592
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:0b4ed73d67ddb35368caa6c45bf71b584f1b79c33341e9ec363539b6a638c15b
      - gcr.io/indrasolproj-2020/essbaseservice:v20
      sizeBytes: 152862592
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:b7380aff14593768b01365b2f270ce7b92468f34dac527fb1a5777cd436c0a4b
      - gcr.io/indrasolproj-2020/essbaseservice:v18
      sizeBytes: 152858888
    - names:
      - k8s.gcr.io/fluentd-elasticsearch@sha256:5a704c386f66bb3c24e3bcf2e94269c426f1473100fcd37b31579ca8b709c558
      - k8s.gcr.io/fluentd-elasticsearch:v2.4.0
      sizeBytes: 139904122
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:c45933c5fe3f153ede7170af94e7cf97a4547e7c0dadce1828736a84a0625b6d
      - gcr.io/indrasolproj-2020/essbaseservice:v23.1
      sizeBytes: 130194273
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:837f26308b8bf131be958c475273fe251ff8f1317b4b9566c3a03ced323fa98f
      - gcr.io/indrasolproj-2020/essbaseservice:v23
      sizeBytes: 130193454
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:9bd5d07f24d170219e008f0769ec695d45d4b0fac6831356585a2389584bae2d
      - gcr.io/indrasolproj-2020/essbaseservice:v22
      sizeBytes: 130191475
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:b1ff9783ed029adc857741360c2b4806b009e22c4d551cee75df622090cc4d37
      - gcr.io/indrasolproj-2020/essbaseservice:v20.4
      sizeBytes: 130186930
    - names:
      - gcr.io/indrasolproj-2020/essbaseservice@sha256:80ff5f72f920551e2addd361ffb3508e12eaa7ce4402f9a4646498068e60d6b2
      - gcr.io/indrasolproj-2020/essbaseservice:v21
      sizeBytes: 130186431
    - names:
      - k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747
      - k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
      sizeBytes: 121711221
    - names:
      - k8s.gcr.io/node-problem-detector@sha256:9d54df11804a862c54276648702a45a6a0027a9d930a86becd69c34cc84bf510
      - k8s.gcr.io/node-problem-detector:v0.6.3
      sizeBytes: 93550819
    - names:
      - k8s.gcr.io/fluentd-gcp-scaler@sha256:4f28f10fb89506768910b858f7a18ffb996824a16d70d5ac895e49687df9ff58
      - k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      sizeBytes: 90498960
    - names:
      - k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:a13c60e2a9d49f965095a1e003388926f3f2a6189ed4aecb1541f114c955f8ec
      - k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      sizeBytes: 86980681
    - names:
      - gke.gcr.io/heapster@sha256:26891d2f8c22407a772b911aed912993e1c530128ebb2d3561b49fc16a52d765
      - gke.gcr.io/heapster:v1.7.2
      sizeBytes: 84338494
    - names:
      - gke.gcr.io/kube-proxy:v1.14.10-gke.27
      - k8s.gcr.io/kube-proxy:v1.14.10-gke.27
      sizeBytes: 83627412
    - names:
      - k8s.gcr.io/kube-addon-manager@sha256:382c220b3531d9f95bf316a16b7282cc2ef929cd8a89a9dd3f5933edafc41a8e
      - k8s.gcr.io/kube-addon-manager:v9.0.1
      sizeBytes: 83076194
    - names:
      - gcr.io/stackdriver-agents/metadata-agent-go@sha256:ca13ec92f6e41befff6ca2a578ee7951edb1e49a566430f816f9a8acf631a62a
      - gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      sizeBytes: 82131866
    - names:
      - k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:e55cbd5361a86bf0a01bfeaca2e958e15571f1e741356eab83bb444a13020d4c
      - k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      sizeBytes: 79319492
    - names:
      - k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:0a70a8a9ae8cfe752021de84f13b3ecd109d9b5fbe3f1541c52fcd1d4c2c0b45
      - k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      sizeBytes: 77756591
    - names:
      - k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521
      - k8s.gcr.io/heapster-amd64:v1.6.0-beta.1
      sizeBytes: 76016169
    - names:
      - k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca
      - k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3
      sizeBytes: 71797285
    nodeInfo:
      architecture: amd64
      bootID: 6e01c85a-6604-41fa-8ab3-7d2654aa7225
      containerRuntimeVersion: docker://18.9.7
      kernelVersion: 4.14.138+
      kubeProxyVersion: v1.14.10-gke.27
      kubeletVersion: v1.14.10-gke.27
      machineID: f2e2dfda9375c4200e66b163e9949ca9
      operatingSystem: linux
      osImage: Container-Optimized OS from Google
      systemUUID: F2E2DFDA-9375-C420-0E66-B163E9949CA9
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== pods manifests ========

apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/limit-ranger: 'LimitRanger plugin set: cpu request for container
        essbaseservice'
    creationTimestamp: "2020-05-02T06:58:29Z"
    generateName: essbaseservice-f5f56b5b-
    labels:
      pod-template-hash: f5f56b5b
      run: essbaseservice
    name: essbaseservice-f5f56b5b-fbzlt
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: essbaseservice-f5f56b5b
      uid: 48e1d7ad-88b1-11ea-b920-42010a8002b4
    resourceVersion: "13428050"
    selfLink: /api/v1/namespaces/default/pods/essbaseservice-f5f56b5b-fbzlt
    uid: 542f6629-8c42-11ea-b920-42010a8002b4
  spec:
    containers:
    - image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
      imagePullPolicy: IfNotPresent
      name: essbaseservice
      ports:
      - containerPort: 8080
        protocol: TCP
      resources:
        requests:
          cpu: 100m
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-l6wj4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-l6wj4
      secret:
        defaultMode: 420
        secretName: default-token-l6wj4
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-05-02T06:58:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://558d928eb17333048815dc9ebfde2ff27bb6c4f8755374a78cb0f9d4baa2af39
      image: gcr.io/indrasolproj-2020/essbaseservice:v23.1
      imageID: docker-pullable://gcr.io/indrasolproj-2020/essbaseservice@sha256:c45933c5fe3f153ede7170af94e7cf97a4547e7c0dadce1828736a84a0625b6d
      lastState: {}
      name: essbaseservice
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-05-02T06:58:30Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.31
    qosClass: Burstable
    startTime: "2020-05-02T06:58:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: event-exporter-v0.2.5-7df89f4b8f-
    labels:
      k8s-app: event-exporter
      pod-template-hash: 7df89f4b8f
      version: v0.2.5
    name: event-exporter-v0.2.5-7df89f4b8f-vgtt4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: event-exporter-v0.2.5-7df89f4b8f
      uid: 78c873a9-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399193"
    selfLink: /api/v1/namespaces/kube-system/pods/event-exporter-v0.2.5-7df89f4b8f-vgtt4
    uid: eaf8601d-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /event-exporter
      - -sink-opts=-stackdriver-resource-model=new
      image: k8s.gcr.io/event-exporter:v0.2.5
      imagePullPolicy: IfNotPresent
      name: event-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-x58h2
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: event-exporter-sa-token-x58h2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: event-exporter-sa
    serviceAccountName: event-exporter-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: ssl-certs
    - name: event-exporter-sa-token-x58h2
      secret:
        defaultMode: 420
        secretName: event-exporter-sa-token-x58h2
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://bd39da0fc6ce9c762d1d815411a1d7b59fd371028a04b7d4f0582c3a565d6d82
      image: k8s.gcr.io/event-exporter:v0.2.5
      imageID: docker-pullable://k8s.gcr.io/event-exporter@sha256:06acf489ab092b4fb49273e426549a52c0fcd1dbcb67e03d5935b5ee1a899c3e
      lastState: {}
      name: event-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:14Z"
    - containerID: docker://605ef115da9546ea390bd5afaf03021e4c71ff3aba2ad1a43daf2993098be146
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:15Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.7
    qosClass: BestEffort
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: fluentd-gcp-scaler-54ccb89d5-
    labels:
      k8s-app: fluentd-gcp-scaler
      pod-template-hash: 54ccb89d5
    name: fluentd-gcp-scaler-54ccb89d5-9jv5d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: fluentd-gcp-scaler-54ccb89d5
      uid: 7b7d4c47-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399094"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-54ccb89d5-9jv5d
    uid: eafc3194-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /scaler.sh
      - --ds-name=fluentd-gcp-v3.1.1
      - --scaling-policy=fluentd-gcp-scaling-policy
      env:
      - name: CPU_REQUEST
        value: 100m
      - name: MEMORY_REQUEST
        value: 200Mi
      - name: CPU_LIMIT
        value: "1"
      - name: MEMORY_LIMIT
        value: 500Mi
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      imagePullPolicy: IfNotPresent
      name: fluentd-gcp-scaler
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-scaler-token-8gdvq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp-scaler
    serviceAccountName: fluentd-gcp-scaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: fluentd-gcp-scaler-token-8gdvq
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-scaler-token-8gdvq
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d10b531483cfd82bcc393cb0f7e88a28a2c5a5756dfbae91427cb7b1594506d7
      image: k8s.gcr.io/fluentd-gcp-scaler:0.5.2
      imageID: docker-pullable://k8s.gcr.io/fluentd-gcp-scaler@sha256:4f28f10fb89506768910b858f7a18ffb996824a16d70d5ac895e49687df9ff58
      lastState: {}
      name: fluentd-gcp-scaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:47Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.9
    qosClass: BestEffort
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      EnableKnativeConfig: "false"
      EnableNodeJournal: "false"
      EnablePodSecurityPolicy: "false"
      PodLogEnabled: "false"
      SystemOnlyLogging: "false"
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-04-01T22:47:56Z"
    generateName: fluentd-gcp-v3.1.1-
    labels:
      controller-revision-hash: 57d5cdd48
      k8s-app: fluentd-gcp
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "3"
      version: v3.1.1
    name: fluentd-gcp-v3.1.1-7wtmz
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluentd-gcp-v3.1.1
      uid: 779ca16d-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399163"
    selfLink: /api/v1/namespaces/kube-system/pods/fluentd-gcp-v3.1.1-7wtmz
    uid: d476410f-746a-11ea-b920-42010a8002b4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-indra20k8-default-pool-b615b32b-kb0v
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: STACKDRIVER_METADATA_AGENT_URL
        value: http://$(NODE_NAME):8799
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - |2

            LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/run/google-fluentd/buffers ]; then
              exit 1;
            fi; touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-stuck -print -quit)" ]; then
              rm -rf /var/run/google-fluentd/buffers;
              exit 1;
            fi; touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness; if [ -z "$(find /var/run/google-fluentd/buffers -type d -newer /tmp/marker-liveness -print -quit)" ]; then
              exit 1;
            fi;
        failureThreshold: 3
        initialDelaySeconds: 600
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: fluentd-gcp
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 200Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/google-fluentd
        name: varrun
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/docker/containers
        name: varlibdockercontainers
        readOnly: true
      - mountPath: /etc/google-fluentd/config.d
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-85hzc
        readOnly: true
    - command:
      - /monitor
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-exporter
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: fluentd-gcp-token-85hzc
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    nodeSelector:
      beta.kubernetes.io/fluentd-ds-ready: "true"
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluentd-gcp
    serviceAccountName: fluentd-gcp
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run/google-fluentd
        type: ""
      name: varrun
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: varlibdockercontainers
    - configMap:
        defaultMode: 420
        name: fluentd-gcp-config-v1.2.6
      name: config-volume
    - name: fluentd-gcp-token-85hzc
      secret:
        defaultMode: 420
        secretName: fluentd-gcp-token-85hzc
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-01T22:47:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-01T22:47:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://9cbb789a838ed5a8c954c9a1710799d8cb45f2d065f979da2bc8f81dedda6e24
      image: gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.17-16060
      imageID: docker-pullable://gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:79ddc530f0e558da80c3857c2e02d8b6dcce64c4c875fb94e3a420f53c502492
      lastState: {}
      name: fluentd-gcp
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:04Z"
    - containerID: docker://95e4822e75901337bfd296657da7446d106a92441f870701ba0f0a9b7b1c074b
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prometheus-to-sd-exporter
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:05Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-04-01T22:47:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:30Z"
    generateName: heapster-gke-7df9bb754d-
    labels:
      k8s-app: heapster
      pod-template-hash: 7df9bb754d
      version: v1.7.2
    name: heapster-gke-7df9bb754d-bvbv6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: heapster-gke-7df9bb754d
      uid: cf396f60-746a-11ea-b920-42010a8002b4
    resourceVersion: "10399249"
    selfLink: /api/v1/namespaces/kube-system/pods/heapster-gke-7df9bb754d-bvbv6
    uid: eb1368d9-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /heapster
      - --source=kubernetes.summary_api:?host_id_annotation=container.googleapis.com/instance_id
      - --sink=stackdriver:?cluster_name=indra20k8&use_old_resources=false&use_new_resources=true&min_interval_sec=100&batch_export_timeout_sec=110&cluster_location=us-central1-c
      image: gke.gcr.io/heapster:v1.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8082
          scheme: HTTP
        initialDelaySeconds: 180
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: heapster
      resources:
        limits:
          cpu: 13m
          memory: 120Mi
        requests:
          cpu: 13m
          memory: 120Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    - command:
      - /monitor
      - --source=heapster:http://localhost:8082?whitelisted=stackdriver_requests_count,stackdriver_timeseries_count
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imagePullPolicy: IfNotPresent
      name: prom-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=10m
      - --extra-cpu=0.5m
      - --memory=100Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=heapster-gke
      - --container=heapster
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.3
      imagePullPolicy: IfNotPresent
      name: heapster-nanny
      resources:
        limits:
          cpu: 50m
          memory: 92560Ki
        requests:
          cpu: 50m
          memory: 92560Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: heapster-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: heapster-token-x8jx5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      supplementalGroups:
      - 65534
    serviceAccount: heapster
    serviceAccountName: heapster
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: heapster-config
      name: heapster-config-volume
    - name: heapster-token-x8jx5
      secret:
        defaultMode: 420
        secretName: heapster-token-x8jx5
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://92050393ea4f667283a83e12320ae4a7999765d5d66d6ec275673de73fc1f888
      image: gke.gcr.io/heapster:v1.7.2
      imageID: docker-pullable://gke.gcr.io/heapster@sha256:26891d2f8c22407a772b911aed912993e1c530128ebb2d3561b49fc16a52d765
      lastState: {}
      name: heapster
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:10Z"
    - containerID: docker://7f9d5bdb7565ca69ab2e44314c2b79385454f8cc3b343b95f076b456b99a245a
      image: k8s.gcr.io/addon-resizer:1.8.3
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:07353f7b26327f0d933515a22b1de587b040d3d85c464ea299c1b9f242529326
      lastState: {}
      name: heapster-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:29Z"
    - containerID: docker://c9dd8d9300e193b31fc91ac59f830e082e13fe7d40bd9037970356f17cf644b7
      image: k8s.gcr.io/prometheus-to-sd:v0.5.0
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e
      lastState: {}
      name: prom-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:12Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.4
    qosClass: Burstable
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: kube-dns-5877696fb4-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5877696fb4
    name: kube-dns-5877696fb4-mjdth
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-5877696fb4
      uid: 76c1c78a-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399306"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-5877696fb4-mjdth
    uid: eb4adcd6-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - args:
      - --domain=cluster.local.
      - --dns-port=10053
      - --config-dir=/kube-dns-config
      - --v=2
      env:
      - name: PROMETHEUS_PORT
        value: "10055"
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/kubedns
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kubedns
      ports:
      - containerPort: 10053
        name: dns-local
        protocol: UDP
      - containerPort: 10053
        name: dns-tcp-local
        protocol: TCP
      - containerPort: 10055
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /kube-dns-config
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - args:
      - -v=2
      - -logtostderr
      - -configDir=/etc/k8s/dns/dnsmasq-nanny
      - -restartDnsmasq=true
      - --
      - -k
      - --cache-size=1000
      - --no-negcache
      - --log-facility=-
      - --server=/cluster.local/127.0.0.1#10053
      - --server=/in-addr.arpa/127.0.0.1#10053
      - --server=/ip6.arpa/127.0.0.1#10053
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthcheck/dnsmasq
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dnsmasq
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      resources:
        requests:
          cpu: 150m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/k8s/dns/dnsmasq-nanny
        name: kube-dns-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - args:
      - --v=2
      - --logtostderr
      - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
      - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /metrics
          port: 10054
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: sidecar
      ports:
      - containerPort: 10054
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    - command:
      - /monitor
      - --source=kubedns:http://localhost:10054?whitelisted=probe_kubedns_latency_ms,probe_kubedns_errors,dnsmasq_misses,dnsmasq_hits
      - --stackdriver-prefix=container.googleapis.com/internal/addons
      - --api-override=https://monitoring.googleapis.com/
      - --pod-id=$(POD_NAME)
      - --namespace-id=$(POD_NAMESPACE)
      - --v=2
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-token-2j6rq
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-dns
    serviceAccountName: kube-dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-dns
        optional: true
      name: kube-dns-config
    - name: kube-dns-token-2j6rq
      secret:
        defaultMode: 420
        secretName: kube-dns-token-2j6rq
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://3b1616a4ae31d4aa25f5d6a7204e1f11b6b5a89a11cfc13d94c60d1b282fa690
      image: k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:0a70a8a9ae8cfe752021de84f13b3ecd109d9b5fbe3f1541c52fcd1d4c2c0b45
      lastState: {}
      name: dnsmasq
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:26Z"
    - containerID: docker://97675a961edbfed4bee6ff276a0e0516905880ee525fe73dbd8b650a61442f7e
      image: k8s.gcr.io/k8s-dns-kube-dns-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:a13c60e2a9d49f965095a1e003388926f3f2a6189ed4aecb1541f114c955f8ec
      lastState: {}
      name: kubedns
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:12Z"
    - containerID: docker://328b783ecd54e34b14bc93c745face1c3bff94cebeba9cdb578815034bc24485
      image: k8s.gcr.io/prometheus-to-sd:v0.4.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:aca8ef83a7fae83f1f8583e978dd4d1ff655b9f2ca0a76bda5edce6d8965bdf2
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:34Z"
    - containerID: docker://ec50a57b02f86fa43abffa1c2fadfc989288f5ee6bbfd43d66c8909a79205e70
      image: k8s.gcr.io/k8s-dns-sidecar-amd64:1.15.4
      imageID: docker-pullable://k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:e55cbd5361a86bf0a01bfeaca2e958e15571f1e741356eab83bb444a13020d4c
      lastState: {}
      name: sidecar
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:31Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.6
    qosClass: Burstable
    startTime: "2020-04-21T13:09:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: kube-dns-autoscaler-8687c64fc-
    labels:
      k8s-app: kube-dns-autoscaler
      pod-template-hash: 8687c64fc
    name: kube-dns-autoscaler-8687c64fc-rbqnd
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-dns-autoscaler-8687c64fc
      uid: 7777872f-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399081"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-8687c64fc-rbqnd
    uid: eb59002c-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /cluster-proportional-autoscaler
      - --namespace=kube-system
      - --configmap=kube-dns-autoscaler
      - --target=Deployment/kube-dns
      - --default-params={"linear":{"coresPerReplica":256,"nodesPerReplica":16,"preventSinglePointFailure":true}}
      - --logtostderr=true
      - --v=2
      image: gke.gcr.io/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
      imagePullPolicy: IfNotPresent
      name: autoscaler
      resources:
        requests:
          cpu: 20m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-dns-autoscaler-token-mfpqp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      supplementalGroups:
      - 65534
    serviceAccount: kube-dns-autoscaler
    serviceAccountName: kube-dns-autoscaler
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-dns-autoscaler-token-mfpqp
      secret:
        defaultMode: 420
        secretName: kube-dns-autoscaler-token-mfpqp
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:47Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:47Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6aec47b65d9388c5b7819c8246f19251b7d64a78b4d5ff73cfbf206d95b38acb
      image: asia.gcr.io/gke-release-staging/cluster-proportional-autoscaler-amd64:1.7.1-gke.0
      imageID: docker-pullable://asia.gcr.io/gke-release-staging/cluster-proportional-autoscaler-amd64@sha256:e3f48b3d1e49cfa3e7f002020769c9cd01cd0e77bbc99dc133c7ab0f8097e989
      lastState: {}
      name: autoscaler
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:45Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.5
    qosClass: Burstable
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: d216a501cc256e4968139420d5d29855
      kubernetes.io/config.mirror: d216a501cc256e4968139420d5d29855
      kubernetes.io/config.seen: "2020-04-21T13:09:35.838830462Z"
      kubernetes.io/config.source: file
      scheduler.alpha.kubernetes.io/critical-pod: ""
    creationTimestamp: "2020-04-21T13:09:41Z"
    labels:
      component: kube-proxy
      tier: node
    name: kube-proxy-gke-indra20k8-default-pool-b615b32b-kb0v
    namespace: kube-system
    resourceVersion: "10399072"
    selfLink: /api/v1/namespaces/kube-system/pods/kube-proxy-gke-indra20k8-default-pool-b615b32b-kb0v
    uid: 5cace7ba-83d1-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /bin/sh
      - -c
      - exec kube-proxy --master=https://104.197.210.17 --kubeconfig=/var/lib/kube-proxy/kubeconfig
        --cluster-cidr=10.4.0.0/14 --resource-container="" --oom-score-adj=-998 --v=2
        --feature-gates=DynamicKubeletConfig=false,TaintBasedEvictions=false,RotateKubeletServerCertificate=true,ExperimentalCriticalPodAnnotation=true
        --iptables-sync-period=1m --iptables-min-sync-period=10s --ipvs-sync-period=1m
        --ipvs-min-sync-period=10s 1>>/var/log/kube-proxy.log 2>&1
      image: gke.gcr.io/kube-proxy:v1.14.10-gke.27
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          cpu: 100m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: etc-ssl-certs
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-ca-certs
        readOnly: true
      - mountPath: /var/log
        name: varlog
      - mountPath: /var/lib/kube-proxy/kubeconfig
        name: kubeconfig
      - mountPath: /run/xtables.lock
        name: iptableslock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/share/ca-certificates
        type: ""
      name: usr-ca-certs
    - hostPath:
        path: /etc/ssl/certs
        type: ""
      name: etc-ssl-certs
    - hostPath:
        path: /var/lib/kube-proxy/kubeconfig
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /var/log
        type: ""
      name: varlog
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: iptableslock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://aa929b8303f213bc26384a2ac46911af7be66dd6aa899b0ec3134d779d591a47
      image: gke.gcr.io/kube-proxy:v1.14.10-gke.27
      imageID: docker://sha256:4c5288b3ecb59693e446354cd4ef1ed45cce9885ce3f6fdba66736aff391698a
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:38Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-03-17T16:27:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: l7-default-backend-8f479dd9-
    labels:
      k8s-app: glbc
      name: glbc
      pod-template-hash: 8f479dd9
    name: l7-default-backend-8f479dd9-gkfqd
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: l7-default-backend-8f479dd9
      uid: 77042a48-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399113"
    selfLink: /api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-gkfqd
    uid: eb573b82-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - image: k8s.gcr.io/defaultbackend-amd64:1.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: default-http-backend
      ports:
      - containerPort: 8080
        protocol: TCP
      resources:
        limits:
          cpu: 10m
          memory: 20Mi
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: default-token-22rgh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: default-token-22rgh
      secret:
        defaultMode: 420
        secretName: default-token-22rgh
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://39ff419cc3d8f57127d33f6b73d5580b91a6f72be2df935f1f7bb718e18bb6f7
      image: k8s.gcr.io/defaultbackend-amd64:1.5
      imageID: docker-pullable://k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7
      lastState: {}
      name: default-http-backend
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:52Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.10
    qosClass: Guaranteed
    startTime: "2020-04-21T13:09:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      scheduler.alpha.kubernetes.io/critical-pod: ""
      seccomp.security.alpha.kubernetes.io/pod: docker/default
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: metrics-server-v0.3.1-5c6fbf777-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 5c6fbf777
      version: v0.3.1
    name: metrics-server-v0.3.1-5c6fbf777-hqvcs
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-v0.3.1-5c6fbf777
      uid: 83c10be5-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399089"
    selfLink: /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-5c6fbf777-hqvcs
    uid: eb7cf390-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - command:
      - /metrics-server
      - --metric-resolution=30s
      - --kubelet-port=10255
      - --deprecated-kubelet-completely-insecure=true
      - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imagePullPolicy: IfNotPresent
      name: metrics-server
      ports:
      - containerPort: 443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 43m
          memory: 55Mi
        requests:
          cpu: 43m
          memory: 55Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-x6d9m
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=40m
      - --extra-cpu=0.5m
      - --memory=35Mi
      - --extra-memory=4Mi
      - --threshold=5
      - --deployment=metrics-server-v0.3.1
      - --container=metrics-server
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: gke.gcr.io/addon-resizer:1.8.4-gke.0
      imagePullPolicy: IfNotPresent
      name: metrics-server-nanny
      resources:
        limits:
          cpu: 100m
          memory: 300Mi
        requests:
          cpu: 5m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: metrics-server-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metrics-server-token-x6d9m
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: metrics-server-config
      name: metrics-server-config-volume
    - name: metrics-server-token-x6d9m
      secret:
        defaultMode: 420
        secretName: metrics-server-token-x6d9m
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ec5dac4ebdf4b2003216a73807e8521c38d0d326dd344a06d0931e6b4cc34925
      image: k8s.gcr.io/metrics-server-amd64:v0.3.1
      imageID: docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:43Z"
    - containerID: docker://86b90f7f689f4851bcccdd8794f29ec8e65aada562a501fe069bd88b3af091d7
      image: asia.gcr.io/gke-release-staging/addon-resizer:1.8.4-gke.0
      imageID: docker-pullable://asia.gcr.io/gke-release-staging/addon-resizer@sha256:94e7e68175dfd18a9e3c31bc1f4a6ab19444efef47192f13b0e5af3b03dc04c6
      lastState: {}
      name: metrics-server-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:46Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.3
    qosClass: Burstable
    startTime: "2020-04-21T13:09:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-03-17T16:27:54Z"
    generateName: prometheus-to-sd-
    labels:
      controller-revision-hash: 6cbdc4dbd7
      k8s-app: prometheus-to-sd
      pod-template-generation: "1"
    name: prometheus-to-sd-t84vf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-to-sd
      uid: 792a47e1-66a4-11ea-b80b-42010a800288
    resourceVersion: "10399097"
    selfLink: /api/v1/namespaces/kube-system/pods/prometheus-to-sd-t84vf
    uid: 41174538-686c-11ea-b004-42010a80008c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - gke-indra20k8-default-pool-b615b32b-kb0v
    containers:
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=container.googleapis.com/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
      - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
      - --stackdriver-prefix=container.googleapis.com/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      - --export-interval=120s
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-h7rkk
        readOnly: true
    - command:
      - /monitor
      - --source=kube-proxy:http://localhost:10249?whitelisted=sync_proxy_rules_latency_microseconds&metricsPrefix=kubernetes.io/internal/addons
      - --source=kubelet:http://localhost:10255?whitelisted=docker_operations,docker_operations_errors,runtime_operations,runtime_operations_errors,runtime_operations_latency_microseconds,pleg_relist_latency_microseconds,pod_start_latency_microseconds,rest_client_requests_total,storage_operation_duration_seconds,storage_operation_errors_total,run_podsandbox_duration_seconds,run_podsandbox_errors_total,storage_operation_status_count
      - --source=kubelet:http://localhost:10255/metrics/probes?whitelisted=prober_probe_total&podIdLabel=pod&namespaceIdLabel=namespace&containerNameLabel=container
      - --stackdriver-prefix=kubernetes.io/internal/nodes
      - --api-override=https://monitoring.googleapis.com/
      - --monitored-resource-type-prefix=k8s_
      - --monitored-resource-labels=location=us-central1-c
      - --export-interval=120s
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imagePullPolicy: IfNotPresent
      name: prometheus-to-sd-new-model
      resources:
        limits:
          cpu: 3m
          memory: 20Mi
        requests:
          cpu: 1m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: prometheus-to-sd-token-h7rkk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    nodeSelector:
      beta.kubernetes.io/os: linux
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus-to-sd
    serviceAccountName: prometheus-to-sd
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: prometheus-to-sd-token-h7rkk
      secret:
        defaultMode: 420
        secretName: prometheus-to-sd-token-h7rkk
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-03-17T16:27:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://283f595d13e726142ccced8948db5d4af92770a54a46ae8974719c53a08819af
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:3216dd0e94d6911f6dc04f4258c0bf5cb1fff088ee2d3ce742ada490cbd5ca5c
      lastState: {}
      name: prometheus-to-sd
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:44Z"
    - containerID: docker://d5aa585d6659ab602854e0122db19128eff1c55994cccee595322e59f7d7e26d
      image: k8s.gcr.io/prometheus-to-sd:v0.8.2
      imageID: docker-pullable://k8s.gcr.io/prometheus-to-sd@sha256:3216dd0e94d6911f6dc04f4258c0bf5cb1fff088ee2d3ce742ada490cbd5ca5c
      lastState: {}
      name: prometheus-to-sd-new-model
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:09:45Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.128.0.6
    qosClass: Burstable
    startTime: "2020-03-17T16:27:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2020-04-21T13:06:31Z"
    generateName: stackdriver-metadata-agent-cluster-level-865b464794-
    labels:
      app: stackdriver-metadata-agent
      cluster-level: "true"
      pod-template-hash: 865b464794
    name: stackdriver-metadata-agent-cluster-level-865b464794-n898v
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: stackdriver-metadata-agent-cluster-level-865b464794
      uid: d28677b2-746a-11ea-b920-42010a8002b4
    resourceVersion: "10399231"
    selfLink: /api/v1/namespaces/kube-system/pods/stackdriver-metadata-agent-cluster-level-865b464794-n898v
    uid: eb86efd1-83d0-11ea-b920-42010a8002b4
  spec:
    containers:
    - args:
      - -logtostderr
      - -v=1
      env:
      - name: CLUSTER_NAME
        value: indra20k8
      - name: CLUSTER_LOCATION
        value: us-central1-c
      image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      imagePullPolicy: IfNotPresent
      name: metadata-agent
      resources:
        limits:
          cpu: 43m
          memory: 25Mi
        requests:
          cpu: 43m
          memory: 25Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ssl-certs
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metadata-agent-token-9jjpn
        readOnly: true
    - command:
      - /pod_nanny
      - --config-dir=/etc/config
      - --cpu=40m
      - --extra-cpu=0.5m
      - --memory=20Mi
      - --extra-memory=1Mi
      - --threshold=5
      - --deployment=stackdriver-metadata-agent-cluster-level
      - --container=metadata-agent
      - --poll-period=300000
      - --estimator=exponential
      - --minClusterSize=5
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: k8s.gcr.io/addon-resizer:1.8.7
      imagePullPolicy: IfNotPresent
      name: metadata-agent-nanny
      resources:
        limits:
          cpu: 50m
          memory: 92560Ki
        requests:
          cpu: 50m
          memory: 92560Ki
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: metadata-agent-config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: metadata-agent-token-9jjpn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: gke-indra20k8-default-pool-b615b32b-kb0v
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metadata-agent
    serviceAccountName: metadata-agent
    terminationGracePeriodSeconds: 5
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: Directory
      name: ssl-certs
    - configMap:
        defaultMode: 420
        name: metadata-agent-config
      name: metadata-agent-config-volume
    - name: metadata-agent-token-9jjpn
      secret:
        defaultMode: 420
        secretName: metadata-agent-token-9jjpn
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:10:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2020-04-21T13:09:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://997c2aa1ec092a9d21b0d10674225f7a0fd25afb46af5a7bc627197fc05775df
      image: gcr.io/stackdriver-agents/metadata-agent-go:1.0.5
      imageID: docker-pullable://gcr.io/stackdriver-agents/metadata-agent-go@sha256:ca13ec92f6e41befff6ca2a578ee7951edb1e49a566430f816f9a8acf631a62a
      lastState: {}
      name: metadata-agent
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:04Z"
    - containerID: docker://9a45525e5d709927003c7542d8dd2d3e6d7dc96d9a86d7b48aa3dd5b1b7ec51c
      image: k8s.gcr.io/addon-resizer:1.8.7
      imageID: docker-pullable://k8s.gcr.io/addon-resizer@sha256:30b3b12e471c534949e12d2da958fdf33848d153f2a0a88565bdef7ca999b5ad
      lastState: {}
      name: metadata-agent-nanny
      ready: true
      restartCount: 0
      state:
        running:
          startedAt: "2020-04-21T13:10:24Z"
    hostIP: 10.128.0.6
    phase: Running
    podIP: 10.4.0.2
    qosClass: Guaranteed
    startTime: "2020-04-21T13:09:37Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== clusterrolebindings manifests ========

apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: cluster-admin
    resourceVersion: "92"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin
    uid: 67d1280b-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cluster-admin
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:masters
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      components.gke.io/component-name: updateinfo-crd
      components.gke.io/component-version: 1.0.1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{"components.gke.io/component-name":"updateinfo-crd","components.gke.io/component-version":"1.0.1"},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"cluster-autoscaler-updateinfo"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"read-updateinfo"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"cluster-autoscaler"}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: cluster-autoscaler-updateinfo
    resourceVersion: "4938120"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-autoscaler-updateinfo
    uid: 7ba24e05-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: read-updateinfo
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: cluster-autoscaler
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"event-exporter","kubernetes.io/cluster-service":"true"},"name":"event-exporter-rb"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"view"},"subjects":[{"kind":"ServiceAccount","name":"event-exporter-sa","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: event-exporter
      kubernetes.io/cluster-service: "true"
    name: event-exporter-rb
    resourceVersion: "347"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/event-exporter-rb
    uid: 78c3cdef-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: view
  subjects:
  - kind: ServiceAccount
    name: event-exporter-sa
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"gce:beta:kubelet-certificate-bootstrap"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"gce:beta:kubelet-certificate-bootstrap"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"kubelet"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: gce:beta:kubelet-certificate-bootstrap
    resourceVersion: "426"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/gce%3Abeta%3Akubelet-certificate-bootstrap
    uid: 7a1e6696-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: gce:beta:kubelet-certificate-bootstrap
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kubelet
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"gce:beta:kubelet-certificate-rotation"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"gce:beta:kubelet-certificate-rotation"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"Group","name":"system:nodes"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: gce:beta:kubelet-certificate-rotation
    resourceVersion: "427"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/gce%3Abeta%3Akubelet-certificate-rotation
    uid: 7a25bef7-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: gce:beta:kubelet-certificate-rotation
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:nodes
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"gce:cloud-provider"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"gce:cloud-provider"},"subjects":[{"kind":"ServiceAccount","name":"cloud-provider","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: gce:cloud-provider
    resourceVersion: "472"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/gce%3Acloud-provider
    uid: 7ba429af-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: gce:cloud-provider
  subjects:
  - kind: ServiceAccount
    name: cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"heapster-binding"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:heapster"},"subjects":[{"kind":"ServiceAccount","name":"heapster","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: heapster-binding
    resourceVersion: "322"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/heapster-binding
    uid: 77a9e931-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:heapster
  subjects:
  - kind: ServiceAccount
    name: heapster
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kube-apiserver-kubelet-api-admin"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"kubelet-api-admin"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"kube-apiserver"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kube-apiserver-kubelet-api-admin
    resourceVersion: "424"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kube-apiserver-kubelet-api-admin
    uid: 7a15d20e-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kubelet-api-admin
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kube-apiserver
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kubelet-bootstrap"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:node-bootstrapper"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"kubelet"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kubelet-bootstrap
    resourceVersion: "430"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubelet-bootstrap
    uid: 7a2b78d0-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-bootstrapper
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kubelet
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kubelet-bootstrap-certificate-bootstrap"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"gce:beta:kubelet-certificate-bootstrap"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"kubelet-bootstrap"}]}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kubelet-bootstrap-certificate-bootstrap
    resourceVersion: "383"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubelet-bootstrap-certificate-bootstrap
    uid: 7911f580-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: gce:beta:kubelet-certificate-bootstrap
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kubelet-bootstrap
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kubelet-bootstrap-node-bootstrapper"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:node-bootstrapper"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"kubelet-bootstrap"}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kubelet-bootstrap-node-bootstrapper
    resourceVersion: "382"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubelet-bootstrap-node-bootstrapper
    uid: 790f91b4-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-bootstrapper
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: kubelet-bootstrap
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    creationTimestamp: "2020-03-15T10:05:12Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
      kubernetes.io/cluster-service: "true"
    name: kubelet-cluster-admin
    resourceVersion: "278"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kubelet-cluster-admin
    uid: 75e680d4-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"metrics-server:system:auth-delegator"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:auth-delegator"},"subjects":[{"kind":"ServiceAccount","name":"metrics-server","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: metrics-server:system:auth-delegator
    resourceVersion: "397"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/metrics-server%3Asystem%3Aauth-delegator
    uid: 794a96af-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:auth-delegator
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"npd-binding"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:node-problem-detector"},"subjects":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"system:node-problem-detector"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: npd-binding
    resourceVersion: "423"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/npd-binding
    uid: 7a143b62-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-problem-detector
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:node-problem-detector
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"stackdriver:fluentd-gcp"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"stackdriver:fluentd-gcp"},"subjects":[{"kind":"ServiceAccount","name":"fluentd-gcp","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: stackdriver:fluentd-gcp
    resourceVersion: "364"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/stackdriver%3Afluentd-gcp
    uid: 78ea44cc-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: stackdriver:fluentd-gcp
  subjects:
  - kind: ServiceAccount
    name: fluentd-gcp
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"stackdriver:metadata-agent"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"stackdriver:metadata-agent"},"subjects":[{"kind":"ServiceAccount","name":"metadata-agent","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: stackdriver:metadata-agent
    resourceVersion: "359"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/stackdriver%3Ametadata-agent
    uid: 78defdbd-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: stackdriver:metadata-agent
  subjects:
  - kind: ServiceAccount
    name: metadata-agent
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:aws-cloud-provider
    resourceVersion: "100"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Aaws-cloud-provider
    uid: 67e5a626-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:aws-cloud-provider
  subjects:
  - kind: ServiceAccount
    name: aws-cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:basic-user
    resourceVersion: "94"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Abasic-user
    uid: 67d4fe3c-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:basic-user
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:authenticated
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:attachdetach-controller
    resourceVersion: "103"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aattachdetach-controller
    uid: 683beef3-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:attachdetach-controller
  subjects:
  - kind: ServiceAccount
    name: attachdetach-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:certificate-controller
    resourceVersion: "126"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Acertificate-controller
    uid: 6864d408-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:certificate-controller
  subjects:
  - kind: ServiceAccount
    name: certificate-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:clusterrole-aggregation-controller
    resourceVersion: "104"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aclusterrole-aggregation-controller
    uid: 683e615e-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:clusterrole-aggregation-controller
  subjects:
  - kind: ServiceAccount
    name: clusterrole-aggregation-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cronjob-controller
    resourceVersion: "105"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Acronjob-controller
    uid: 683fed19-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:cronjob-controller
  subjects:
  - kind: ServiceAccount
    name: cronjob-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:daemon-set-controller
    resourceVersion: "106"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adaemon-set-controller
    uid: 684178f2-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:daemon-set-controller
  subjects:
  - kind: ServiceAccount
    name: daemon-set-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:deployment-controller
    resourceVersion: "107"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adeployment-controller
    uid: 6842f71a-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:deployment-controller
  subjects:
  - kind: ServiceAccount
    name: deployment-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:disruption-controller
    resourceVersion: "108"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Adisruption-controller
    uid: 68446409-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:disruption-controller
  subjects:
  - kind: ServiceAccount
    name: disruption-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:endpoint-controller
    resourceVersion: "109"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aendpoint-controller
    uid: 6845d2dd-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:endpoint-controller
  subjects:
  - kind: ServiceAccount
    name: endpoint-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:expand-controller
    resourceVersion: "110"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aexpand-controller
    uid: 684879be-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:expand-controller
  subjects:
  - kind: ServiceAccount
    name: expand-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:generic-garbage-collector
    resourceVersion: "111"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ageneric-garbage-collector
    uid: 684a5116-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:generic-garbage-collector
  subjects:
  - kind: ServiceAccount
    name: generic-garbage-collector
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:horizontal-pod-autoscaler
    resourceVersion: "112"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ahorizontal-pod-autoscaler
    uid: 684c5605-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:horizontal-pod-autoscaler
  subjects:
  - kind: ServiceAccount
    name: horizontal-pod-autoscaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:job-controller
    resourceVersion: "113"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Ajob-controller
    uid: 684e0c01-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:job-controller
  subjects:
  - kind: ServiceAccount
    name: job-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:namespace-controller
    resourceVersion: "114"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Anamespace-controller
    uid: 684fc292-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:namespace-controller
  subjects:
  - kind: ServiceAccount
    name: namespace-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:node-controller
    resourceVersion: "115"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Anode-controller
    uid: 68515477-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:node-controller
  subjects:
  - kind: ServiceAccount
    name: node-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:persistent-volume-binder
    resourceVersion: "116"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apersistent-volume-binder
    uid: 6852c47e-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:persistent-volume-binder
  subjects:
  - kind: ServiceAccount
    name: persistent-volume-binder
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pod-garbage-collector
    resourceVersion: "117"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apod-garbage-collector
    uid: 6854e85e-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:pod-garbage-collector
  subjects:
  - kind: ServiceAccount
    name: pod-garbage-collector
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pv-protection-controller
    resourceVersion: "128"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apv-protection-controller
    uid: 6867d41a-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:pv-protection-controller
  subjects:
  - kind: ServiceAccount
    name: pv-protection-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pvc-protection-controller
    resourceVersion: "127"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Apvc-protection-controller
    uid: 6866911b-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:pvc-protection-controller
  subjects:
  - kind: ServiceAccount
    name: pvc-protection-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replicaset-controller
    resourceVersion: "118"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Areplicaset-controller
    uid: 6856c1b2-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:replicaset-controller
  subjects:
  - kind: ServiceAccount
    name: replicaset-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replication-controller
    resourceVersion: "119"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Areplication-controller
    uid: 6859f563-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:replication-controller
  subjects:
  - kind: ServiceAccount
    name: replication-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:resourcequota-controller
    resourceVersion: "120"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aresourcequota-controller
    uid: 685bb1a7-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:resourcequota-controller
  subjects:
  - kind: ServiceAccount
    name: resourcequota-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:route-controller
    resourceVersion: "121"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aroute-controller
    uid: 685da2a2-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:route-controller
  subjects:
  - kind: ServiceAccount
    name: route-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-account-controller
    resourceVersion: "122"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aservice-account-controller
    uid: 685f1dde-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:service-account-controller
  subjects:
  - kind: ServiceAccount
    name: service-account-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-controller
    resourceVersion: "123"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Aservice-controller
    uid: 68605432-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:service-controller
  subjects:
  - kind: ServiceAccount
    name: service-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:statefulset-controller
    resourceVersion: "124"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Astatefulset-controller
    uid: 686203f0-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:statefulset-controller
  subjects:
  - kind: ServiceAccount
    name: statefulset-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:ttl-controller
    resourceVersion: "125"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Acontroller%3Attl-controller
    uid: 686385e0-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:controller:ttl-controller
  subjects:
  - kind: ServiceAccount
    name: ttl-controller
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:discovery
    resourceVersion: "93"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Adiscovery
    uid: 67d33b28-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:discovery
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:authenticated
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-controller-manager
    resourceVersion: "97"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-controller-manager
    uid: 67da4e7d-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-controller-manager
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-controller-manager
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-dns
    resourceVersion: "98"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-dns
    uid: 67dd4f76-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-dns
  subjects:
  - kind: ServiceAccount
    name: kube-dns
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"system:kube-dns-autoscaler"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:kube-dns-autoscaler"},"subjects":[{"kind":"ServiceAccount","name":"kube-dns-autoscaler","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: system:kube-dns-autoscaler
    resourceVersion: "444"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-dns-autoscaler
    uid: 7b72debe-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-dns-autoscaler
  subjects:
  - kind: ServiceAccount
    name: kube-dns-autoscaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-scheduler
    resourceVersion: "99"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Akube-scheduler
    uid: 67e359a4-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:kube-scheduler
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-scheduler
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"system:metrics-server"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"ClusterRole","name":"system:metrics-server"},"subjects":[{"kind":"ServiceAccount","name":"metrics-server","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: system:metrics-server
    resourceVersion: "422"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Ametrics-server
    uid: 7a12981b-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:metrics-server
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node
    resourceVersion: "102"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Anode
    uid: 67edefb0-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-proxier
    resourceVersion: "96"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Anode-proxier
    uid: 67d8bfa8-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-proxier
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-proxy
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:public-info-viewer
    resourceVersion: "95"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Apublic-info-viewer
    uid: 67d71d64-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:public-info-viewer
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:authenticated
  - apiGroup: rbac.authorization.k8s.io
    kind: Group
    name: system:unauthenticated
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:volume-scheduler
    resourceVersion: "101"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Avolume-scheduler
    uid: 67e74f2c-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:volume-scheduler
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-scheduler
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== clusterroles manifests ========

apiVersion: v1
items:
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-admin: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: admin
    resourceVersion: "258"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/admin
    uid: 674bb677-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    - secrets
    - services/proxy
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - rbac.authorization.k8s.io
    resources:
    - rolebindings
    - roles
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{"kubernetes.io/deprecation":"cloud-provider clusterrole is DEPRECATED in the concern of potential collisions and will be removed in 1.16. Do not use this role."},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"cloud-provider"},"rules":[{"apiGroups":[""],"resources":["events"],"verbs":["create","patch","update"]}]}
      kubernetes.io/deprecation: cloud-provider clusterrole is DEPRECATED in the concern
        of potential collisions and will be removed in 1.16. Do not use this role.
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: cloud-provider
    resourceVersion: "476"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cloud-provider
    uid: 7bb1666b-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: cluster-admin
    resourceVersion: "38"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin
    uid: 674337a4-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - '*'
  - nonResourceURLs:
    - '*'
    verbs:
    - '*'
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-edit: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-admin: "true"
    name: edit
    resourceVersion: "254"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/edit
    uid: 674d174b-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    - secrets
    - services/proxy
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"gce:beta:kubelet-certificate-bootstrap"},"rules":[{"apiGroups":["certificates.k8s.io"],"resources":["certificatesigningrequests/nodeclient"],"verbs":["create"]}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: gce:beta:kubelet-certificate-bootstrap
    resourceVersion: "428"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/gce%3Abeta%3Akubelet-certificate-bootstrap
    uid: 7a2749dc-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/nodeclient
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"gce:beta:kubelet-certificate-rotation"},"rules":[{"apiGroups":["certificates.k8s.io"],"resources":["certificatesigningrequests/selfnodeclient","certificatesigningrequests/selfnodeserver"],"verbs":["create"]}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: gce:beta:kubelet-certificate-rotation
    resourceVersion: "429"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/gce%3Abeta%3Akubelet-certificate-rotation
    uid: 7a29d549-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/selfnodeclient
    - certificatesigningrequests/selfnodeserver
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"gce:cloud-provider"},"rules":[{"apiGroups":[""],"resources":["events"],"verbs":["create","patch","update"]}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: gce:cloud-provider
    resourceVersion: "474"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/gce%3Acloud-provider
    uid: 7ba61de7-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"kubelet-api-admin"},"rules":[{"apiGroups":[""],"resources":["nodes/proxy","nodes/log","nodes/stats","nodes/metrics","nodes/spec"],"verbs":["*"]}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: kubelet-api-admin
    resourceVersion: "425"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/kubelet-api-admin
    uid: 7a17719b-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes/proxy
    - nodes/log
    - nodes/stats
    - nodes/metrics
    - nodes/spec
    verbs:
    - '*'
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      components.gke.io/component-name: updateinfo-crd
      components.gke.io/component-version: 1.0.1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{"components.gke.io/component-name":"updateinfo-crd","components.gke.io/component-version":"1.0.1"},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"read-updateinfo"},"rules":[{"apiGroups":["nodemanagement.gke.io"],"resources":["updateinfos"],"verbs":["get","list","watch"]}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: read-updateinfo
    resourceVersion: "4938119"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/read-updateinfo
    uid: 7ba16e0d-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - nodemanagement.gke.io
    resources:
    - updateinfos
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"stackdriver:fluentd-gcp"},"rules":[{"apiGroups":[""],"resources":["pods","namespaces"],"verbs":["watch","get","list"]}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: stackdriver:fluentd-gcp
    resourceVersion: "363"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/stackdriver%3Afluentd-gcp
    uid: 78e3a682-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - namespaces
    verbs:
    - watch
    - get
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"stackdriver:metadata-agent"},"rules":[{"apiGroups":["*"],"resources":["*"],"verbs":["watch","get","list"]},{"apiGroups":["apps","extensions"],"resources":["deployments"],"verbs":["get","update"]}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: stackdriver:metadata-agent
    resourceVersion: "4938109"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/stackdriver%3Ametadata-agent
    uid: 78dca1e6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - watch
    - get
    - list
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-admin: "true"
    name: system:aggregate-to-admin
    resourceVersion: "45"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-admin
    uid: 67500526-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - rbac.authorization.k8s.io
    resources:
    - rolebindings
    - roles
    verbs:
    - create
    - delete
    - deletecollection
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-edit: "true"
    name: system:aggregate-to-edit
    resourceVersion: "46"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-edit
    uid: 6751ece3-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    - secrets
    - services/proxy
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - impersonate
  - apiGroups:
    - ""
    resources:
    - pods
    - pods/attach
    - pods/exec
    - pods/portforward
    - pods/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - replicationcontrollers
    - replicationcontrollers/scale
    - secrets
    - serviceaccounts
    - services
    - services/proxy
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/rollback
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - create
    - delete
    - deletecollection
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-view: "true"
    name: system:aggregate-to-view
    resourceVersion: "47"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaggregate-to-view
    uid: 6757985d-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:auth-delegator
    resourceVersion: "54"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aauth-delegator
    uid: 67654b51-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:aws-cloud-provider
    resourceVersion: "61"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aaws-cloud-provider
    uid: 67707c55-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:basic-user
    resourceVersion: "40"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Abasic-user
    uid: 6747a184-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - authorization.k8s.io
    resources:
    - selfsubjectaccessreviews
    - selfsubjectrulesreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
    resourceVersion: "62"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acertificates.k8s.io%3Acertificatesigningrequests%3Anodeclient
    uid: 6772935c-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/nodeclient
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
    resourceVersion: "63"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acertificates.k8s.io%3Acertificatesigningrequests%3Aselfnodeclient
    uid: 67758c87-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/selfnodeclient
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:attachdetach-controller
    resourceVersion: "66"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aattachdetach-controller
    uid: 6784bbcd-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - storage.k8s.io
    resources:
    - volumeattachments
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - csidrivers
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:certificate-controller
    resourceVersion: "89"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Acertificate-controller
    uid: 67ca3af6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests/approval
    - certificatesigningrequests/status
    verbs:
    - update
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:clusterrole-aggregation-controller
    resourceVersion: "67"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aclusterrole-aggregation-controller
    uid: 67a0b996-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - '*'
  - nonResourceURLs:
    - '*'
    verbs:
    - '*'
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cronjob-controller
    resourceVersion: "68"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Acronjob-controller
    uid: 67a24a41-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - batch
    resources:
    - cronjobs
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - jobs
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs/status
    verbs:
    - update
  - apiGroups:
    - batch
    resources:
    - cronjobs/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:daemon-set-controller
    resourceVersion: "69"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adaemon-set-controller
    uid: 67a48d4a-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - pods/binding
    verbs:
    - create
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:deployment-controller
    resourceVersion: "70"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adeployment-controller
    uid: 67a6900a-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments/finalizers
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:disruption-controller
    resourceVersion: "71"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Adisruption-controller
    uid: 67a8b027-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:endpoint-controller
    resourceVersion: "72"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aendpoint-controller
    uid: 67aa53fd-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - create
    - delete
    - get
    - list
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints/restricted
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:expand-controller
    resourceVersion: "73"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aexpand-controller
    uid: 67ac343e-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:generic-garbage-collector
    resourceVersion: "74"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ageneric-garbage-collector
    uid: 67ad3a3a-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:horizontal-pod-autoscaler
    resourceVersion: "75"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ahorizontal-pod-autoscaler
    uid: 67aedcb8-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers/status
    verbs:
    - update
  - apiGroups:
    - '*'
    resources:
    - '*/scale'
    verbs:
    - get
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
  - apiGroups:
    - ""
    resourceNames:
    - 'http:heapster:'
    - 'https:heapster:'
    resources:
    - services/proxy
    verbs:
    - get
  - apiGroups:
    - metrics.k8s.io
    resources:
    - pods
    verbs:
    - list
  - apiGroups:
    - custom.metrics.k8s.io
    resources:
    - '*'
    verbs:
    - get
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:job-controller
    resourceVersion: "76"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Ajob-controller
    uid: 67b0c38f-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - batch
    resources:
    - jobs
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - batch
    resources:
    - jobs/status
    verbs:
    - update
  - apiGroups:
    - batch
    resources:
    - jobs/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:namespace-controller
    resourceVersion: "77"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Anamespace-controller
    uid: 67b2c4a8-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces/finalize
    - namespaces/status
    verbs:
    - update
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - delete
    - deletecollection
    - get
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:node-controller
    resourceVersion: "78"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Anode-controller
    uid: 67b42727-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - delete
    - get
    - list
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:persistent-volume-binder
    resourceVersion: "79"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apersistent-volume-binder
    uid: 67b66297-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - create
    - delete
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumes/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - create
    - delete
    - get
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pod-garbage-collector
    resourceVersion: "80"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apod-garbage-collector
    uid: 67b7cf86-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pv-protection-controller
    resourceVersion: "91"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apv-protection-controller
    uid: 67cf1e40-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:pvc-protection-controller
    resourceVersion: "90"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Apvc-protection-controller
    uid: 67cbf9fe-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replicaset-controller
    resourceVersion: "81"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Areplicaset-controller
    uid: 67b9b2e0-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets/status
    verbs:
    - update
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:replication-controller
    resourceVersion: "82"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Areplication-controller
    uid: 67bb561d-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - list
    - patch
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:resourcequota-controller
    resourceVersion: "83"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aresourcequota-controller
    uid: 67bd4431-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - resourcequotas/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:route-controller
    resourceVersion: "84"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aroute-controller
    uid: 67bfa1bd-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-account-controller
    resourceVersion: "85"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aservice-account-controller
    uid: 67c2c17d-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - serviceaccounts
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:service-controller
    resourceVersion: "86"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Aservice-controller
    uid: 67c4d275-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - services/status
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:statefulset-controller
    resourceVersion: "87"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Astatefulset-controller
    uid: 67c66fa6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets/status
    verbs:
    - update
  - apiGroups:
    - apps
    resources:
    - statefulsets/finalizers
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    verbs:
    - create
    - delete
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - create
    - get
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:49Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:ttl-controller
    resourceVersion: "88"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acontroller%3Attl-controller
    uid: 67c89269-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:csi-external-attacher
    resourceVersion: "60"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acsi-external-attacher
    uid: 676e91d7-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - volumeattachments
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - get
    - list
    - patch
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:csi-external-provisioner
    resourceVersion: "65"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Acsi-external-provisioner
    uid: 677aa8e4-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - csinodes
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:discovery
    resourceVersion: "39"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Adiscovery
    uid: 6745e6e4-66a4-11ea-b80b-42010a800288
  rules:
  - nonResourceURLs:
    - /api
    - /api/*
    - /apis
    - /apis/*
    - /healthz
    - /openapi
    - /openapi/*
    - /version
    - /version/
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:heapster
    resourceVersion: "48"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Aheapster
    uid: 675a2013-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    - namespaces
    - nodes
    - pods
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-aggregator
    resourceVersion: "55"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-aggregator
    uid: 676716ae-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-controller-manager
    resourceVersion: "56"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-controller-manager
    uid: 67689fdf-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints
    - secrets
    - serviceaccounts
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - delete
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - namespaces
    - secrets
    - serviceaccounts
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - endpoints
    - secrets
    - serviceaccounts
    verbs:
    - update
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - '*'
    resources:
    - '*'
    verbs:
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-dns
    resourceVersion: "58"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-dns
    uid: 676b823e-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"system:kube-dns-autoscaler"},"rules":[{"apiGroups":[""],"resources":["nodes"],"verbs":["list","watch"]},{"apiGroups":[""],"resources":["replicationcontrollers/scale"],"verbs":["get","update"]},{"apiGroups":["extensions","apps"],"resources":["deployments/scale","replicasets/scale"],"verbs":["get","update"]},{"apiGroups":[""],"resources":["configmaps"],"verbs":["get","create"]}]}
    creationTimestamp: "2020-03-15T10:05:21Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: system:kube-dns-autoscaler
    resourceVersion: "443"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-dns-autoscaler
    uid: 7b719f0e-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers/scale
    verbs:
    - get
    - update
  - apiGroups:
    - extensions
    - apps
    resources:
    - deployments/scale
    - replicasets/scale
    verbs:
    - get
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kube-scheduler
    resourceVersion: "57"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akube-scheduler
    uid: 6769f1e0-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - create
  - apiGroups:
    - ""
    resourceNames:
    - kube-scheduler
    resources:
    - endpoints
    verbs:
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - pods/binding
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - replicationcontrollers
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - statefulsets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - subjectaccessreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:kubelet-api-admin
    resourceVersion: "52"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Akubelet-api-admin
    uid: 6761f9d3-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - proxy
  - apiGroups:
    - ""
    resources:
    - nodes/log
    - nodes/metrics
    - nodes/proxy
    - nodes/spec
    - nodes/stats
    verbs:
    - '*'
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"ClusterRole","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"system:metrics-server"},"rules":[{"apiGroups":[""],"resources":["pods","nodes","namespaces"],"verbs":["get","list","watch"]},{"apiGroups":["extensions"],"resources":["deployments"],"verbs":["get","list","update","watch"]}]}
    creationTimestamp: "2020-03-15T10:05:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: system:metrics-server
    resourceVersion: "421"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Ametrics-server
    uid: 7a10bc6b-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    - nodes
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - list
    - update
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node
    resourceVersion: "49"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode
    uid: 675c1419-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
  - apiGroups:
    - authorization.k8s.io
    resources:
    - localsubjectaccessreviews
    - subjectaccessreviews
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - create
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - create
    - delete
  - apiGroups:
    - ""
    resources:
    - pods/status
    verbs:
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - pods/eviction
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - configmaps
    - secrets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    - persistentvolumes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - endpoints
    verbs:
    - get
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - create
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims/status
    verbs:
    - get
    - patch
    - update
  - apiGroups:
    - ""
    resources:
    - serviceaccounts/token
    verbs:
    - create
  - apiGroups:
    - storage.k8s.io
    resources:
    - volumeattachments
    verbs:
    - get
  - apiGroups:
    - storage.k8s.io
    resources:
    - csidrivers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - csinodes
    verbs:
    - create
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - coordination.k8s.io
    resources:
    - leases
    verbs:
    - create
    - delete
    - get
    - patch
    - update
  - apiGroups:
    - node.k8s.io
    resources:
    - runtimeclasses
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-bootstrapper
    resourceVersion: "53"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-bootstrapper
    uid: 67639f3c-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - certificates.k8s.io
    resources:
    - certificatesigningrequests
    verbs:
    - create
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-problem-detector
    resourceVersion: "50"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-problem-detector
    uid: 675da19a-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - nodes/status
    verbs:
    - patch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:node-proxier
    resourceVersion: "51"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Anode-proxier
    uid: 675f835e-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    verbs:
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - nodes
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:persistent-volume-provisioner
    resourceVersion: "59"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Apersistent-volume-provisioner
    uid: 676cd7d6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - create
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:public-info-viewer
    resourceVersion: "41"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Apublic-info-viewer
    uid: 674a2001-66a4-11ea-b80b-42010a800288
  rules:
  - nonResourceURLs:
    - /healthz
    - /version
    - /version/
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:volume-scheduler
    resourceVersion: "64"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Avolume-scheduler
    uid: 6777f33d-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - persistentvolumes
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - persistentvolumeclaims
    verbs:
    - get
    - list
    - patch
    - update
    - watch
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-view: "true"
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:48Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
      rbac.authorization.k8s.io/aggregate-to-edit: "true"
    name: view
    resourceVersion: "251"
    selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/view
    uid: 674e7b23-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    - endpoints
    - persistentvolumeclaims
    - pods
    - replicationcontrollers
    - replicationcontrollers/scale
    - serviceaccounts
    - services
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - bindings
    - events
    - limitranges
    - namespaces/status
    - pods/log
    - pods/status
    - replicationcontrollers/status
    - resourcequotas
    - resourcequotas/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - apps
    resources:
    - controllerrevisions
    - daemonsets
    - deployments
    - deployments/scale
    - replicasets
    - replicasets/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - batch
    resources:
    - cronjobs
    - jobs
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    - deployments
    - deployments/scale
    - ingresses
    - networkpolicies
    - replicasets
    - replicasets/scale
    - replicationcontrollers/scale
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - policy
    resources:
    - poddisruptionbudgets
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - networking.k8s.io
    resources:
    - ingresses
    - networkpolicies
    verbs:
    - get
    - list
    - watch
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== rolebindings manifests ========

apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-public
    resourceVersion: "142"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/rolebindings/system%3Acontroller%3Abootstrap-signer
    uid: 6889c7e1-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:bootstrap-signer
  subjects:
  - kind: ServiceAccount
    name: bootstrap-signer
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"fluentd-gcp-scaler-binding","namespace":"kube-system"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"system:fluentd-gcp-scaler"},"subjects":[{"kind":"ServiceAccount","name":"fluentd-gcp-scaler","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: fluentd-gcp-scaler-binding
    namespace: kube-system
    resourceVersion: "369"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/fluentd-gcp-scaler-binding
    uid: 78f6aaa3-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:fluentd-gcp-scaler
  subjects:
  - kind: ServiceAccount
    name: fluentd-gcp-scaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"gce:cloud-provider","namespace":"kube-system"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"gce:cloud-provider"},"subjects":[{"kind":"ServiceAccount","name":"cloud-provider","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: gce:cloud-provider
    namespace: kube-system
    resourceVersion: "471"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/gce%3Acloud-provider
    uid: 7ba374f3-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: gce:cloud-provider
  subjects:
  - kind: ServiceAccount
    name: cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"heapster-binding","namespace":"kube-system"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"system:pod-nanny"},"subjects":[{"kind":"ServiceAccount","name":"heapster","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: heapster-binding
    namespace: kube-system
    resourceVersion: "324"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/heapster-binding
    uid: 77b3ee4a-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:pod-nanny
  subjects:
  - kind: ServiceAccount
    name: heapster
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"RoleBinding","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"metrics-server-auth-reader","namespace":"kube-system"},"roleRef":{"apiGroup":"rbac.authorization.k8s.io","kind":"Role","name":"extension-apiserver-authentication-reader"},"subjects":[{"kind":"ServiceAccount","name":"metrics-server","namespace":"kube-system"}]}
    creationTimestamp: "2020-03-15T10:05:18Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: metrics-server-auth-reader
    namespace: kube-system
    resourceVersion: "398"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/metrics-server-auth-reader
    uid: 794bf507-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: extension-apiserver-authentication-reader
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::extension-apiserver-authentication-reader
    namespace: kube-system
    resourceVersion: "136"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3A%3Aextension-apiserver-authentication-reader
    uid: 687c4100-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: extension-apiserver-authentication-reader
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-controller-manager
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-scheduler
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-controller-manager
    namespace: kube-system
    resourceVersion: "137"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3A%3Aleader-locking-kube-controller-manager
    uid: 687e5f4b-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system::leader-locking-kube-controller-manager
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-controller-manager
  - kind: ServiceAccount
    name: kube-controller-manager
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-scheduler
    namespace: kube-system
    resourceVersion: "138"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3A%3Aleader-locking-kube-scheduler
    uid: 688082dd-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system::leader-locking-kube-scheduler
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:kube-scheduler
  - kind: ServiceAccount
    name: kube-scheduler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-system
    resourceVersion: "139"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Abootstrap-signer
    uid: 6882aa1c-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:bootstrap-signer
  subjects:
  - kind: ServiceAccount
    name: bootstrap-signer
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cloud-provider
    namespace: kube-system
    resourceVersion: "140"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Acloud-provider
    uid: 6885bc9e-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:cloud-provider
  subjects:
  - kind: ServiceAccount
    name: cloud-provider
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:token-cleaner
    namespace: kube-system
    resourceVersion: "141"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system%3Acontroller%3Atoken-cleaner
    uid: 6887e288-66a4-11ea-b80b-42010a800288
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: system:controller:token-cleaner
  subjects:
  - kind: ServiceAccount
    name: token-cleaner
    namespace: kube-system
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== roles manifests ========

apiVersion: v1
items:
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-public
    resourceVersion: "135"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/roles/system%3Acontroller%3Abootstrap-signer
    uid: 687836dd-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - cluster-info
    resources:
    - configmaps
    verbs:
    - update
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":{"annotations":{"kubernetes.io/deprecation":"cloud-provider role is DEPRECATED in the concern of potential collisions and will be removed in 1.16. Do not use this role."},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"cloud-provider","namespace":"kube-system"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["create","get","patch","update","list","watch"]}]}
      kubernetes.io/deprecation: cloud-provider role is DEPRECATED in the concern
        of potential collisions and will be removed in 1.16. Do not use this role.
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: cloud-provider
    namespace: kube-system
    resourceVersion: "475"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/cloud-provider
    uid: 7bac34c6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - create
    - get
    - patch
    - update
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: extension-apiserver-authentication-reader
    namespace: kube-system
    resourceVersion: "129"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/extension-apiserver-authentication-reader
    uid: 686aa847-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resourceNames:
    - extension-apiserver-authentication
    resources:
    - configmaps
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile"},"name":"gce:cloud-provider","namespace":"kube-system"},"rules":[{"apiGroups":[""],"resources":["configmaps"],"verbs":["create","get","patch","update","list","watch"]}]}
    creationTimestamp: "2020-03-15T10:05:22Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
    name: gce:cloud-provider
    namespace: kube-system
    resourceVersion: "473"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/gce%3Acloud-provider
    uid: 7ba508dd-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - create
    - get
    - patch
    - update
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-controller-manager
    namespace: kube-system
    resourceVersion: "133"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3A%3Aleader-locking-kube-controller-manager
    uid: 6873bf7f-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - kube-controller-manager
    resources:
    - configmaps
    verbs:
    - get
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system::leader-locking-kube-scheduler
    namespace: kube-system
    resourceVersion: "134"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3A%3Aleader-locking-kube-scheduler
    uid: 6875c7fc-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - watch
  - apiGroups:
    - ""
    resourceNames:
    - kube-scheduler
    resources:
    - configmaps
    verbs:
    - get
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:bootstrap-signer
    namespace: kube-system
    resourceVersion: "130"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Abootstrap-signer
    uid: 686c9497-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:cloud-provider
    namespace: kube-system
    resourceVersion: "131"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Acloud-provider
    uid: 686e5e98-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - create
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      rbac.authorization.kubernetes.io/autoupdate: "true"
    creationTimestamp: "2020-03-15T10:04:50Z"
    labels:
      kubernetes.io/bootstrapping: rbac-defaults
    name: system:controller:token-cleaner
    namespace: kube-system
    resourceVersion: "132"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Acontroller%3Atoken-cleaner
    uid: 687136b7-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - secrets
    verbs:
    - delete
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - events
    verbs:
    - create
    - patch
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"system:fluentd-gcp-scaler","namespace":"kube-system"},"rules":[{"apiGroups":["extensions"],"resources":["daemonsets"],"verbs":["get","patch"]},{"apiGroups":["scalingpolicy.kope.io"],"resources":["scalingpolicies"],"verbs":["get"]}]}
    creationTimestamp: "2020-03-15T10:05:17Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: system:fluentd-gcp-scaler
    namespace: kube-system
    resourceVersion: "368"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Afluentd-gcp-scaler
    uid: 78f4f3c6-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - extensions
    resources:
    - daemonsets
    verbs:
    - get
    - patch
  - apiGroups:
    - scalingpolicy.kope.io
    resources:
    - scalingpolicies
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"rbac.authorization.k8s.io/v1","kind":"Role","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","kubernetes.io/cluster-service":"true"},"name":"system:pod-nanny","namespace":"kube-system"},"rules":[{"apiGroups":[""],"resources":["pods"],"verbs":["get"]},{"apiGroups":["extensions"],"resources":["deployments"],"verbs":["get","update"]}]}
    creationTimestamp: "2020-03-15T10:05:15Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/cluster-service: "true"
    name: system:pod-nanny
    namespace: kube-system
    resourceVersion: "323"
    selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system%3Apod-nanny
    uid: 77ae081b-66a4-11ea-b80b-42010a800288
  rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - get
  - apiGroups:
    - extensions
    resources:
    - deployments
    verbs:
    - get
    - update
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== priorityclasses manifests ========

apiVersion: v1
items:
- apiVersion: scheduling.k8s.io/v1
  description: Used for system critical pods that must run in the cluster, but can
    be moved to another node if necessary.
  kind: PriorityClass
  metadata:
    creationTimestamp: "2020-03-15T10:04:48Z"
    generation: 1
    name: system-cluster-critical
    resourceVersion: "37"
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/system-cluster-critical
    uid: 6740e8b6-66a4-11ea-b80b-42010a800288
  value: 2000000000
- apiVersion: scheduling.k8s.io/v1
  description: Used for system critical pods that must not be moved from their current
    node.
  kind: PriorityClass
  metadata:
    creationTimestamp: "2020-03-15T10:04:48Z"
    generation: 1
    name: system-node-critical
    resourceVersion: "36"
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/system-node-critical
    uid: 673d4ad7-66a4-11ea-b80b-42010a800288
  value: 2000001000
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

======== storageclasses manifests ========

apiVersion: v1
items:
- allowVolumeExpansion: true
  apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
    annotations:
      storageclass.kubernetes.io/is-default-class: "true"
    creationTimestamp: "2020-03-15T10:05:12Z"
    labels:
      addonmanager.kubernetes.io/mode: EnsureExists
      kubernetes.io/cluster-service: "true"
    name: standard
    resourceVersion: "279"
    selfLink: /apis/storage.k8s.io/v1/storageclasses/standard
    uid: 75e85c4d-66a4-11ea-b80b-42010a800288
  parameters:
    type: pd-standard
  provisioner: kubernetes.io/gce-pd
  reclaimPolicy: Delete
  volumeBindingMode: Immediate
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
